DATASET = covid-misinformation
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 64
MODEL = distilbert-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 10000
SAVE EVERY = None

2023-08-22-13-52-28: Loading and pre-processing datasets...
2023-08-22-13-54-30: Finished pre-processing datasets.

2023-08-22-13-54-30: Tokenizing datasets...
2023-08-22-13-57-30: Finished tokenizing datasets.

2023-08-22-13-57-30: Preparing data-loaders...
2023-08-22-13-57-30: Finished preparing data-loaders.

2023-08-22-13-57-30: Loading and preparing model...
2023-08-22-13-57-32: Finshed preparing model.

2023-08-22-13-57-32: Starting training...

2023-08-22-14-21-23: Training (last 10000 batches): accuracy = 0.896334, f1-score = 0.917166, loss = 2408.670036
2023-08-22-14-24-02: Validation (total 3214 batches): accuracy = 0.920917, f1-score = 0.936302, loss = 587.443481
2023-08-22-14-24-02: Finished batch 10000.

2023-08-22-14-47-55: Training (last 10000 batches): accuracy = 0.924419, f1-score = 0.939034, loss = 1750.788431
2023-08-22-14-50-33: Validation (total 3214 batches): accuracy = 0.928248, f1-score = 0.941718, loss = 535.430725
2023-08-22-14-50-33: Finished batch 20000.

2023-08-22-15-14-28: Training (last 10000 batches): accuracy = 0.933025, f1-score = 0.945801, loss = 1549.671100
2023-08-22-15-17-08: Validation (total 3214 batches): accuracy = 0.932016, f1-score = 0.944618, loss = 506.189026
2023-08-22-15-17-08: Finished batch 30000.

2023-08-22-15-41-07: Training (last 10000 batches): accuracy = 0.940823, f1-score = 0.951961, loss = 1358.657931
2023-08-22-15-44-11: Validation (total 3214 batches): accuracy = 0.934462, f1-score = 0.946936, loss = 505.080627
2023-08-22-15-44-11: Finished batch 40000.

2023-08-22-16-05-20: Training (last 10000 batches): accuracy = 0.943284, f1-score = 0.953924, loss = 1306.917289
2023-08-22-16-08-00: Validation (total 3214 batches): accuracy = 0.934622, f1-score = 0.946612, loss = 498.539734
2023-08-22-16-08-00: Finished batch 48207.

