DATASET = covid-misinformation
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 286
BATCH SIZE = 64
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 10000
SAVE EVERY = None

2023-08-21-03-17-58: Loading and pre-processing datasets...
2023-08-21-03-19-59: Finished pre-processing datasets.

2023-08-21-03-19-59: Tokenizing datasets...
2023-08-21-03-23-07: Finished tokenizing datasets.

2023-08-21-03-23-07: Preparing data-loaders...
2023-08-21-03-23-07: Finished preparing data-loaders.

2023-08-21-03-23-07: Loading and preparing model...
2023-08-21-03-23-09: Finshed preparing model.

2023-08-21-03-23-09: Starting training...

2023-08-21-06-42-02: Training (last 10000 batches): accuracy = 0.896158, f1-score = 0.916871, loss = 2416.504291
2023-08-21-07-09-43: Validation (total 3214 batches): accuracy = 0.921738, f1-score = 0.936370, loss = 584.788330
2023-08-21-07-09-43: Finished batch 10000.

2023-08-21-10-19-10: Training (last 10000 batches): accuracy = 0.924265, f1-score = 0.938909, loss = 1766.107820
2023-08-21-10-42-27: Validation (total 3214 batches): accuracy = 0.928944, f1-score = 0.942253, loss = 539.026978
2023-08-21-10-42-27: Finished batch 20000.

2023-08-21-13-49-01: Training (last 10000 batches): accuracy = 0.932305, f1-score = 0.945231, loss = 1576.257758
2023-08-21-14-10-21: Validation (total 3214 batches): accuracy = 0.932420, f1-score = 0.945700, loss = 511.752136
2023-08-21-14-10-21: Finished batch 30000.

2023-08-21-17-22-02: Training (last 10000 batches): accuracy = 0.939574, f1-score = 0.951010, loss = 1391.078383
2023-08-21-17-49-10: Validation (total 3214 batches): accuracy = 0.934836, f1-score = 0.947128, loss = 507.233215
2023-08-21-17-49-10: Finished batch 40000.

2023-08-21-20-33-32: Training (last 10000 batches): accuracy = 0.941538, f1-score = 0.952470, loss = 1348.037459
2023-08-21-21-00-39: Validation (total 3214 batches): accuracy = 0.935794, f1-score = 0.947835, loss = 495.930756
2023-08-21-21-00-39: Finished batch 48207.

