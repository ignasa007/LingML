DATASET = covid-misinformation
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 128
BATCH SIZE = 64
MODEL = albert-base-v2
LEARNING RATE = 1e-05
TEST EVERY = 10000
SAVE EVERY = None

2023-08-19-16-53-24: Loading and pre-processing datasets...
2023-08-19-16-55-29: Finished pre-processing datasets.

2023-08-19-16-55-29: Tokenizing datasets...
2023-08-19-16-58-37: Finished tokenizing datasets.

2023-08-19-16-58-37: Preparing data-loaders...
2023-08-19-16-58-37: Finished preparing data-loaders.

2023-08-19-16-58-37: Loading and preparing model...
2023-08-19-16-58-38: Finshed preparing model.

2023-08-19-16-58-38: Starting training...

2023-08-19-18-22-39: Training (last 10000 batches): accuracy = 0.888094, f1-score = 0.910675, loss = 2606.019612
2023-08-19-18-33-00: Validation (total 3214 batches): accuracy = 0.909224, f1-score = 0.925500, loss = 675.829956
2023-08-19-18-33-00: Finished batch 10000.

2023-08-19-20-02-45: Training (last 10000 batches): accuracy = 0.920521, f1-score = 0.936001, loss = 1856.288972
2023-08-19-20-15-04: Validation (total 3214 batches): accuracy = 0.921121, f1-score = 0.935800, loss = 590.787109
2023-08-19-20-15-04: Finished batch 20000.

2023-08-19-21-33-00: Training (last 10000 batches): accuracy = 0.929130, f1-score = 0.942710, loss = 1650.744633
2023-08-19-21-44-24: Validation (total 3214 batches): accuracy = 0.926853, f1-score = 0.941461, loss = 554.000793
2023-08-19-21-44-24: Finished batch 30000.

2023-08-19-23-13-07: Training (last 10000 batches): accuracy = 0.936743, f1-score = 0.948663, loss = 1458.558028
2023-08-19-23-23-45: Validation (total 3214 batches): accuracy = 0.929153, f1-score = 0.942915, loss = 536.270081
2023-08-19-23-23-45: Finished batch 40000.

2023-08-20-00-20-12: Training (last 10000 batches): accuracy = 0.938492, f1-score = 0.950093, loss = 1418.883926
2023-08-20-00-27-03: Validation (total 3214 batches): accuracy = 0.929853, f1-score = 0.943168, loss = 525.864380
2023-08-20-00-27-03: Finished batch 48207.

