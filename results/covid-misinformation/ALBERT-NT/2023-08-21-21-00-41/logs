DATASET = covid-misinformation
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 128
BATCH SIZE = 64
MODEL = albert-base-v2
LEARNING RATE = 1e-05
TEST EVERY = 10000
SAVE EVERY = None

2023-08-21-21-00-41: Loading and pre-processing datasets...
2023-08-21-21-02-45: Finished pre-processing datasets.

2023-08-21-21-02-45: Tokenizing datasets...
2023-08-21-21-05-49: Finished tokenizing datasets.

2023-08-21-21-05-49: Preparing data-loaders...
2023-08-21-21-05-49: Finished preparing data-loaders.

2023-08-21-21-05-49: Loading and preparing model...
2023-08-21-21-05-51: Finshed preparing model.

2023-08-21-21-05-51: Starting training...

2023-08-21-22-30-39: Training (last 10000 batches): accuracy = 0.889852, f1-score = 0.911989, loss = 2573.585485
2023-08-21-22-43-53: Validation (total 3214 batches): accuracy = 0.909968, f1-score = 0.927369, loss = 673.944336
2023-08-21-22-43-53: Finished batch 10000.

2023-08-22-00-16-22: Training (last 10000 batches): accuracy = 0.916746, f1-score = 0.932957, loss = 1954.409074
2023-08-22-00-27-02: Validation (total 3214 batches): accuracy = 0.915296, f1-score = 0.931336, loss = 635.576782
2023-08-22-00-27-02: Finished batch 20000.

2023-08-22-02-02-24: Training (last 10000 batches): accuracy = 0.917223, f1-score = 0.933278, loss = 1929.471919
2023-08-22-02-16-25: Validation (total 3214 batches): accuracy = 0.909326, f1-score = 0.927568, loss = 683.802612
2023-08-22-02-16-25: Finished batch 30000.

2023-08-22-03-43-37: Training (last 10000 batches): accuracy = 0.924576, f1-score = 0.939028, loss = 1749.231974
2023-08-22-03-56-44: Validation (total 3214 batches): accuracy = 0.923669, f1-score = 0.938395, loss = 573.375427
2023-08-22-03-56-44: Finished batch 40000.

2023-08-22-05-19-02: Training (last 10000 batches): accuracy = 0.921346, f1-score = 0.936783, loss = 1778.709690
2023-08-22-05-29-59: Validation (total 3214 batches): accuracy = 0.823947, f1-score = 0.847121, loss = 1262.766357
2023-08-22-05-29-59: Finished batch 48207.

