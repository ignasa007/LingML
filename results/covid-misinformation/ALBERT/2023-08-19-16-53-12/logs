DATASET = covid-misinformation
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 64
MODEL = albert-base-v2
LEARNING RATE = 1e-05
TEST EVERY = 10000
SAVE EVERY = None

2023-08-19-16-53-12: Loading and pre-processing datasets...
2023-08-19-16-55-15: Finished pre-processing datasets.

2023-08-19-16-55-15: Tokenizing datasets...
2023-08-19-16-58-33: Finished tokenizing datasets.

2023-08-19-16-58-33: Preparing data-loaders...
2023-08-19-16-58-33: Finished preparing data-loaders.

2023-08-19-16-58-33: Loading and preparing model...
2023-08-19-16-58-34: Finshed preparing model.

2023-08-19-16-58-34: Starting training...

2023-08-19-17-51-22: Training (last 10000 batches): accuracy = 0.890725, f1-score = 0.912710, loss = 2565.680449
2023-08-19-17-57-40: Validation (total 3214 batches): accuracy = 0.908043, f1-score = 0.927342, loss = 684.744019
2023-08-19-17-57-40: Finished batch 10000.

2023-08-19-18-50-16: Training (last 10000 batches): accuracy = 0.920918, f1-score = 0.936346, loss = 1845.546703
2023-08-19-18-56-35: Validation (total 3214 batches): accuracy = 0.922118, f1-score = 0.937396, loss = 593.313232
2023-08-19-18-56-35: Finished batch 20000.

2023-08-19-19-49-24: Training (last 10000 batches): accuracy = 0.925378, f1-score = 0.939756, loss = 1739.748657
2023-08-19-19-55-44: Validation (total 3214 batches): accuracy = 0.913439, f1-score = 0.930166, loss = 646.136780
2023-08-19-19-55-44: Finished batch 30000.

2023-08-19-20-48-24: Training (last 10000 batches): accuracy = 0.933657, f1-score = 0.946341, loss = 1534.908522
2023-08-19-20-54-42: Validation (total 3214 batches): accuracy = 0.924242, f1-score = 0.937706, loss = 562.914490
2023-08-19-20-54-42: Finished batch 40000.

2023-08-19-21-37-51: Training (last 10000 batches): accuracy = 0.936129, f1-score = 0.948251, loss = 1471.289076
2023-08-19-21-44-10: Validation (total 3214 batches): accuracy = 0.928001, f1-score = 0.942086, loss = 538.060364
2023-08-19-21-44-10: Finished batch 48207.

