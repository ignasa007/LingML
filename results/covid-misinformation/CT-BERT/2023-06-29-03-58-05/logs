DATASET = covid-misinformation
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 64
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 10000
SAVE EVERY = 10000

2023-06-29-03-58-05: Loading and pre-processing datasets...
2023-06-29-04-00-22: Finished pre-processing datasets.

2023-06-29-04-00-22: Tokenizing datasets...
2023-06-29-04-03-46: Finished tokenizing datasets.

2023-06-29-04-03-46: Preparing data-loaders...
2023-06-29-04-03-46: Finished preparing data-loaders.

2023-06-29-04-03-46: Loading and preparing model...
2023-06-29-04-03-53: Finshed preparing model.

2023-06-29-04-03-53: Starting training...

2023-06-29-06-48-25: Training (last 10000 batches): accuracy = 0.910739, f1-score = 0.928109, loss = 2077.319488
2023-06-29-07-07-41: Validation (total 3214 batches): accuracy = 0.930427, f1-score = 0.943980, loss = 521.584045
2023-06-29-07-07-41: Finished batch 10000.

2023-06-29-07-07-41: Saving model at ./results/2023-06-29-03-58-05/ckpt10000.pth...
2023-06-29-07-07-42: Finished saving model at ./results/2023-06-29-03-58-05/ckpt10000.pth.

2023-06-29-09-52-29: Training (last 10000 batches): accuracy = 0.934571, f1-score = 0.946931, loss = 1537.486856
2023-06-29-10-11-35: Validation (total 3214 batches): accuracy = 0.936348, f1-score = 0.947778, loss = 486.858765
2023-06-29-10-11-35: Finished batch 20000.

2023-06-29-10-11-35: Saving model at ./results/2023-06-29-03-58-05/ckpt20000.pth...
2023-06-29-10-11-36: Finished saving model at ./results/2023-06-29-03-58-05/ckpt20000.pth.

2023-06-29-12-55-26: Training (last 10000 batches): accuracy = 0.942084, f1-score = 0.952927, loss = 1345.932661
2023-06-29-13-14-23: Validation (total 3214 batches): accuracy = 0.940753, f1-score = 0.951938, loss = 453.590607
2023-06-29-13-14-23: Finished batch 30000.

2023-06-29-13-14-23: Saving model at ./results/2023-06-29-03-58-05/ckpt30000.pth...
2023-06-29-13-14-24: Finished saving model at ./results/2023-06-29-03-58-05/ckpt30000.pth.

2023-06-29-15-59-29: Training (last 10000 batches): accuracy = 0.951320, f1-score = 0.960279, loss = 1129.440633
2023-06-29-16-18-27: Validation (total 3214 batches): accuracy = 0.939722, f1-score = 0.950396, loss = 487.363007
2023-06-29-16-18-27: Finished batch 40000.

2023-06-29-16-18-27: Saving model at ./results/2023-06-29-03-58-05/ckpt40000.pth...
2023-06-29-16-18-28: Finished saving model at ./results/2023-06-29-03-58-05/ckpt40000.pth.

2023-06-29-18-32-27: Training (last 10000 batches): accuracy = 0.952895, f1-score = 0.961544, loss = 1087.470534
2023-06-29-18-50-54: Validation (total 3214 batches): accuracy = 0.942503, f1-score = 0.952958, loss = 456.442352
2023-06-29-18-50-54: Finished batch 48207.

2023-06-29-18-50-54: Saving model at ./results/2023-06-29-03-58-05/ckpt48207.pth...
2023-06-29-18-50-55: Finished saving model at ./results/2023-06-29-03-58-05/ckpt48207.pth.