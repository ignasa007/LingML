DATASET = covid-misinformation
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 64
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 10000
SAVE EVERY = None

2023-08-20-03-05-11: Loading and pre-processing datasets...
2023-08-20-03-07-12: Finished pre-processing datasets.

2023-08-20-03-07-12: Tokenizing datasets...
2023-08-20-03-10-14: Finished tokenizing datasets.

2023-08-20-03-10-14: Preparing data-loaders...
2023-08-20-03-10-14: Finished preparing data-loaders.

2023-08-20-03-10-14: Loading and preparing model...
2023-08-20-03-10-20: Finshed preparing model.

2023-08-20-03-10-20: Starting training...

2023-08-20-05-39-17: Training (last 10000 batches): accuracy = 0.810884, f1-score = 0.856624, loss = 3583.374193
2023-08-20-05-56-19: Validation (total 3214 batches): accuracy = 0.892120, f1-score = 0.916592, loss = 763.049194
2023-08-20-05-56-19: Finished batch 10000.

2023-08-20-08-25-19: Training (last 10000 batches): accuracy = 0.916521, f1-score = 0.933171, loss = 1903.495529
2023-08-20-08-42-22: Validation (total 3214 batches): accuracy = 0.933324, f1-score = 0.946225, loss = 515.940369
2023-08-20-08-42-22: Finished batch 20000.

2023-08-20-11-11-16: Training (last 10000 batches): accuracy = 0.935677, f1-score = 0.947771, loss = 1503.815137
2023-08-20-11-28-20: Validation (total 3214 batches): accuracy = 0.938789, f1-score = 0.950499, loss = 463.514923
2023-08-20-11-28-20: Finished batch 30000.

2023-08-20-13-56-59: Training (last 10000 batches): accuracy = 0.945595, f1-score = 0.955667, loss = 1259.891353
2023-08-20-14-14-02: Validation (total 3214 batches): accuracy = 0.940841, f1-score = 0.951978, loss = 464.080505
2023-08-20-14-14-02: Finished batch 40000.

2023-08-20-16-16-03: Training (last 10000 batches): accuracy = 0.947892, f1-score = 0.957488, loss = 1207.515317
2023-08-20-16-33-07: Validation (total 3214 batches): accuracy = 0.942294, f1-score = 0.953273, loss = 448.976959
2023-08-20-16-33-07: Finished batch 48207.

