DATASET = covid-misinformation
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 128
BATCH SIZE = 64
MODEL = distilbert-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 10000
SAVE EVERY = None

2023-08-23-19-20-53: Loading and pre-processing datasets...
2023-08-23-19-22-56: Finished pre-processing datasets.

2023-08-23-19-22-56: Tokenizing datasets...
2023-08-23-19-26-02: Finished tokenizing datasets.

2023-08-23-19-26-02: Preparing data-loaders...
2023-08-23-19-26-02: Finished preparing data-loaders.

2023-08-23-19-26-02: Loading and preparing model...
2023-08-23-19-26-13: Finshed preparing model.

2023-08-23-19-26-13: Starting training...

2023-08-23-20-11-14: Training (last 10000 batches): accuracy = 0.896280, f1-score = 0.916944, loss = 2408.127626
2023-08-23-20-17-16: Validation (total 3214 batches): accuracy = 0.919842, f1-score = 0.934970, loss = 595.784302
2023-08-23-20-17-16: Finished batch 10000.

2023-08-23-20-55-06: Training (last 10000 batches): accuracy = 0.924901, f1-score = 0.939565, loss = 1741.654746
2023-08-23-20-59-51: Validation (total 3214 batches): accuracy = 0.928093, f1-score = 0.942368, loss = 549.549866
2023-08-23-20-59-51: Finished batch 20000.

2023-08-23-21-32-14: Training (last 10000 batches): accuracy = 0.933456, f1-score = 0.946143, loss = 1544.329278
2023-08-23-21-35-26: Validation (total 3214 batches): accuracy = 0.931739, f1-score = 0.945175, loss = 517.237427
2023-08-23-21-35-26: Finished batch 30000.

2023-08-23-22-04-43: Training (last 10000 batches): accuracy = 0.941315, f1-score = 0.952335, loss = 1348.233801
2023-08-23-22-07-59: Validation (total 3214 batches): accuracy = 0.933976, f1-score = 0.946370, loss = 508.057587
2023-08-23-22-07-59: Finished batch 40000.

2023-08-23-22-32-08: Training (last 10000 batches): accuracy = 0.943034, f1-score = 0.953698, loss = 1306.800703
2023-08-23-22-35-24: Validation (total 3214 batches): accuracy = 0.935449, f1-score = 0.947669, loss = 497.806702
2023-08-23-22-35-24: Finished batch 48207.

