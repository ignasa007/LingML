DATASET = covid-misinformation
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 128
BATCH SIZE = 64
MODEL = distilbert-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 10000
SAVE EVERY = None

2023-08-22-05-30-01: Loading and pre-processing datasets...
2023-08-22-05-32-05: Finished pre-processing datasets.

2023-08-22-05-32-05: Tokenizing datasets...
2023-08-22-05-34-54: Finished tokenizing datasets.

2023-08-22-05-34-54: Preparing data-loaders...
2023-08-22-05-34-54: Finished preparing data-loaders.

2023-08-22-05-34-54: Loading and preparing model...
2023-08-22-05-34-56: Finshed preparing model.

2023-08-22-05-34-56: Starting training...

2023-08-22-06-12-57: Training (last 10000 batches): accuracy = 0.897106, f1-score = 0.917713, loss = 2395.464272
2023-08-22-06-18-27: Validation (total 3214 batches): accuracy = 0.919322, f1-score = 0.934668, loss = 601.539612
2023-08-22-06-18-27: Finished batch 10000.

2023-08-22-07-03-34: Training (last 10000 batches): accuracy = 0.925009, f1-score = 0.939494, loss = 1752.436642
2023-08-22-07-09-33: Validation (total 3214 batches): accuracy = 0.927981, f1-score = 0.941944, loss = 531.711365
2023-08-22-07-09-33: Finished batch 20000.

2023-08-22-07-56-22: Training (last 10000 batches): accuracy = 0.933142, f1-score = 0.945862, loss = 1541.015542
2023-08-22-08-01-25: Validation (total 3214 batches): accuracy = 0.928282, f1-score = 0.941041, loss = 530.486938
2023-08-22-08-01-25: Finished batch 30000.

2023-08-22-08-38-48: Training (last 10000 batches): accuracy = 0.941477, f1-score = 0.952484, loss = 1344.482506
2023-08-22-08-43-31: Validation (total 3214 batches): accuracy = 0.933504, f1-score = 0.945941, loss = 504.378479
2023-08-22-08-43-31: Finished batch 40000.

2023-08-22-09-14-54: Training (last 10000 batches): accuracy = 0.943406, f1-score = 0.953983, loss = 1295.637582
2023-08-22-09-20-35: Validation (total 3214 batches): accuracy = 0.934627, f1-score = 0.946839, loss = 496.872345
2023-08-22-09-20-35: Finished batch 48207.

