DATASET = covid-misinformation
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 286
BATCH SIZE = 64
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 10000
SAVE EVERY = None

2023-08-20-16-33-09: Loading and pre-processing datasets...
2023-08-20-16-35-13: Finished pre-processing datasets.

2023-08-20-16-35-13: Tokenizing datasets...
2023-08-20-16-38-22: Finished tokenizing datasets.

2023-08-20-16-38-22: Preparing data-loaders...
2023-08-20-16-38-22: Finished preparing data-loaders.

2023-08-20-16-38-22: Loading and preparing model...
2023-08-20-16-38-24: Finshed preparing model.

2023-08-20-16-38-24: Starting training...

2023-08-20-18-28-34: Training (last 10000 batches): accuracy = 0.896202, f1-score = 0.916683, loss = 2403.846434
2023-08-20-18-40-55: Validation (total 3214 batches): accuracy = 0.922054, f1-score = 0.937792, loss = 591.601990
2023-08-20-18-40-55: Finished batch 10000.

2023-08-20-20-31-05: Training (last 10000 batches): accuracy = 0.924023, f1-score = 0.938748, loss = 1772.566201
2023-08-20-20-43-21: Validation (total 3214 batches): accuracy = 0.929177, f1-score = 0.943336, loss = 530.298523
2023-08-20-20-43-21: Finished batch 20000.

2023-08-20-22-33-54: Training (last 10000 batches): accuracy = 0.931681, f1-score = 0.944686, loss = 1581.564941
2023-08-20-22-46-11: Validation (total 3214 batches): accuracy = 0.933893, f1-score = 0.946594, loss = 498.318420
2023-08-20-22-46-11: Finished batch 30000.

2023-08-21-00-36-42: Training (last 10000 batches): accuracy = 0.938676, f1-score = 0.950282, loss = 1410.089350
2023-08-21-00-49-04: Validation (total 3214 batches): accuracy = 0.933849, f1-score = 0.945970, loss = 511.714539
2023-08-21-00-49-04: Finished batch 40000.

2023-08-21-02-19-33: Training (last 10000 batches): accuracy = 0.940835, f1-score = 0.951922, loss = 1359.400034
2023-08-21-02-31-52: Validation (total 3214 batches): accuracy = 0.936285, f1-score = 0.948507, loss = 490.922577
2023-08-21-02-31-52: Finished batch 48207.

