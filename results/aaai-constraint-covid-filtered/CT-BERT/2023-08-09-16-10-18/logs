DATASET = aaai-constraint-covid-filtered
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 300
SAVE EVERY = None

2023-08-09-16-10-18: Loading and pre-processing datasets...
2023-08-09-16-10-19: Finished pre-processing datasets.

2023-08-09-16-10-19: Tokenizing datasets...
2023-08-09-16-10-20: Finished tokenizing datasets.

2023-08-09-16-10-20: Preparing data-loaders...
2023-08-09-16-10-20: Finished preparing data-loaders.

2023-08-09-16-10-20: Loading and preparing model...
2023-08-09-16-10-23: Finshed preparing model.

2023-08-09-16-10-23: Starting training...

2023-08-09-16-11-28: Training (last 300 batches): accuracy = 0.919444, f1-score = 0.937901, loss = 68.226788
2023-08-09-16-11-33: Validation (total 82 batches): accuracy = 0.968367, f1-score = 0.975762, loss = 10.563725
2023-08-09-16-11-33: Finished batch 300.

2023-08-09-16-12-37: Training (last 300 batches): accuracy = 0.968846, f1-score = 0.975320, loss = 33.206011
2023-08-09-16-12-42: Validation (total 82 batches): accuracy = 0.967347, f1-score = 0.974603, loss = 9.557792
2023-08-09-16-12-42: Finished batch 600.

2023-08-09-16-13-47: Training (last 300 batches): accuracy = 0.979694, f1-score = 0.984030, loss = 21.806284
2023-08-09-16-13-52: Validation (total 82 batches): accuracy = 0.964286, f1-score = 0.972678, loss = 9.719794
2023-08-09-16-13-52: Finished batch 900.

2023-08-09-16-14-56: Training (last 300 batches): accuracy = 0.986926, f1-score = 0.989478, loss = 14.242504
2023-08-09-16-15-01: Validation (total 82 batches): accuracy = 0.968367, f1-score = 0.975571, loss = 10.467288
2023-08-09-16-15-01: Finished batch 1200.

2023-08-09-16-16-06: Training (last 300 batches): accuracy = 0.989430, f1-score = 0.991634, loss = 11.388679
2023-08-09-16-16-11: Validation (total 82 batches): accuracy = 0.968367, f1-score = 0.975648, loss = 10.640335
2023-08-09-16-16-11: Finished batch 1500.

2023-08-09-16-17-15: Training (last 300 batches): accuracy = 0.991655, f1-score = 0.993455, loss = 8.384219
2023-08-09-16-17-20: Validation (total 82 batches): accuracy = 0.969388, f1-score = 0.976228, loss = 10.271450
2023-08-09-16-17-20: Finished batch 1800.

2023-08-09-16-18-25: Training (last 300 batches): accuracy = 0.992490, f1-score = 0.993996, loss = 6.957457
2023-08-09-16-18-30: Validation (total 82 batches): accuracy = 0.966327, f1-score = 0.973995, loss = 11.389463
2023-08-09-16-18-30: Finished batch 2100.

2023-08-09-16-19-34: Training (last 300 batches): accuracy = 0.993046, f1-score = 0.994519, loss = 5.999172
2023-08-09-16-19-39: Validation (total 82 batches): accuracy = 0.963265, f1-score = 0.971831, loss = 12.875930
2023-08-09-16-19-39: Finished batch 2400.

2023-08-09-16-20-44: Training (last 300 batches): accuracy = 0.994715, f1-score = 0.995827, loss = 4.157283
2023-08-09-16-20-49: Validation (total 82 batches): accuracy = 0.969388, f1-score = 0.976228, loss = 11.149545
2023-08-09-16-20-49: Finished batch 2700.

2023-08-09-16-21-53: Training (last 300 batches): accuracy = 0.993324, f1-score = 0.994767, loss = 5.459256
2023-08-09-16-21-58: Validation (total 82 batches): accuracy = 0.971429, f1-score = 0.977813, loss = 11.838011
2023-08-09-16-21-58: Finished batch 3000.

2023-08-09-16-22-56: Training (last 300 batches): accuracy = 0.994159, f1-score = 0.995396, loss = 4.582072
2023-08-09-16-23-01: Validation (total 82 batches): accuracy = 0.956122, f1-score = 0.966485, loss = 15.629395
2023-08-09-16-23-01: Finished batch 3270.

