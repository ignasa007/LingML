DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-10-28-16-55-15: Loading and pre-processing datasets...
2023-10-28-16-55-17: Finished pre-processing datasets.

2023-10-28-16-55-17: Tokenizing datasets...
2023-10-28-16-55-19: Finished tokenizing datasets.

2023-10-28-16-55-19: Preparing data-loaders...
2023-10-28-16-55-19: Finished preparing data-loaders.

2023-10-28-16-55-19: Loading and preparing model...
2023-10-28-16-55-23: Finshed preparing model.

2023-10-28-16-55-23: Starting training...

2023-10-28-16-57-44: Training (last 600 batches): accuracy = 0.910694, f1-score = 0.916374, loss = 126.391892
2023-10-28-16-57-57: Validation (total 179 batches): accuracy = 0.972897, f1-score = 0.974222, loss = 13.875328
2023-10-28-16-58-10: Testing (total 179 batches): accuracy = 0.971963, f1-score = 0.973381, loss = 14.179431
2023-10-28-16-58-10: Finished batch 600.

2023-10-28-17-00-31: Training (last 600 batches): accuracy = 0.982778, f1-score = 0.983515, loss = 31.017947
2023-10-28-17-00-44: Validation (total 179 batches): accuracy = 0.977570, f1-score = 0.978723, loss = 14.701226
2023-10-28-17-00-57: Testing (total 179 batches): accuracy = 0.979907, f1-score = 0.980863, loss = 13.022634
2023-10-28-17-00-57: Finished batch 1200.

2023-10-28-17-03-17: Training (last 600 batches): accuracy = 0.992361, f1-score = 0.992648, loss = 13.094070
2023-10-28-17-03-29: Validation (total 179 batches): accuracy = 0.977570, f1-score = 0.978780, loss = 14.640248
2023-10-28-17-03-42: Testing (total 179 batches): accuracy = 0.978037, f1-score = 0.979120, loss = 13.605479
2023-10-28-17-03-42: Finished batch 1800.

2023-10-28-17-06-02: Training (last 600 batches): accuracy = 0.996111, f1-score = 0.996298, loss = 6.704267
2023-10-28-17-06-15: Validation (total 179 batches): accuracy = 0.982243, f1-score = 0.983126, loss = 14.729601
2023-10-28-17-06-28: Testing (total 179 batches): accuracy = 0.982710, f1-score = 0.983519, loss = 15.977279
2023-10-28-17-06-28: Finished batch 2400.

2023-10-28-17-08-47: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997131, loss = 5.283298
2023-10-28-17-09-00: Validation (total 179 batches): accuracy = 0.980374, f1-score = 0.981432, loss = 18.699921
2023-10-28-17-09-13: Testing (total 179 batches): accuracy = 0.981308, f1-score = 0.982238, loss = 17.456511
2023-10-28-17-09-13: Finished batch 3000.

2023-10-28-17-11-33: Training (last 600 batches): accuracy = 0.997500, f1-score = 0.997592, loss = 6.375179
2023-10-28-17-11-46: Validation (total 179 batches): accuracy = 0.978972, f1-score = 0.980027, loss = 18.191458
2023-10-28-17-11-58: Testing (total 179 batches): accuracy = 0.981776, f1-score = 0.982659, loss = 15.473423
2023-10-28-17-11-58: Finished batch 3600.

2023-10-28-17-14-18: Training (last 600 batches): accuracy = 0.999583, f1-score = 0.999602, loss = 1.538608
2023-10-28-17-14-31: Validation (total 179 batches): accuracy = 0.976168, f1-score = 0.977424, loss = 23.999668
2023-10-28-17-14-44: Testing (total 179 batches): accuracy = 0.980841, f1-score = 0.981802, loss = 16.720562
2023-10-28-17-14-44: Finished batch 4200.

2023-10-28-17-17-04: Training (last 600 batches): accuracy = 0.997083, f1-score = 0.997212, loss = 7.095351
2023-10-28-17-17-17: Validation (total 179 batches): accuracy = 0.974299, f1-score = 0.975717, loss = 18.877743
2023-10-28-17-17-30: Testing (total 179 batches): accuracy = 0.980374, f1-score = 0.981366, loss = 18.239456
2023-10-28-17-17-30: Finished batch 4800.

2023-10-28-17-19-39: Training (last 600 batches): accuracy = 0.997500, f1-score = 0.997607, loss = 5.479946
2023-10-28-17-19-51: Validation (total 179 batches): accuracy = 0.978972, f1-score = 0.979973, loss = 15.217880
2023-10-28-17-20-04: Testing (total 179 batches): accuracy = 0.983178, f1-score = 0.983943, loss = 12.206177
2023-10-28-17-20-04: Finished batch 5350.

