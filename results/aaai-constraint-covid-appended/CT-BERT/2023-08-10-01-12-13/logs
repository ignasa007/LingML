DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-10-01-12-13: Loading and pre-processing datasets...
2023-08-10-01-12-14: Finished pre-processing datasets.

2023-08-10-01-12-14: Tokenizing datasets...
2023-08-10-01-12-16: Finished tokenizing datasets.

2023-08-10-01-12-16: Preparing data-loaders...
2023-08-10-01-12-16: Finished preparing data-loaders.

2023-08-10-01-12-16: Loading and preparing model...
2023-08-10-01-12-19: Finshed preparing model.

2023-08-10-01-12-19: Starting training...

2023-08-10-01-14-33: Training (last 600 batches): accuracy = 0.906806, f1-score = 0.913653, loss = 136.810904
2023-08-10-01-14-46: Validation (total 179 batches): accuracy = 0.971495, f1-score = 0.972682, loss = 13.686192
2023-08-10-01-14-46: Finished batch 600.

2023-08-10-01-17-45: Training (last 600 batches): accuracy = 0.986944, f1-score = 0.987628, loss = 25.964342
2023-08-10-01-18-04: Validation (total 179 batches): accuracy = 0.972897, f1-score = 0.974494, loss = 17.328114
2023-08-10-01-18-04: Finished batch 1200.

2023-08-10-01-21-50: Training (last 600 batches): accuracy = 0.993472, f1-score = 0.993772, loss = 12.590603
2023-08-10-01-22-12: Validation (total 179 batches): accuracy = 0.975701, f1-score = 0.976723, loss = 16.198854
2023-08-10-01-22-12: Finished batch 1800.

2023-08-10-01-26-10: Training (last 600 batches): accuracy = 0.994444, f1-score = 0.994662, loss = 11.091408
2023-08-10-01-26-33: Validation (total 179 batches): accuracy = 0.976636, f1-score = 0.977837, loss = 17.555492
2023-08-10-01-26-33: Finished batch 2400.

2023-08-10-01-30-36: Training (last 600 batches): accuracy = 0.997639, f1-score = 0.997737, loss = 4.230818
2023-08-10-01-31-00: Validation (total 179 batches): accuracy = 0.977103, f1-score = 0.978347, loss = 21.537159
2023-08-10-01-31-00: Finished batch 3000.

2023-08-10-01-34-51: Training (last 600 batches): accuracy = 0.995694, f1-score = 0.995875, loss = 8.930622
2023-08-10-01-35-14: Validation (total 179 batches): accuracy = 0.979907, f1-score = 0.980931, loss = 14.291519
2023-08-10-01-35-14: Finished batch 3600.

2023-08-10-01-38-52: Training (last 600 batches): accuracy = 0.998472, f1-score = 0.998560, loss = 3.234021
2023-08-10-01-39-11: Validation (total 179 batches): accuracy = 0.979907, f1-score = 0.980880, loss = 16.834616
2023-08-10-01-39-11: Finished batch 4200.

2023-08-10-01-42-42: Training (last 600 batches): accuracy = 0.999444, f1-score = 0.999465, loss = 1.140557
2023-08-10-01-43-02: Validation (total 179 batches): accuracy = 0.979439, f1-score = 0.980496, loss = 14.067503
2023-08-10-01-43-02: Finished batch 4800.

2023-08-10-01-46-13: Training (last 600 batches): accuracy = 0.999028, f1-score = 0.999075, loss = 2.691689
2023-08-10-01-46-31: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969856, loss = 21.889059
2023-08-10-01-46-31: Finished batch 5350.

