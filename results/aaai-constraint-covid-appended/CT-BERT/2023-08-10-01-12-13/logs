DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-10-01-12-13: Loading and pre-processing datasets...
2023-08-10-01-12-14: Finished pre-processing datasets.

2023-08-10-01-12-14: Tokenizing datasets...
2023-08-10-01-12-16: Finished tokenizing datasets.

2023-08-10-01-12-16: Preparing data-loaders...
2023-08-10-01-12-16: Finished preparing data-loaders.

2023-08-10-01-12-16: Loading and preparing model...
2023-08-10-01-12-19: Finshed preparing model.

2023-08-10-01-12-19: Starting training...

2023-08-10-01-14-33: Training (last 600 batches): accuracy = 0.906806, f1-score = 0.913653, loss = 136.810904
2023-08-10-01-14-46: Validation (total 179 batches): accuracy = 0.971495, f1-score = 0.972682, loss = 13.686192
2023-08-10-01-14-46: Finished batch 600.

2023-08-10-01-17-45: Training (last 600 batches): accuracy = 0.986944, f1-score = 0.987628, loss = 25.964342
2023-08-10-01-18-04: Validation (total 179 batches): accuracy = 0.972897, f1-score = 0.974494, loss = 17.328114
2023-08-10-01-18-04: Finished batch 1200.

