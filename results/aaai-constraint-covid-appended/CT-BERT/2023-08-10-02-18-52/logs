DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-10-02-18-52: Loading and pre-processing datasets...
2023-08-10-02-18-53: Finished pre-processing datasets.

2023-08-10-02-18-53: Tokenizing datasets...
2023-08-10-02-18-55: Finished tokenizing datasets.

2023-08-10-02-18-55: Preparing data-loaders...
2023-08-10-02-18-55: Finished preparing data-loaders.

2023-08-10-02-18-55: Loading and preparing model...
2023-08-10-02-18-59: Finshed preparing model.

2023-08-10-02-18-59: Starting training...

2023-08-10-02-22-10: Training (last 600 batches): accuracy = 0.907778, f1-score = 0.915392, loss = 130.649760
2023-08-10-02-22-27: Validation (total 179 batches): accuracy = 0.976168, f1-score = 0.977384, loss = 12.213852
2023-08-10-02-22-27: Finished batch 600.

2023-08-10-02-25-44: Training (last 600 batches): accuracy = 0.984167, f1-score = 0.985004, loss = 29.535780
2023-08-10-02-26-01: Validation (total 179 batches): accuracy = 0.978972, f1-score = 0.979938, loss = 12.827117
2023-08-10-02-26-01: Finished batch 1200.

2023-08-10-02-29-16: Training (last 600 batches): accuracy = 0.994722, f1-score = 0.994910, loss = 11.730164
2023-08-10-02-29-34: Validation (total 179 batches): accuracy = 0.979439, f1-score = 0.980479, loss = 12.387221
2023-08-10-02-29-34: Finished batch 1800.

2023-08-10-02-32-46: Training (last 600 batches): accuracy = 0.999444, f1-score = 0.999474, loss = 1.368237
2023-08-10-02-33-05: Validation (total 179 batches): accuracy = 0.983178, f1-score = 0.984028, loss = 15.539847
2023-08-10-02-33-05: Finished batch 2400.

2023-08-10-02-36-21: Training (last 600 batches): accuracy = 0.995000, f1-score = 0.995178, loss = 8.603336
2023-08-10-02-36-38: Validation (total 179 batches): accuracy = 0.969626, f1-score = 0.971578, loss = 26.655422
2023-08-10-02-36-38: Finished batch 3000.

2023-08-10-02-39-51: Training (last 600 batches): accuracy = 0.999028, f1-score = 0.999070, loss = 2.728190
2023-08-10-02-40-09: Validation (total 179 batches): accuracy = 0.977570, f1-score = 0.978742, loss = 23.243574
2023-08-10-02-40-09: Finished batch 3600.

2023-08-10-02-43-24: Training (last 600 batches): accuracy = 0.994583, f1-score = 0.994816, loss = 10.719142
2023-08-10-02-43-41: Validation (total 179 batches): accuracy = 0.978972, f1-score = 0.980150, loss = 18.813068
2023-08-10-02-43-41: Finished batch 4200.

2023-08-10-02-47-00: Training (last 600 batches): accuracy = 0.999444, f1-score = 0.999475, loss = 0.836294
2023-08-10-02-47-19: Validation (total 179 batches): accuracy = 0.977103, f1-score = 0.978037, loss = 17.525549
2023-08-10-02-47-19: Finished batch 4800.

2023-08-10-02-50-27: Training (last 600 batches): accuracy = 0.997917, f1-score = 0.998005, loss = 4.680906
2023-08-10-02-50-47: Validation (total 179 batches): accuracy = 0.975234, f1-score = 0.976286, loss = 25.327021
2023-08-10-02-50-47: Finished batch 5350.

