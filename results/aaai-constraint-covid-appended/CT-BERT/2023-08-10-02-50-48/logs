DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-10-02-50-48: Loading and pre-processing datasets...
2023-08-10-02-50-50: Finished pre-processing datasets.

2023-08-10-02-50-50: Tokenizing datasets...
2023-08-10-02-50-51: Finished tokenizing datasets.

2023-08-10-02-50-51: Preparing data-loaders...
2023-08-10-02-50-51: Finished preparing data-loaders.

2023-08-10-02-50-51: Loading and preparing model...
2023-08-10-02-50-55: Finshed preparing model.

2023-08-10-02-50-55: Starting training...

2023-08-10-02-54-19: Training (last 600 batches): accuracy = 0.907361, f1-score = 0.913410, loss = 131.393896
2023-08-10-02-54-38: Validation (total 179 batches): accuracy = 0.976168, f1-score = 0.977543, loss = 14.788278
2023-08-10-02-54-38: Finished batch 600.

2023-08-10-02-58-11: Training (last 600 batches): accuracy = 0.982500, f1-score = 0.983390, loss = 33.260282
2023-08-10-02-58-31: Validation (total 179 batches): accuracy = 0.966822, f1-score = 0.969171, loss = 20.750191
2023-08-10-02-58-31: Finished batch 1200.

2023-08-10-03-02-10: Training (last 600 batches): accuracy = 0.993194, f1-score = 0.993469, loss = 15.126793
2023-08-10-03-02-31: Validation (total 179 batches): accuracy = 0.974766, f1-score = 0.975654, loss = 15.938488
2023-08-10-03-02-31: Finished batch 1800.

2023-08-10-03-06-13: Training (last 600 batches): accuracy = 0.995000, f1-score = 0.995177, loss = 10.147933
2023-08-10-03-06-34: Validation (total 179 batches): accuracy = 0.975701, f1-score = 0.976786, loss = 14.988147
2023-08-10-03-06-34: Finished batch 2400.

2023-08-10-03-10-15: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997150, loss = 6.117886
2023-08-10-03-10-35: Validation (total 179 batches): accuracy = 0.979907, f1-score = 0.980863, loss = 14.371570
2023-08-10-03-10-35: Finished batch 3000.

2023-08-10-03-14-24: Training (last 600 batches): accuracy = 0.998889, f1-score = 0.998932, loss = 2.870278
2023-08-10-03-14-47: Validation (total 179 batches): accuracy = 0.980374, f1-score = 0.981183, loss = 17.681753
2023-08-10-03-14-47: Finished batch 3600.

2023-08-10-03-18-35: Training (last 600 batches): accuracy = 0.998056, f1-score = 0.998136, loss = 3.159137
2023-08-10-03-18-57: Validation (total 179 batches): accuracy = 0.979439, f1-score = 0.980375, loss = 20.303106
2023-08-10-03-18-57: Finished batch 4200.

2023-08-10-03-22-27: Training (last 600 batches): accuracy = 0.996389, f1-score = 0.996557, loss = 7.291483
2023-08-10-03-22-41: Validation (total 179 batches): accuracy = 0.977570, f1-score = 0.978629, loss = 15.041597
2023-08-10-03-22-41: Finished batch 4800.

2023-08-10-03-24-59: Training (last 600 batches): accuracy = 0.999167, f1-score = 0.999201, loss = 1.618970
2023-08-10-03-25-12: Validation (total 179 batches): accuracy = 0.981776, f1-score = 0.982566, loss = 19.364464
2023-08-10-03-25-12: Finished batch 5350.

