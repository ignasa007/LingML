DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-10-01-46-33: Loading and pre-processing datasets...
2023-08-10-01-46-35: Finished pre-processing datasets.

2023-08-10-01-46-35: Tokenizing datasets...
2023-08-10-01-46-36: Finished tokenizing datasets.

2023-08-10-01-46-36: Preparing data-loaders...
2023-08-10-01-46-36: Finished preparing data-loaders.

2023-08-10-01-46-36: Loading and preparing model...
2023-08-10-01-46-40: Finshed preparing model.

2023-08-10-01-46-40: Starting training...

2023-08-10-01-49-57: Training (last 600 batches): accuracy = 0.858194, f1-score = 0.869052, loss = 201.123444
2023-08-10-01-50-16: Validation (total 179 batches): accuracy = 0.952804, f1-score = 0.956745, loss = 23.935909
2023-08-10-01-50-16: Finished batch 600.

2023-08-10-01-53-38: Training (last 600 batches): accuracy = 0.968472, f1-score = 0.969745, loss = 58.087156
2023-08-10-01-53-55: Validation (total 179 batches): accuracy = 0.978037, f1-score = 0.979231, loss = 11.776708
2023-08-10-01-53-55: Finished batch 1200.

2023-08-10-01-57-15: Training (last 600 batches): accuracy = 0.989167, f1-score = 0.989772, loss = 22.805008
2023-08-10-01-57-34: Validation (total 179 batches): accuracy = 0.978505, f1-score = 0.979646, loss = 13.255419
2023-08-10-01-57-34: Finished batch 1800.

2023-08-10-02-00-54: Training (last 600 batches): accuracy = 0.989028, f1-score = 0.989507, loss = 20.893278
2023-08-10-02-01-12: Validation (total 179 batches): accuracy = 0.974299, f1-score = 0.975867, loss = 16.085571
2023-08-10-02-01-12: Finished batch 2400.

2023-08-10-02-04-31: Training (last 600 batches): accuracy = 0.995556, f1-score = 0.995760, loss = 9.487486
2023-08-10-02-04-48: Validation (total 179 batches): accuracy = 0.978505, f1-score = 0.979483, loss = 14.331373
2023-08-10-02-04-48: Finished batch 3000.

2023-08-10-02-08-06: Training (last 600 batches): accuracy = 0.998194, f1-score = 0.998292, loss = 4.583522
2023-08-10-02-08-24: Validation (total 179 batches): accuracy = 0.978505, f1-score = 0.979610, loss = 16.348982
2023-08-10-02-08-24: Finished batch 3600.

2023-08-10-02-11-42: Training (last 600 batches): accuracy = 0.998333, f1-score = 0.998406, loss = 2.617206
2023-08-10-02-12-00: Validation (total 179 batches): accuracy = 0.976636, f1-score = 0.977915, loss = 21.044392
2023-08-10-02-12-00: Finished batch 4200.

2023-08-10-02-15-18: Training (last 600 batches): accuracy = 0.995694, f1-score = 0.995865, loss = 8.684175
2023-08-10-02-15-35: Validation (total 179 batches): accuracy = 0.981776, f1-score = 0.982613, loss = 13.538714
2023-08-10-02-15-35: Finished batch 4800.

2023-08-10-02-18-32: Training (last 600 batches): accuracy = 0.996667, f1-score = 0.996816, loss = 6.579661
2023-08-10-02-18-50: Validation (total 179 batches): accuracy = 0.983178, f1-score = 0.983986, loss = 13.935958
2023-08-10-02-18-50: Finished batch 5350.

