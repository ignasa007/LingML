DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = bert-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-05-21-28-16: Loading and pre-processing datasets...
2023-09-05-21-28-17: Finished pre-processing datasets.

2023-09-05-21-28-17: Tokenizing datasets...
2023-09-05-21-28-19: Finished tokenizing datasets.

2023-09-05-21-28-19: Preparing data-loaders...
2023-09-05-21-28-19: Finished preparing data-loaders.

2023-09-05-21-28-19: Loading and preparing model...
2023-09-05-21-28-21: Finshed preparing model.

2023-09-05-21-28-21: Starting training...

2023-09-05-21-29-20: Training (last 600 batches): accuracy = 0.914444, f1-score = 0.918990, loss = 136.989804
2023-09-05-21-29-28: Validation (total 179 batches): accuracy = 0.956075, f1-score = 0.958296, loss = 22.651016
2023-09-05-21-29-28: Finished batch 600.

2023-09-05-21-30-42: Training (last 600 batches): accuracy = 0.975972, f1-score = 0.977192, loss = 45.162540
2023-09-05-21-30-51: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.966858, loss = 18.656546
2023-09-05-21-30-51: Finished batch 1200.

2023-09-05-21-32-05: Training (last 600 batches): accuracy = 0.986528, f1-score = 0.987096, loss = 24.614791
2023-09-05-21-32-11: Validation (total 179 batches): accuracy = 0.953738, f1-score = 0.957161, loss = 29.436131
2023-09-05-21-32-11: Finished batch 1800.

2023-09-05-21-33-07: Training (last 600 batches): accuracy = 0.992639, f1-score = 0.992959, loss = 14.353645
2023-09-05-21-33-12: Validation (total 179 batches): accuracy = 0.962617, f1-score = 0.964539, loss = 23.307251
2023-09-05-21-33-12: Finished batch 2400.

2023-09-05-21-34-00: Training (last 600 batches): accuracy = 0.995833, f1-score = 0.996029, loss = 9.273790
2023-09-05-21-34-05: Validation (total 179 batches): accuracy = 0.962617, f1-score = 0.964943, loss = 28.044266
2023-09-05-21-34-05: Finished batch 3000.

2023-09-05-21-34-52: Training (last 600 batches): accuracy = 0.995694, f1-score = 0.995850, loss = 8.219953
2023-09-05-21-34-56: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.969670, loss = 25.276022
2023-09-05-21-34-56: Finished batch 3600.

2023-09-05-21-35-43: Training (last 600 batches): accuracy = 0.996667, f1-score = 0.996857, loss = 6.214348
2023-09-05-21-35-47: Validation (total 179 batches): accuracy = 0.965888, f1-score = 0.967856, loss = 25.309921
2023-09-05-21-35-47: Finished batch 4200.

2023-09-05-21-36-34: Training (last 600 batches): accuracy = 0.997778, f1-score = 0.997861, loss = 3.779840
2023-09-05-21-36-38: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.966231, loss = 25.223612
2023-09-05-21-36-38: Finished batch 4800.

2023-09-05-21-37-21: Training (last 600 batches): accuracy = 0.999028, f1-score = 0.999064, loss = 1.700288
2023-09-05-21-37-25: Validation (total 179 batches): accuracy = 0.965421, f1-score = 0.967572, loss = 29.497370
2023-09-05-21-37-25: Finished batch 5350.

