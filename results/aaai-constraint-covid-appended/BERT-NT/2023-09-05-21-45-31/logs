DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = bert-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-05-21-45-31: Loading and pre-processing datasets...
2023-09-05-21-45-32: Finished pre-processing datasets.

2023-09-05-21-45-32: Tokenizing datasets...
2023-09-05-21-45-34: Finished tokenizing datasets.

2023-09-05-21-45-34: Preparing data-loaders...
2023-09-05-21-45-34: Finished preparing data-loaders.

2023-09-05-21-45-34: Loading and preparing model...
2023-09-05-21-45-36: Finshed preparing model.

2023-09-05-21-45-36: Starting training...

2023-09-05-21-46-21: Training (last 600 batches): accuracy = 0.921806, f1-score = 0.925677, loss = 122.515141
2023-09-05-21-46-25: Validation (total 179 batches): accuracy = 0.950467, f1-score = 0.954113, loss = 25.336988
2023-09-05-21-46-25: Finished batch 600.

2023-09-05-21-47-12: Training (last 600 batches): accuracy = 0.980139, f1-score = 0.981027, loss = 40.650523
2023-09-05-21-47-16: Validation (total 179 batches): accuracy = 0.964019, f1-score = 0.965823, loss = 22.405815
2023-09-05-21-47-16: Finished batch 1200.

2023-09-05-21-48-02: Training (last 600 batches): accuracy = 0.990694, f1-score = 0.991129, loss = 18.928358
2023-09-05-21-48-06: Validation (total 179 batches): accuracy = 0.960748, f1-score = 0.963319, loss = 26.984188
2023-09-05-21-48-06: Finished batch 1800.

2023-09-05-21-48-53: Training (last 600 batches): accuracy = 0.994306, f1-score = 0.994560, loss = 10.751972
2023-09-05-21-48-57: Validation (total 179 batches): accuracy = 0.955140, f1-score = 0.958692, loss = 37.590794
2023-09-05-21-48-57: Finished batch 2400.

2023-09-05-21-49-43: Training (last 600 batches): accuracy = 0.993889, f1-score = 0.994168, loss = 10.567778
2023-09-05-21-49-47: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.970070, loss = 21.328194
2023-09-05-21-49-47: Finished batch 3000.

2023-09-05-21-50-33: Training (last 600 batches): accuracy = 0.996667, f1-score = 0.996814, loss = 6.841222
2023-09-05-21-50-37: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969724, loss = 24.247772
2023-09-05-21-50-37: Finished batch 3600.

2023-09-05-21-51-22: Training (last 600 batches): accuracy = 0.999028, f1-score = 0.999068, loss = 2.368473
2023-09-05-21-51-27: Validation (total 179 batches): accuracy = 0.961215, f1-score = 0.962290, loss = 31.886457
2023-09-05-21-51-27: Finished batch 4200.

2023-09-05-21-52-12: Training (last 600 batches): accuracy = 0.998472, f1-score = 0.998542, loss = 3.279714
2023-09-05-21-52-16: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.970796, loss = 26.823877
2023-09-05-21-52-16: Finished batch 4800.

2023-09-05-21-52-58: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997097, loss = 5.806265
2023-09-05-21-53-02: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.970796, loss = 23.096182
2023-09-05-21-53-02: Finished batch 5350.

