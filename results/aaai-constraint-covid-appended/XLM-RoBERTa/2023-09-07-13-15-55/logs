DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = xlm-roberta-base
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-07-13-15-55: Loading and pre-processing datasets...
2023-09-07-13-15-57: Finished pre-processing datasets.

2023-09-07-13-15-57: Tokenizing datasets...
2023-09-07-13-16-00: Finished tokenizing datasets.

2023-09-07-13-16-00: Preparing data-loaders...
2023-09-07-13-16-00: Finished preparing data-loaders.

2023-09-07-13-16-00: Loading and preparing model...
2023-09-07-13-16-03: Finshed preparing model.

2023-09-07-13-16-03: Starting training...

2023-09-07-13-17-12: Training (last 600 batches): accuracy = 0.874167, f1-score = 0.883127, loss = 178.889966
2023-09-07-13-17-17: Validation (total 179 batches): accuracy = 0.936916, f1-score = 0.942626, loss = 31.305626
2023-09-07-13-17-17: Finished batch 600.

2023-09-07-13-18-30: Training (last 600 batches): accuracy = 0.963472, f1-score = 0.965390, loss = 69.085033
2023-09-07-13-18-35: Validation (total 179 batches): accuracy = 0.958879, f1-score = 0.961772, loss = 27.158882
2023-09-07-13-18-35: Finished batch 1200.

2023-09-07-13-19-48: Training (last 600 batches): accuracy = 0.978333, f1-score = 0.979398, loss = 36.547687
2023-09-07-13-19-53: Validation (total 179 batches): accuracy = 0.963551, f1-score = 0.966146, loss = 25.300552
2023-09-07-13-19-53: Finished batch 1800.

2023-09-07-13-21-07: Training (last 600 batches): accuracy = 0.986111, f1-score = 0.986631, loss = 25.438257
2023-09-07-13-21-12: Validation (total 179 batches): accuracy = 0.966355, f1-score = 0.968254, loss = 19.070766
2023-09-07-13-21-12: Finished batch 2400.

2023-09-07-13-22-27: Training (last 600 batches): accuracy = 0.993472, f1-score = 0.993779, loss = 11.787362
2023-09-07-13-22-33: Validation (total 179 batches): accuracy = 0.966355, f1-score = 0.968028, loss = 27.623760
2023-09-07-13-22-33: Finished batch 3000.

2023-09-07-13-23-46: Training (last 600 batches): accuracy = 0.991806, f1-score = 0.992126, loss = 14.500576
2023-09-07-13-23-52: Validation (total 179 batches): accuracy = 0.973832, f1-score = 0.975155, loss = 18.679325
2023-09-07-13-23-52: Finished batch 3600.

2023-09-07-13-25-06: Training (last 600 batches): accuracy = 0.995417, f1-score = 0.995657, loss = 9.500150
2023-09-07-13-25-12: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969829, loss = 25.142612
2023-09-07-13-25-12: Finished batch 4200.

2023-09-07-13-26-26: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997078, loss = 6.489998
2023-09-07-13-26-31: Validation (total 179 batches): accuracy = 0.932710, f1-score = 0.939496, loss = 79.470184
2023-09-07-13-26-31: Finished batch 4800.

2023-09-07-13-27-36: Training (last 600 batches): accuracy = 0.993750, f1-score = 0.994026, loss = 11.021821
2023-09-07-13-27-41: Validation (total 179 batches): accuracy = 0.961215, f1-score = 0.964085, loss = 36.311111
2023-09-07-13-27-41: Finished batch 5350.

