DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = xlm-roberta-base
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-07-12-37-25: Loading and pre-processing datasets...
2023-09-07-12-37-27: Finished pre-processing datasets.

2023-09-07-12-37-27: Tokenizing datasets...
2023-09-07-12-37-32: Finished tokenizing datasets.

2023-09-07-12-37-32: Preparing data-loaders...
2023-09-07-12-37-32: Finished preparing data-loaders.

2023-09-07-12-37-32: Loading and preparing model...
2023-09-07-12-39-33: Finshed preparing model.

2023-09-07-12-39-33: Starting training...

2023-09-07-12-40-25: Training (last 600 batches): accuracy = 0.861806, f1-score = 0.871331, loss = 189.677744
2023-09-07-12-40-29: Validation (total 179 batches): accuracy = 0.929439, f1-score = 0.929800, loss = 30.436144
2023-09-07-12-40-29: Finished batch 600.

2023-09-07-12-41-24: Training (last 600 batches): accuracy = 0.960000, f1-score = 0.962323, loss = 68.800253
2023-09-07-12-41-29: Validation (total 179 batches): accuracy = 0.954206, f1-score = 0.957759, loss = 24.306662
2023-09-07-12-41-29: Finished batch 1200.

2023-09-07-12-42-33: Training (last 600 batches): accuracy = 0.977639, f1-score = 0.978610, loss = 38.426230
2023-09-07-12-42-38: Validation (total 179 batches): accuracy = 0.945794, f1-score = 0.950638, loss = 39.569260
2023-09-07-12-42-38: Finished batch 1800.

2023-09-07-12-43-54: Training (last 600 batches): accuracy = 0.982639, f1-score = 0.983463, loss = 29.289797
2023-09-07-12-44-00: Validation (total 179 batches): accuracy = 0.962150, f1-score = 0.964613, loss = 24.030306
2023-09-07-12-44-00: Finished batch 2400.

2023-09-07-12-45-22: Training (last 600 batches): accuracy = 0.988333, f1-score = 0.988782, loss = 20.428077
2023-09-07-12-45-28: Validation (total 179 batches): accuracy = 0.957009, f1-score = 0.960345, loss = 35.705090
2023-09-07-12-45-28: Finished batch 3000.

2023-09-07-12-46-56: Training (last 600 batches): accuracy = 0.991111, f1-score = 0.991514, loss = 14.639264
2023-09-07-12-47-03: Validation (total 179 batches): accuracy = 0.971963, f1-score = 0.973707, loss = 24.572147
2023-09-07-12-47-03: Finished batch 3600.

2023-09-07-12-48-33: Training (last 600 batches): accuracy = 0.995556, f1-score = 0.995771, loss = 7.995552
2023-09-07-12-48-39: Validation (total 179 batches): accuracy = 0.973364, f1-score = 0.975011, loss = 23.788324
2023-09-07-12-48-39: Finished batch 4200.

2023-09-07-12-50-04: Training (last 600 batches): accuracy = 0.997917, f1-score = 0.998019, loss = 5.119079
2023-09-07-12-50-10: Validation (total 179 batches): accuracy = 0.975701, f1-score = 0.977052, loss = 32.292244
2023-09-07-12-50-10: Finished batch 4800.

2023-09-07-12-51-24: Training (last 600 batches): accuracy = 0.995417, f1-score = 0.995633, loss = 9.015995
2023-09-07-12-51-30: Validation (total 179 batches): accuracy = 0.972430, f1-score = 0.974134, loss = 29.403687
2023-09-07-12-51-30: Finished batch 5350.

