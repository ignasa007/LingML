DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = xlnet-base-cased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-10-28-01-05-12: Loading and pre-processing datasets...
2023-10-28-01-05-14: Finished pre-processing datasets.

2023-10-28-01-05-14: Tokenizing datasets...
2023-10-28-01-05-17: Finished tokenizing datasets.

2023-10-28-01-05-17: Preparing data-loaders...
2023-10-28-01-05-17: Finished preparing data-loaders.

2023-10-28-01-05-17: Loading and preparing model...
2023-10-28-01-05-19: Finshed preparing model.

2023-10-28-01-05-19: Starting training...

2023-10-28-01-06-16: Training (last 600 batches): accuracy = 0.900000, f1-score = 0.905710, loss = 143.281571
2023-10-28-01-06-21: Validation (total 179 batches): accuracy = 0.954673, f1-score = 0.957400, loss = 21.411175
2023-10-28-01-06-27: Testing (total 179 batches): accuracy = 0.953738, f1-score = 0.956674, loss = 24.001577
2023-10-28-01-06-27: Finished batch 600.

2023-10-28-01-07-24: Training (last 600 batches): accuracy = 0.963889, f1-score = 0.965852, loss = 58.425208
2023-10-28-01-07-30: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.967206, loss = 18.721748
2023-10-28-01-07-35: Testing (total 179 batches): accuracy = 0.959813, f1-score = 0.962413, loss = 20.717813
2023-10-28-01-07-35: Finished batch 1200.

2023-10-28-01-08-33: Training (last 600 batches): accuracy = 0.982778, f1-score = 0.983546, loss = 29.991872
2023-10-28-01-08-38: Validation (total 179 batches): accuracy = 0.959346, f1-score = 0.962125, loss = 25.970249
2023-10-28-01-08-43: Testing (total 179 batches): accuracy = 0.956542, f1-score = 0.959618, loss = 28.239252
2023-10-28-01-08-43: Finished batch 1800.

2023-10-28-01-09-40: Training (last 600 batches): accuracy = 0.987917, f1-score = 0.988503, loss = 19.875180
2023-10-28-01-09-46: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969374, loss = 20.557680
2023-10-28-01-09-51: Testing (total 179 batches): accuracy = 0.967290, f1-score = 0.968917, loss = 21.825644
2023-10-28-01-09-51: Finished batch 2400.

2023-10-28-01-10-48: Training (last 600 batches): accuracy = 0.992083, f1-score = 0.992348, loss = 13.474153
2023-10-28-01-10-53: Validation (total 179 batches): accuracy = 0.967290, f1-score = 0.969109, loss = 22.762920
2023-10-28-01-10-59: Testing (total 179 batches): accuracy = 0.962150, f1-score = 0.964396, loss = 26.700153
2023-10-28-01-10-59: Finished batch 3000.

2023-10-28-01-11-55: Training (last 600 batches): accuracy = 0.995694, f1-score = 0.995911, loss = 8.670509
2023-10-28-01-12-01: Validation (total 179 batches): accuracy = 0.972897, f1-score = 0.974268, loss = 21.291803
2023-10-28-01-12-06: Testing (total 179 batches): accuracy = 0.967757, f1-score = 0.969483, loss = 23.134628
2023-10-28-01-12-06: Finished batch 3600.

2023-10-28-01-13-02: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997085, loss = 5.963235
2023-10-28-01-13-08: Validation (total 179 batches): accuracy = 0.966822, f1-score = 0.969036, loss = 32.588345
2023-10-28-01-13-13: Testing (total 179 batches): accuracy = 0.961215, f1-score = 0.963929, loss = 40.443581
2023-10-28-01-13-13: Finished batch 4200.

2023-10-28-01-14-10: Training (last 600 batches): accuracy = 0.997500, f1-score = 0.997608, loss = 4.798883
2023-10-28-01-14-15: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.972112, loss = 25.571974
2023-10-28-01-14-20: Testing (total 179 batches): accuracy = 0.965888, f1-score = 0.967884, loss = 27.967659
2023-10-28-01-14-20: Finished batch 4800.

2023-10-28-01-15-12: Training (last 600 batches): accuracy = 0.995278, f1-score = 0.995504, loss = 8.433955
2023-10-28-01-15-17: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.970976, loss = 28.164709
2023-10-28-01-15-23: Testing (total 179 batches): accuracy = 0.968692, f1-score = 0.970575, loss = 30.833700
2023-10-28-01-15-23: Finished batch 5350.

