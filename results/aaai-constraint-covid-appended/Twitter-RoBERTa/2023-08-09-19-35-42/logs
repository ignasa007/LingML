DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-09-19-35-42: Loading and pre-processing datasets...
2023-08-09-19-35-43: Finished pre-processing datasets.

2023-08-09-19-35-43: Tokenizing datasets...
2023-08-09-19-35-46: Finished tokenizing datasets.

2023-08-09-19-35-46: Preparing data-loaders...
2023-08-09-19-35-46: Finished preparing data-loaders.

2023-08-09-19-35-46: Loading and preparing model...
2023-08-09-19-35-48: Finshed preparing model.

2023-08-09-19-35-48: Starting training...

2023-08-09-19-37-15: Training (last 600 batches): accuracy = 0.923472, f1-score = 0.927662, loss = 115.966740
2023-08-09-19-37-23: Validation (total 179 batches): accuracy = 0.938785, f1-score = 0.942870, loss = 32.908264
2023-08-09-19-37-23: Finished batch 600.

2023-08-09-19-38-51: Training (last 600 batches): accuracy = 0.976806, f1-score = 0.977825, loss = 44.519884
2023-08-09-19-38-59: Validation (total 179 batches): accuracy = 0.964486, f1-score = 0.966071, loss = 19.441313
2023-08-09-19-38-59: Finished batch 1200.

2023-08-09-19-40-27: Training (last 600 batches): accuracy = 0.983750, f1-score = 0.984468, loss = 26.806285
2023-08-09-19-40-35: Validation (total 179 batches): accuracy = 0.951869, f1-score = 0.955699, loss = 36.354019
2023-08-09-19-40-35: Finished batch 1800.

2023-08-09-19-42-03: Training (last 600 batches): accuracy = 0.992639, f1-score = 0.992966, loss = 12.249982
2023-08-09-19-42-11: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.970018, loss = 30.666855
2023-08-09-19-42-11: Finished batch 2400.

2023-08-09-19-43-39: Training (last 600 batches): accuracy = 0.994306, f1-score = 0.994617, loss = 9.254033
2023-08-09-19-43-47: Validation (total 179 batches): accuracy = 0.964019, f1-score = 0.966449, loss = 33.593754
2023-08-09-19-43-47: Finished batch 3000.

2023-08-09-19-45-15: Training (last 600 batches): accuracy = 0.995417, f1-score = 0.995590, loss = 9.042057
2023-08-09-19-45-23: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.967148, loss = 25.398909
2023-08-09-19-45-23: Finished batch 3600.

2023-08-09-19-46-51: Training (last 600 batches): accuracy = 0.995278, f1-score = 0.995498, loss = 6.894773
2023-08-09-19-46-59: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971606, loss = 25.706684
2023-08-09-19-46-59: Finished batch 4200.

2023-08-09-19-48-27: Training (last 600 batches): accuracy = 0.996806, f1-score = 0.996952, loss = 6.559217
2023-08-09-19-48-35: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.971078, loss = 37.580067
2023-08-09-19-48-35: Finished batch 4800.

2023-08-09-19-49-55: Training (last 600 batches): accuracy = 0.997778, f1-score = 0.997872, loss = 6.160040
2023-08-09-19-50-03: Validation (total 179 batches): accuracy = 0.966822, f1-score = 0.969036, loss = 24.817930
2023-08-09-19-50-03: Finished batch 5350.

