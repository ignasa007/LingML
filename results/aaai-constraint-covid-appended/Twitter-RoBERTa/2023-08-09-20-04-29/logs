DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-09-20-04-29: Loading and pre-processing datasets...
2023-08-09-20-04-31: Finished pre-processing datasets.

2023-08-09-20-04-31: Tokenizing datasets...
2023-08-09-20-04-33: Finished tokenizing datasets.

2023-08-09-20-04-33: Preparing data-loaders...
2023-08-09-20-04-33: Finished preparing data-loaders.

2023-08-09-20-04-33: Loading and preparing model...
2023-08-09-20-04-35: Finshed preparing model.

2023-08-09-20-04-35: Starting training...

2023-08-09-20-06-04: Training (last 600 batches): accuracy = 0.929028, f1-score = 0.932345, loss = 111.755495
2023-08-09-20-06-12: Validation (total 179 batches): accuracy = 0.946729, f1-score = 0.951240, loss = 29.595901
2023-08-09-20-06-12: Finished batch 600.

2023-08-09-20-07-40: Training (last 600 batches): accuracy = 0.975972, f1-score = 0.977144, loss = 44.241378
2023-08-09-20-07-48: Validation (total 179 batches): accuracy = 0.962150, f1-score = 0.964301, loss = 20.661489
2023-08-09-20-07-48: Finished batch 1200.

2023-08-09-20-09-16: Training (last 600 batches): accuracy = 0.985556, f1-score = 0.986305, loss = 26.527475
2023-08-09-20-09-24: Validation (total 179 batches): accuracy = 0.959346, f1-score = 0.962321, loss = 21.067228
2023-08-09-20-09-24: Finished batch 1800.

2023-08-09-20-10-52: Training (last 600 batches): accuracy = 0.992083, f1-score = 0.992517, loss = 14.223731
2023-08-09-20-11-00: Validation (total 179 batches): accuracy = 0.966822, f1-score = 0.968764, loss = 26.251247
2023-08-09-20-11-00: Finished batch 2400.

2023-08-09-20-12-28: Training (last 600 batches): accuracy = 0.994583, f1-score = 0.994799, loss = 10.650223
2023-08-09-20-12-36: Validation (total 179 batches): accuracy = 0.965888, f1-score = 0.967996, loss = 19.978033
2023-08-09-20-12-36: Finished batch 3000.

2023-08-09-20-14-04: Training (last 600 batches): accuracy = 0.996111, f1-score = 0.996287, loss = 7.378709
2023-08-09-20-14-12: Validation (total 179 batches): accuracy = 0.965888, f1-score = 0.967884, loss = 31.592846
2023-08-09-20-14-12: Finished batch 3600.

2023-08-09-20-15-40: Training (last 600 batches): accuracy = 0.994028, f1-score = 0.994275, loss = 10.674154
2023-08-09-20-15-48: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969563, loss = 25.889832
2023-08-09-20-15-48: Finished batch 4200.

2023-08-09-20-17-16: Training (last 600 batches): accuracy = 0.998611, f1-score = 0.998672, loss = 3.189597
2023-08-09-20-17-24: Validation (total 179 batches): accuracy = 0.963084, f1-score = 0.964842, loss = 36.732674
2023-08-09-20-17-24: Finished batch 4800.

2023-08-09-20-18-44: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997064, loss = 5.644943
2023-08-09-20-18-52: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.971913, loss = 25.944223
2023-08-09-20-18-52: Finished batch 5350.

