DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-06-03-34-02: Loading and pre-processing datasets...
2023-09-06-03-34-03: Finished pre-processing datasets.

2023-09-06-03-34-03: Tokenizing datasets...
2023-09-06-03-34-06: Finished tokenizing datasets.

2023-09-06-03-34-06: Preparing data-loaders...
2023-09-06-03-34-06: Finished preparing data-loaders.

2023-09-06-03-34-06: Loading and preparing model...
2023-09-06-03-34-08: Finshed preparing model.

2023-09-06-03-34-08: Starting training...

2023-09-06-03-34-50: Training (last 600 batches): accuracy = 0.931250, f1-score = 0.934860, loss = 112.333139
2023-09-06-03-34-54: Validation (total 179 batches): accuracy = 0.958879, f1-score = 0.960467, loss = 19.241385
2023-09-06-03-34-54: Finished batch 600.

2023-09-06-03-35-36: Training (last 600 batches): accuracy = 0.975694, f1-score = 0.976849, loss = 44.201990
2023-09-06-03-35-40: Validation (total 179 batches): accuracy = 0.958411, f1-score = 0.961186, loss = 28.115597
2023-09-06-03-35-40: Finished batch 1200.

2023-09-06-03-36-22: Training (last 600 batches): accuracy = 0.984861, f1-score = 0.985633, loss = 29.540910
2023-09-06-03-36-26: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.966917, loss = 24.478458
2023-09-06-03-36-26: Finished batch 1800.

2023-09-06-03-37-08: Training (last 600 batches): accuracy = 0.992500, f1-score = 0.992810, loss = 14.575185
2023-09-06-03-37-12: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.970719, loss = 22.593655
2023-09-06-03-37-12: Finished batch 2400.

2023-09-06-03-37-54: Training (last 600 batches): accuracy = 0.993194, f1-score = 0.993513, loss = 11.829901
2023-09-06-03-37-58: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.969831, loss = 27.505575
2023-09-06-03-37-58: Finished batch 3000.

2023-09-06-03-38-40: Training (last 600 batches): accuracy = 0.994722, f1-score = 0.994970, loss = 9.120620
2023-09-06-03-38-44: Validation (total 179 batches): accuracy = 0.967290, f1-score = 0.969244, loss = 24.543314
2023-09-06-03-38-44: Finished batch 3600.

2023-09-06-03-39-26: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997103, loss = 6.055434
2023-09-06-03-39-29: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.970848, loss = 22.658108
2023-09-06-03-39-29: Finished batch 4200.

2023-09-06-03-40-11: Training (last 600 batches): accuracy = 0.996806, f1-score = 0.996912, loss = 6.464922
2023-09-06-03-40-15: Validation (total 179 batches): accuracy = 0.949065, f1-score = 0.953359, loss = 55.314983
2023-09-06-03-40-15: Finished batch 4800.

2023-09-06-03-40-54: Training (last 600 batches): accuracy = 0.997083, f1-score = 0.997226, loss = 6.390802
2023-09-06-03-40-57: Validation (total 179 batches): accuracy = 0.958879, f1-score = 0.960073, loss = 34.055218
2023-09-06-03-40-57: Finished batch 5350.

