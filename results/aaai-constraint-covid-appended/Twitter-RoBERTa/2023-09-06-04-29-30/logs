DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-06-04-29-30: Loading and pre-processing datasets...
2023-09-06-04-29-32: Finished pre-processing datasets.

2023-09-06-04-29-32: Tokenizing datasets...
2023-09-06-04-29-34: Finished tokenizing datasets.

2023-09-06-04-29-34: Preparing data-loaders...
2023-09-06-04-29-34: Finished preparing data-loaders.

2023-09-06-04-29-34: Loading and preparing model...
2023-09-06-04-29-36: Finshed preparing model.

2023-09-06-04-29-36: Starting training...

2023-09-06-04-30-19: Training (last 600 batches): accuracy = 0.929028, f1-score = 0.933420, loss = 114.088758
2023-09-06-04-30-23: Validation (total 179 batches): accuracy = 0.960280, f1-score = 0.962670, loss = 20.711393
2023-09-06-04-30-23: Finished batch 600.

2023-09-06-04-31-04: Training (last 600 batches): accuracy = 0.973056, f1-score = 0.974264, loss = 45.402118
2023-09-06-04-31-08: Validation (total 179 batches): accuracy = 0.962617, f1-score = 0.965096, loss = 24.768175
2023-09-06-04-31-08: Finished batch 1200.

2023-09-06-04-31-50: Training (last 600 batches): accuracy = 0.986528, f1-score = 0.987099, loss = 23.148599
2023-09-06-04-31-54: Validation (total 179 batches): accuracy = 0.959813, f1-score = 0.962771, loss = 38.061619
2023-09-06-04-31-54: Finished batch 1800.

2023-09-06-04-32-36: Training (last 600 batches): accuracy = 0.991389, f1-score = 0.991795, loss = 15.281140
2023-09-06-04-32-40: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.967120, loss = 27.991545
2023-09-06-04-32-40: Finished batch 2400.

2023-09-06-04-33-22: Training (last 600 batches): accuracy = 0.995417, f1-score = 0.995682, loss = 8.639597
2023-09-06-04-33-25: Validation (total 179 batches): accuracy = 0.969626, f1-score = 0.971226, loss = 29.250933
2023-09-06-04-33-25: Finished batch 3000.

2023-09-06-04-34-07: Training (last 600 batches): accuracy = 0.994028, f1-score = 0.994254, loss = 9.148766
2023-09-06-04-34-11: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971606, loss = 20.504940
2023-09-06-04-34-11: Finished batch 3600.

2023-09-06-04-34-53: Training (last 600 batches): accuracy = 0.997361, f1-score = 0.997488, loss = 4.471329
2023-09-06-04-34-57: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971556, loss = 29.519232
2023-09-06-04-34-57: Finished batch 4200.

2023-09-06-04-35-38: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997050, loss = 5.864523
2023-09-06-04-35-42: Validation (total 179 batches): accuracy = 0.974299, f1-score = 0.975501, loss = 25.014296
2023-09-06-04-35-42: Finished batch 4800.

2023-09-06-04-36-21: Training (last 600 batches): accuracy = 0.998056, f1-score = 0.998152, loss = 4.712358
2023-09-06-04-36-24: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.972136, loss = 31.742086
2023-09-06-04-36-24: Finished batch 5350.

