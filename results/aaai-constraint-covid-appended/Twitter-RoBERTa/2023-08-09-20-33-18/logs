DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-09-20-33-18: Loading and pre-processing datasets...
2023-08-09-20-33-20: Finished pre-processing datasets.

2023-08-09-20-33-20: Tokenizing datasets...
2023-08-09-20-33-23: Finished tokenizing datasets.

2023-08-09-20-33-23: Preparing data-loaders...
2023-08-09-20-33-23: Finished preparing data-loaders.

2023-08-09-20-33-23: Loading and preparing model...
2023-08-09-20-33-25: Finshed preparing model.

2023-08-09-20-33-25: Starting training...

2023-08-09-20-34-53: Training (last 600 batches): accuracy = 0.925833, f1-score = 0.929866, loss = 118.886839
2023-08-09-20-35-01: Validation (total 179 batches): accuracy = 0.951402, f1-score = 0.955250, loss = 28.601534
2023-08-09-20-35-01: Finished batch 600.

2023-08-09-20-36-29: Training (last 600 batches): accuracy = 0.972222, f1-score = 0.973468, loss = 47.682145
2023-08-09-20-36-37: Validation (total 179 batches): accuracy = 0.960748, f1-score = 0.962433, loss = 18.825542
2023-08-09-20-36-37: Finished batch 1200.

2023-08-09-20-38-05: Training (last 600 batches): accuracy = 0.985000, f1-score = 0.985515, loss = 26.601639
2023-08-09-20-38-13: Validation (total 179 batches): accuracy = 0.961215, f1-score = 0.964054, loss = 27.137817
2023-08-09-20-38-13: Finished batch 1800.

2023-08-09-20-39-41: Training (last 600 batches): accuracy = 0.992639, f1-score = 0.992990, loss = 13.534093
2023-08-09-20-39-49: Validation (total 179 batches): accuracy = 0.971495, f1-score = 0.973021, loss = 23.874413
2023-08-09-20-39-49: Finished batch 2400.

2023-08-09-20-41-16: Training (last 600 batches): accuracy = 0.994861, f1-score = 0.995125, loss = 7.692707
2023-08-09-20-41-24: Validation (total 179 batches): accuracy = 0.971028, f1-score = 0.972639, loss = 31.636244
2023-08-09-20-41-24: Finished batch 3000.

2023-08-09-20-42-52: Training (last 600 batches): accuracy = 0.997639, f1-score = 0.997737, loss = 6.281559
2023-08-09-20-43-00: Validation (total 179 batches): accuracy = 0.972430, f1-score = 0.973672, loss = 29.600859
2023-08-09-20-43-00: Finished batch 3600.

2023-08-09-20-44-28: Training (last 600 batches): accuracy = 0.993750, f1-score = 0.994092, loss = 10.407522
2023-08-09-20-44-36: Validation (total 179 batches): accuracy = 0.958879, f1-score = 0.961839, loss = 37.028015
2023-08-09-20-44-36: Finished batch 4200.

2023-08-09-20-46-04: Training (last 600 batches): accuracy = 0.998056, f1-score = 0.998132, loss = 5.694466
2023-08-09-20-46-12: Validation (total 179 batches): accuracy = 0.966355, f1-score = 0.968338, loss = 31.801466
2023-08-09-20-46-12: Finished batch 4800.

2023-08-09-20-47-33: Training (last 600 batches): accuracy = 0.997361, f1-score = 0.997466, loss = 3.895108
2023-08-09-20-47-41: Validation (total 179 batches): accuracy = 0.969626, f1-score = 0.970865, loss = 26.460129
2023-08-09-20-47-41: Finished batch 5350.

