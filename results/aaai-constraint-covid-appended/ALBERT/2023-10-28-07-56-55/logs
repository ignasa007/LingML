DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = albert-base-v2
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-10-28-07-56-55: Loading and pre-processing datasets...
2023-10-28-07-56-57: Finished pre-processing datasets.

2023-10-28-07-56-57: Tokenizing datasets...
2023-10-28-07-57-01: Finished tokenizing datasets.

2023-10-28-07-57-01: Preparing data-loaders...
2023-10-28-07-57-01: Finished preparing data-loaders.

2023-10-28-07-57-01: Loading and preparing model...
2023-10-28-07-57-02: Finshed preparing model.

2023-10-28-07-57-02: Starting training...

2023-10-28-07-57-47: Training (last 600 batches): accuracy = 0.922222, f1-score = 0.927064, loss = 123.819420
2023-10-28-07-57-52: Validation (total 179 batches): accuracy = 0.943458, f1-score = 0.948091, loss = 31.880590
2023-10-28-07-57-57: Testing (total 179 batches): accuracy = 0.945327, f1-score = 0.949677, loss = 29.023926
2023-10-28-07-57-57: Finished batch 600.

2023-10-28-07-58-43: Training (last 600 batches): accuracy = 0.971806, f1-score = 0.972944, loss = 50.566499
2023-10-28-07-58-48: Validation (total 179 batches): accuracy = 0.961215, f1-score = 0.963581, loss = 21.339144
2023-10-28-07-58-53: Testing (total 179 batches): accuracy = 0.965888, f1-score = 0.967770, loss = 19.256142
2023-10-28-07-58-53: Finished batch 1200.

2023-10-28-07-59-40: Training (last 600 batches): accuracy = 0.980278, f1-score = 0.981306, loss = 32.641561
2023-10-28-07-59-45: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969724, loss = 19.231337
2023-10-28-07-59-49: Testing (total 179 batches): accuracy = 0.968692, f1-score = 0.970524, loss = 16.471741
2023-10-28-07-59-49: Finished batch 1800.

2023-10-28-08-00-36: Training (last 600 batches): accuracy = 0.989306, f1-score = 0.989792, loss = 19.814230
2023-10-28-08-00-41: Validation (total 179 batches): accuracy = 0.963551, f1-score = 0.965147, loss = 21.614975
2023-10-28-08-00-46: Testing (total 179 batches): accuracy = 0.972430, f1-score = 0.973649, loss = 16.639256
2023-10-28-08-00-46: Finished batch 2400.

2023-10-28-08-01-32: Training (last 600 batches): accuracy = 0.994306, f1-score = 0.994596, loss = 11.673625
2023-10-28-08-01-37: Validation (total 179 batches): accuracy = 0.972430, f1-score = 0.973625, loss = 18.947399
2023-10-28-08-01-42: Testing (total 179 batches): accuracy = 0.971963, f1-score = 0.973046, loss = 17.438171
2023-10-28-08-01-42: Finished batch 3000.

2023-10-28-08-02-27: Training (last 600 batches): accuracy = 0.994722, f1-score = 0.994910, loss = 10.629855
2023-10-28-08-02-32: Validation (total 179 batches): accuracy = 0.962150, f1-score = 0.963628, loss = 18.109539
2023-10-28-08-02-37: Testing (total 179 batches): accuracy = 0.965421, f1-score = 0.966876, loss = 17.152069
2023-10-28-08-02-37: Finished batch 3600.

2023-10-28-08-03-23: Training (last 600 batches): accuracy = 0.994028, f1-score = 0.994338, loss = 12.718334
2023-10-28-08-03-28: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971656, loss = 20.517944
2023-10-28-08-03-33: Testing (total 179 batches): accuracy = 0.970093, f1-score = 0.971556, loss = 18.825829
2023-10-28-08-03-33: Finished batch 4200.

2023-10-28-08-04-18: Training (last 600 batches): accuracy = 0.995972, f1-score = 0.996136, loss = 7.057768
2023-10-28-08-04-23: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.966975, loss = 27.531979
2023-10-28-08-04-28: Testing (total 179 batches): accuracy = 0.971028, f1-score = 0.972591, loss = 21.107719
2023-10-28-08-04-28: Finished batch 4800.

2023-10-28-08-05-10: Training (last 600 batches): accuracy = 0.995694, f1-score = 0.995910, loss = 7.133704
2023-10-28-08-05-14: Validation (total 179 batches): accuracy = 0.968692, f1-score = 0.970806, loss = 30.460878
2023-10-28-08-05-19: Testing (total 179 batches): accuracy = 0.967757, f1-score = 0.969697, loss = 26.569546
2023-10-28-08-05-19: Finished batch 5350.

