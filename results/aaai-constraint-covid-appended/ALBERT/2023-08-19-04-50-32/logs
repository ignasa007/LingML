DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = albert-base-v2
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-19-04-50-32: Loading and pre-processing datasets...
2023-08-19-04-50-34: Finished pre-processing datasets.

2023-08-19-04-50-34: Tokenizing datasets...
2023-08-19-04-50-36: Finished tokenizing datasets.

2023-08-19-04-50-36: Preparing data-loaders...
2023-08-19-04-50-36: Finished preparing data-loaders.

2023-08-19-04-50-36: Loading and preparing model...
2023-08-19-04-50-38: Finshed preparing model.

2023-08-19-04-50-38: Starting training...

2023-08-19-04-51-20: Training (last 600 batches): accuracy = 0.910139, f1-score = 0.915634, loss = 136.416058
2023-08-19-04-51-25: Validation (total 179 batches): accuracy = 0.943925, f1-score = 0.946996, loss = 27.073906
2023-08-19-04-51-25: Finished batch 600.

2023-08-19-04-52-07: Training (last 600 batches): accuracy = 0.966667, f1-score = 0.968271, loss = 58.473473
2023-08-19-04-52-11: Validation (total 179 batches): accuracy = 0.966355, f1-score = 0.968531, loss = 19.801231
2023-08-19-04-52-11: Finished batch 1200.

2023-08-19-04-52-53: Training (last 600 batches): accuracy = 0.982083, f1-score = 0.983069, loss = 35.502899
2023-08-19-04-52-58: Validation (total 179 batches): accuracy = 0.936916, f1-score = 0.937238, loss = 31.392168
2023-08-19-04-52-58: Finished batch 1800.

2023-08-19-04-53-39: Training (last 600 batches): accuracy = 0.986389, f1-score = 0.986891, loss = 24.201182
2023-08-19-04-53-44: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.972185, loss = 20.057884
2023-08-19-04-53-44: Finished batch 2400.

2023-08-19-04-54-26: Training (last 600 batches): accuracy = 0.990417, f1-score = 0.990852, loss = 16.578647
2023-08-19-04-54-30: Validation (total 179 batches): accuracy = 0.968692, f1-score = 0.970498, loss = 22.875742
2023-08-19-04-54-30: Finished batch 3000.

2023-08-19-04-55-12: Training (last 600 batches): accuracy = 0.995139, f1-score = 0.995392, loss = 9.132277
2023-08-19-04-55-17: Validation (total 179 batches): accuracy = 0.960748, f1-score = 0.963478, loss = 32.053318
2023-08-19-04-55-17: Finished batch 3600.

2023-08-19-04-55-59: Training (last 600 batches): accuracy = 0.992361, f1-score = 0.992666, loss = 14.431908
2023-08-19-04-56-03: Validation (total 179 batches): accuracy = 0.965888, f1-score = 0.968025, loss = 27.098217
2023-08-19-04-56-03: Finished batch 4200.

2023-08-19-04-56-45: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997064, loss = 6.173326
2023-08-19-04-56-49: Validation (total 179 batches): accuracy = 0.942523, f1-score = 0.943396, loss = 32.979954
2023-08-19-04-56-49: Finished batch 4800.

2023-08-19-04-57-28: Training (last 600 batches): accuracy = 0.991528, f1-score = 0.991892, loss = 13.842436
2023-08-19-04-57-32: Validation (total 179 batches): accuracy = 0.960748, f1-score = 0.963222, loss = 27.305077
2023-08-19-04-57-32: Finished batch 5350.

