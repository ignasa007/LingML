DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = bertweet-covid19-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-10-29-09-23-42: Loading and pre-processing datasets...
2023-10-29-09-23-43: Finished pre-processing datasets.

2023-10-29-09-23-43: Tokenizing datasets...
2023-10-29-09-23-47: Finished tokenizing datasets.

2023-10-29-09-23-47: Preparing data-loaders...
2023-10-29-09-23-47: Finished preparing data-loaders.

2023-10-29-09-23-47: Loading and preparing model...
2023-10-29-09-23-49: Finshed preparing model.

2023-10-29-09-23-49: Starting training...

2023-10-29-09-24-36: Training (last 600 batches): accuracy = 0.902778, f1-score = 0.909020, loss = 144.343584
2023-10-29-09-24-40: Validation (total 179 batches): accuracy = 0.957477, f1-score = 0.958991, loss = 22.197998
2023-10-29-09-24-44: Testing (total 179 batches): accuracy = 0.957944, f1-score = 0.959532, loss = 21.419708
2023-10-29-09-24-44: Finished batch 600.

2023-10-29-09-25-32: Training (last 600 batches): accuracy = 0.974028, f1-score = 0.975320, loss = 49.617554
2023-10-29-09-25-36: Validation (total 179 batches): accuracy = 0.965421, f1-score = 0.967686, loss = 23.833853
2023-10-29-09-25-40: Testing (total 179 batches): accuracy = 0.965421, f1-score = 0.967686, loss = 22.677540
2023-10-29-09-25-40: Finished batch 1200.

2023-10-29-09-26-28: Training (last 600 batches): accuracy = 0.985139, f1-score = 0.985796, loss = 28.709527
2023-10-29-09-26-32: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.970719, loss = 19.967659
2023-10-29-09-26-36: Testing (total 179 batches): accuracy = 0.974299, f1-score = 0.975610, loss = 15.560780
2023-10-29-09-26-36: Finished batch 1800.

2023-10-29-09-27-24: Training (last 600 batches): accuracy = 0.990139, f1-score = 0.990654, loss = 20.282873
2023-10-29-09-27-28: Validation (total 179 batches): accuracy = 0.968692, f1-score = 0.970419, loss = 22.286453
2023-10-29-09-27-32: Testing (total 179 batches): accuracy = 0.971028, f1-score = 0.972639, loss = 18.812038
2023-10-29-09-27-32: Finished batch 2400.

2023-10-29-09-28-19: Training (last 600 batches): accuracy = 0.993889, f1-score = 0.994191, loss = 13.630019
2023-10-29-09-28-24: Validation (total 179 batches): accuracy = 0.951869, f1-score = 0.955851, loss = 38.051224
2023-10-29-09-28-28: Testing (total 179 batches): accuracy = 0.948131, f1-score = 0.952544, loss = 37.094532
2023-10-29-09-28-28: Finished batch 3000.

2023-10-29-09-29-15: Training (last 600 batches): accuracy = 0.993194, f1-score = 0.993436, loss = 12.468882
2023-10-29-09-29-19: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971656, loss = 22.082308
2023-10-29-09-29-23: Testing (total 179 batches): accuracy = 0.975234, f1-score = 0.976455, loss = 16.741238
2023-10-29-09-29-23: Finished batch 3600.

2023-10-29-09-30-10: Training (last 600 batches): accuracy = 0.996667, f1-score = 0.996820, loss = 7.382473
2023-10-29-09-30-14: Validation (total 179 batches): accuracy = 0.964486, f1-score = 0.965950, loss = 29.371571
2023-10-29-09-30-18: Testing (total 179 batches): accuracy = 0.969626, f1-score = 0.970865, loss = 23.155867
2023-10-29-09-30-18: Finished batch 4200.

2023-10-29-09-31-05: Training (last 600 batches): accuracy = 0.998194, f1-score = 0.998286, loss = 4.200226
2023-10-29-09-31-10: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969374, loss = 30.804102
2023-10-29-09-31-14: Testing (total 179 batches): accuracy = 0.973832, f1-score = 0.975177, loss = 22.510759
2023-10-29-09-31-14: Finished batch 4800.

2023-10-29-09-31-57: Training (last 600 batches): accuracy = 0.996528, f1-score = 0.996684, loss = 7.304078
2023-10-29-09-32-01: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969670, loss = 26.716900
2023-10-29-09-32-05: Testing (total 179 batches): accuracy = 0.966822, f1-score = 0.968873, loss = 23.820759
2023-10-29-09-32-05: Finished batch 5350.

