DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = bertweet-covid19-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-10-27-11-25-50: Loading and pre-processing datasets...
2023-10-27-11-25-52: Finished pre-processing datasets.

2023-10-27-11-25-52: Tokenizing datasets...
2023-10-27-11-25-55: Finished tokenizing datasets.

2023-10-27-11-25-55: Preparing data-loaders...
2023-10-27-11-25-55: Finished preparing data-loaders.

2023-10-27-11-25-55: Loading and preparing model...
2023-10-27-11-25-57: Finshed preparing model.

2023-10-27-11-25-57: Starting training...

2023-10-27-11-26-44: Training (last 600 batches): accuracy = 0.905833, f1-score = 0.912222, loss = 140.211728
2023-10-27-11-26-48: Validation (total 179 batches): accuracy = 0.922430, f1-score = 0.930833, loss = 40.697765
2023-10-27-11-26-53: Testing (total 179 batches): accuracy = 0.923364, f1-score = 0.931381, loss = 39.483845
2023-10-27-11-26-53: Finished batch 600.

2023-10-27-11-27-40: Training (last 600 batches): accuracy = 0.969444, f1-score = 0.971174, loss = 52.439657
2023-10-27-11-27-44: Validation (total 179 batches): accuracy = 0.964019, f1-score = 0.965362, loss = 19.263031
2023-10-27-11-27-48: Testing (total 179 batches): accuracy = 0.967290, f1-score = 0.968412, loss = 18.013031
2023-10-27-11-27-48: Finished batch 1200.

2023-10-27-11-28-35: Training (last 600 batches): accuracy = 0.985972, f1-score = 0.986607, loss = 25.662046
2023-10-27-11-28-40: Validation (total 179 batches): accuracy = 0.965421, f1-score = 0.966637, loss = 21.469988
2023-10-27-11-28-44: Testing (total 179 batches): accuracy = 0.963551, f1-score = 0.964674, loss = 20.597803
2023-10-27-11-28-44: Finished batch 1800.

2023-10-27-11-29-31: Training (last 600 batches): accuracy = 0.988889, f1-score = 0.989435, loss = 20.351506
2023-10-27-11-29-35: Validation (total 179 batches): accuracy = 0.967290, f1-score = 0.969136, loss = 19.929293
2023-10-27-11-29-39: Testing (total 179 batches): accuracy = 0.971963, f1-score = 0.973381, loss = 17.238449
2023-10-27-11-29-39: Finished batch 2400.

2023-10-27-11-30-26: Training (last 600 batches): accuracy = 0.993056, f1-score = 0.993317, loss = 12.304723
2023-10-27-11-30-31: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.967062, loss = 29.575693
2023-10-27-11-30-35: Testing (total 179 batches): accuracy = 0.966355, f1-score = 0.968226, loss = 24.083654
2023-10-27-11-30-35: Finished batch 3000.

2023-10-27-11-31-22: Training (last 600 batches): accuracy = 0.995972, f1-score = 0.996167, loss = 8.734297
2023-10-27-11-31-26: Validation (total 179 batches): accuracy = 0.962150, f1-score = 0.963693, loss = 25.422628
2023-10-27-11-31-30: Testing (total 179 batches): accuracy = 0.969626, f1-score = 0.970681, loss = 20.979778
2023-10-27-11-31-30: Finished batch 3600.

2023-10-27-11-32-17: Training (last 600 batches): accuracy = 0.996389, f1-score = 0.996515, loss = 6.370243
2023-10-27-11-32-22: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.966292, loss = 27.553514
2023-10-27-11-32-26: Testing (total 179 batches): accuracy = 0.962617, f1-score = 0.963801, loss = 26.764359
2023-10-27-11-32-26: Finished batch 4200.

2023-10-27-11-33-13: Training (last 600 batches): accuracy = 0.994444, f1-score = 0.994724, loss = 11.456346
2023-10-27-11-33-17: Validation (total 179 batches): accuracy = 0.959813, f1-score = 0.962835, loss = 27.856997
2023-10-27-11-33-21: Testing (total 179 batches): accuracy = 0.956542, f1-score = 0.959792, loss = 28.877226
2023-10-27-11-33-21: Finished batch 4800.

2023-10-27-11-34-04: Training (last 600 batches): accuracy = 0.997639, f1-score = 0.997758, loss = 6.569308
2023-10-27-11-34-09: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969128, loss = 31.757971
2023-10-27-11-34-13: Testing (total 179 batches): accuracy = 0.965888, f1-score = 0.967161, loss = 32.200001
2023-10-27-11-34-13: Finished batch 5350.

