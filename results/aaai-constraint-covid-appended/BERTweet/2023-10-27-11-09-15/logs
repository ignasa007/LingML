DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = bertweet-covid19-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-10-27-11-09-15: Loading and pre-processing datasets...
2023-10-27-11-09-16: Finished pre-processing datasets.

2023-10-27-11-09-16: Tokenizing datasets...
2023-10-27-11-09-20: Finished tokenizing datasets.

2023-10-27-11-09-20: Preparing data-loaders...
2023-10-27-11-09-20: Finished preparing data-loaders.

2023-10-27-11-09-20: Loading and preparing model...
2023-10-27-11-09-26: Finshed preparing model.

2023-10-27-11-09-26: Starting training...

2023-10-27-11-10-12: Training (last 600 batches): accuracy = 0.909722, f1-score = 0.915099, loss = 141.119578
2023-10-27-11-10-15: Validation (total 179 batches): accuracy = 0.952804, f1-score = 0.954931, loss = 25.333290
2023-10-27-11-10-19: Testing (total 179 batches): accuracy = 0.958411, f1-score = 0.960108, loss = 22.603859
2023-10-27-11-10-19: Finished batch 600.

2023-10-27-11-11-02: Training (last 600 batches): accuracy = 0.972639, f1-score = 0.974116, loss = 52.020108
2023-10-27-11-11-06: Validation (total 179 batches): accuracy = 0.964486, f1-score = 0.966549, loss = 21.158493
2023-10-27-11-11-10: Testing (total 179 batches): accuracy = 0.970093, f1-score = 0.971681, loss = 17.372444
2023-10-27-11-11-10: Finished batch 1200.

2023-10-27-11-11-54: Training (last 600 batches): accuracy = 0.985417, f1-score = 0.986113, loss = 29.681698
2023-10-27-11-11-58: Validation (total 179 batches): accuracy = 0.967290, f1-score = 0.968610, loss = 21.793730
2023-10-27-11-12-02: Testing (total 179 batches): accuracy = 0.970561, f1-score = 0.971660, loss = 19.578991
2023-10-27-11-12-02: Finished batch 1800.

2023-10-27-11-12-47: Training (last 600 batches): accuracy = 0.990139, f1-score = 0.990562, loss = 21.962924
2023-10-27-11-12-51: Validation (total 179 batches): accuracy = 0.963551, f1-score = 0.965819, loss = 21.680525
2023-10-27-11-12-55: Testing (total 179 batches): accuracy = 0.968692, f1-score = 0.970419, loss = 18.105928
2023-10-27-11-12-55: Finished batch 2400.

2023-10-27-11-13-41: Training (last 600 batches): accuracy = 0.991528, f1-score = 0.991874, loss = 16.486595
2023-10-27-11-13-45: Validation (total 179 batches): accuracy = 0.963551, f1-score = 0.966087, loss = 26.765438
2023-10-27-11-13-49: Testing (total 179 batches): accuracy = 0.964953, f1-score = 0.967292, loss = 26.500441
2023-10-27-11-13-49: Finished batch 3000.

2023-10-27-11-14-36: Training (last 600 batches): accuracy = 0.995139, f1-score = 0.995395, loss = 10.491640
2023-10-27-11-14-40: Validation (total 179 batches): accuracy = 0.962617, f1-score = 0.964758, loss = 25.157780
2023-10-27-11-14-44: Testing (total 179 batches): accuracy = 0.968692, f1-score = 0.970419, loss = 21.192316
2023-10-27-11-14-44: Finished batch 3600.

2023-10-27-11-15-30: Training (last 600 batches): accuracy = 0.998194, f1-score = 0.998273, loss = 6.654039
2023-10-27-11-15-34: Validation (total 179 batches): accuracy = 0.965421, f1-score = 0.966994, loss = 28.534372
2023-10-27-11-15-38: Testing (total 179 batches): accuracy = 0.972430, f1-score = 0.973578, loss = 23.374260
2023-10-27-11-15-38: Finished batch 4200.

2023-10-27-11-16-25: Training (last 600 batches): accuracy = 0.995972, f1-score = 0.996150, loss = 8.553713
2023-10-27-11-16-29: Validation (total 179 batches): accuracy = 0.966822, f1-score = 0.968458, loss = 27.073519
2023-10-27-11-16-33: Testing (total 179 batches): accuracy = 0.971495, f1-score = 0.972877, loss = 23.565996
2023-10-27-11-16-33: Finished batch 4800.

2023-10-27-11-17-15: Training (last 600 batches): accuracy = 0.997361, f1-score = 0.997470, loss = 6.457352
2023-10-27-11-17-20: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.967148, loss = 30.731159
2023-10-27-11-17-24: Testing (total 179 batches): accuracy = 0.969159, f1-score = 0.971002, loss = 27.138939
2023-10-27-11-17-24: Finished batch 5350.

