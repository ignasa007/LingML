DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = distilbert-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-19-03-46-20: Loading and pre-processing datasets...
2023-08-19-03-46-21: Finished pre-processing datasets.

2023-08-19-03-46-21: Tokenizing datasets...
2023-08-19-03-46-23: Finished tokenizing datasets.

2023-08-19-03-46-23: Preparing data-loaders...
2023-08-19-03-46-23: Finished preparing data-loaders.

2023-08-19-03-46-23: Loading and preparing model...
2023-08-19-03-46-25: Finshed preparing model.

2023-08-19-03-46-25: Starting training...

2023-08-19-03-46-59: Training (last 600 batches): accuracy = 0.920833, f1-score = 0.925354, loss = 128.318387
2023-08-19-03-47-03: Validation (total 179 batches): accuracy = 0.962150, f1-score = 0.964333, loss = 18.881840
2023-08-19-03-47-03: Finished batch 600.

2023-08-19-03-47-41: Training (last 600 batches): accuracy = 0.976528, f1-score = 0.977524, loss = 39.901421
2023-08-19-03-47-45: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971831, loss = 19.954247
2023-08-19-03-47-45: Finished batch 1200.

2023-08-19-03-48-23: Training (last 600 batches): accuracy = 0.987500, f1-score = 0.988180, loss = 22.342712
2023-08-19-03-48-27: Validation (total 179 batches): accuracy = 0.959813, f1-score = 0.962609, loss = 24.953079
2023-08-19-03-48-27: Finished batch 1800.

2023-08-19-03-49-04: Training (last 600 batches): accuracy = 0.994167, f1-score = 0.994350, loss = 11.559969
2023-08-19-03-49-08: Validation (total 179 batches): accuracy = 0.963551, f1-score = 0.965608, loss = 24.031977
2023-08-19-03-49-08: Finished batch 2400.

2023-08-19-03-49-46: Training (last 600 batches): accuracy = 0.994583, f1-score = 0.994826, loss = 9.068572
2023-08-19-03-49-50: Validation (total 179 batches): accuracy = 0.968692, f1-score = 0.970262, loss = 23.551479
2023-08-19-03-49-50: Finished batch 3000.

2023-08-19-03-50-29: Training (last 600 batches): accuracy = 0.997222, f1-score = 0.997368, loss = 5.652429
2023-08-19-03-50-33: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971731, loss = 24.752148
2023-08-19-03-50-33: Finished batch 3600.

2023-08-19-03-51-12: Training (last 600 batches): accuracy = 0.996806, f1-score = 0.996947, loss = 5.644111
2023-08-19-03-51-17: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.970745, loss = 23.525219
2023-08-19-03-51-17: Finished batch 4200.

2023-08-19-03-51-56: Training (last 600 batches): accuracy = 0.997917, f1-score = 0.998006, loss = 5.072120
2023-08-19-03-52-00: Validation (total 179 batches): accuracy = 0.973832, f1-score = 0.975045, loss = 24.891300
2023-08-19-03-52-00: Finished batch 4800.

2023-08-19-03-52-36: Training (last 600 batches): accuracy = 0.999861, f1-score = 0.999868, loss = 0.381963
2023-08-19-03-52-40: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.971787, loss = 27.412754
2023-08-19-03-52-40: Finished batch 5350.

