DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-10-05-20-46: Loading and pre-processing datasets...
2023-08-10-05-20-48: Finished pre-processing datasets.

2023-08-10-05-20-48: Tokenizing datasets...
2023-08-10-05-20-50: Finished tokenizing datasets.

2023-08-10-05-20-50: Preparing data-loaders...
2023-08-10-05-20-50: Finished preparing data-loaders.

2023-08-10-05-20-50: Loading and preparing model...
2023-08-10-05-20-53: Finshed preparing model.

2023-08-10-05-20-53: Starting training...

2023-08-10-05-23-14: Training (last 600 batches): accuracy = 0.909444, f1-score = 0.915566, loss = 134.494504
2023-08-10-05-23-27: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.970745, loss = 18.571283
2023-08-10-05-23-27: Finished batch 600.

2023-08-10-05-25-49: Training (last 600 batches): accuracy = 0.985694, f1-score = 0.986330, loss = 28.596572
2023-08-10-05-26-02: Validation (total 179 batches): accuracy = 0.973832, f1-score = 0.975243, loss = 16.989710
2023-08-10-05-26-02: Finished batch 1200.

2023-08-10-05-28-23: Training (last 600 batches): accuracy = 0.994861, f1-score = 0.995101, loss = 12.785183
2023-08-10-05-28-35: Validation (total 179 batches): accuracy = 0.974299, f1-score = 0.975566, loss = 16.266495
2023-08-10-05-28-35: Finished batch 1800.

2023-08-10-05-30-56: Training (last 600 batches): accuracy = 0.994861, f1-score = 0.995058, loss = 11.104961
2023-08-10-05-31-09: Validation (total 179 batches): accuracy = 0.973364, f1-score = 0.974901, loss = 21.827047
2023-08-10-05-31-09: Finished batch 2400.

2023-08-10-05-33-30: Training (last 600 batches): accuracy = 0.996111, f1-score = 0.996303, loss = 7.726247
2023-08-10-05-33-43: Validation (total 179 batches): accuracy = 0.971495, f1-score = 0.973068, loss = 22.039579
2023-08-10-05-33-43: Finished batch 3000.

2023-08-10-05-36-03: Training (last 600 batches): accuracy = 0.997778, f1-score = 0.997901, loss = 5.102995
2023-08-10-05-36-16: Validation (total 179 batches): accuracy = 0.977103, f1-score = 0.978154, loss = 19.214485
2023-08-10-05-36-16: Finished batch 3600.

2023-08-10-05-38-37: Training (last 600 batches): accuracy = 0.998056, f1-score = 0.998129, loss = 3.640289
2023-08-10-05-38-50: Validation (total 179 batches): accuracy = 0.975234, f1-score = 0.976518, loss = 20.345201
2023-08-10-05-38-50: Finished batch 4200.

2023-08-10-05-41-11: Training (last 600 batches): accuracy = 0.997778, f1-score = 0.997879, loss = 6.016058
2023-08-10-05-41-24: Validation (total 179 batches): accuracy = 0.978037, f1-score = 0.978990, loss = 16.806055
2023-08-10-05-41-24: Finished batch 4800.

2023-08-10-05-43-33: Training (last 600 batches): accuracy = 0.997639, f1-score = 0.997734, loss = 5.090372
2023-08-10-05-43-46: Validation (total 179 batches): accuracy = 0.976636, f1-score = 0.977837, loss = 19.340235
2023-08-10-05-43-46: Finished batch 5350.

