DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-10-04-57-54: Loading and pre-processing datasets...
2023-08-10-04-57-55: Finished pre-processing datasets.

2023-08-10-04-57-55: Tokenizing datasets...
2023-08-10-04-57-57: Finished tokenizing datasets.

2023-08-10-04-57-57: Preparing data-loaders...
2023-08-10-04-57-57: Finished preparing data-loaders.

2023-08-10-04-57-57: Loading and preparing model...
2023-08-10-04-58-01: Finshed preparing model.

2023-08-10-04-58-01: Starting training...

2023-08-10-05-00-21: Training (last 600 batches): accuracy = 0.917361, f1-score = 0.922090, loss = 127.801045
2023-08-10-05-00-34: Validation (total 179 batches): accuracy = 0.969626, f1-score = 0.971429, loss = 16.885466
2023-08-10-05-00-34: Finished batch 600.

2023-08-10-05-02-55: Training (last 600 batches): accuracy = 0.986667, f1-score = 0.987114, loss = 28.562167
2023-08-10-05-03-08: Validation (total 179 batches): accuracy = 0.969626, f1-score = 0.971479, loss = 20.769791
2023-08-10-05-03-08: Finished batch 1200.

2023-08-10-05-05-28: Training (last 600 batches): accuracy = 0.992083, f1-score = 0.992445, loss = 16.252742
2023-08-10-05-05-41: Validation (total 179 batches): accuracy = 0.973364, f1-score = 0.974723, loss = 19.044617
2023-08-10-05-05-41: Finished batch 1800.

2023-08-10-05-08-01: Training (last 600 batches): accuracy = 0.994444, f1-score = 0.994747, loss = 10.848582
2023-08-10-05-08-14: Validation (total 179 batches): accuracy = 0.971495, f1-score = 0.973045, loss = 19.931253
2023-08-10-05-08-14: Finished batch 2400.

2023-08-10-05-10-33: Training (last 600 batches): accuracy = 0.996667, f1-score = 0.996791, loss = 8.616676
2023-08-10-05-10-46: Validation (total 179 batches): accuracy = 0.971963, f1-score = 0.973381, loss = 20.300713
2023-08-10-05-10-46: Finished batch 3000.

2023-08-10-05-13-06: Training (last 600 batches): accuracy = 0.999861, f1-score = 0.999868, loss = 1.345028
2023-08-10-05-13-19: Validation (total 179 batches): accuracy = 0.971963, f1-score = 0.972801, loss = 23.138910
2023-08-10-05-13-19: Finished batch 3600.

2023-08-10-05-15-38: Training (last 600 batches): accuracy = 0.996111, f1-score = 0.996278, loss = 7.972947
2023-08-10-05-15-51: Validation (total 179 batches): accuracy = 0.968692, f1-score = 0.970755, loss = 27.953447
2023-08-10-05-15-51: Finished batch 4200.

2023-08-10-05-18-11: Training (last 600 batches): accuracy = 0.995556, f1-score = 0.995774, loss = 10.432642
2023-08-10-05-18-24: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.972112, loss = 23.080074
2023-08-10-05-18-24: Finished batch 4800.

2023-08-10-05-20-32: Training (last 600 batches): accuracy = 0.999028, f1-score = 0.999074, loss = 2.722537
2023-08-10-05-20-44: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971979, loss = 24.906914
2023-08-10-05-20-44: Finished batch 5350.

