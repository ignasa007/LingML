DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = roberta-base
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-10-28-05-41-43: Loading and pre-processing datasets...
2023-10-28-05-41-45: Finished pre-processing datasets.

2023-10-28-05-41-45: Tokenizing datasets...
2023-10-28-05-41-48: Finished tokenizing datasets.

2023-10-28-05-41-48: Preparing data-loaders...
2023-10-28-05-41-48: Finished preparing data-loaders.

2023-10-28-05-41-48: Loading and preparing model...
2023-10-28-05-41-50: Finshed preparing model.

2023-10-28-05-41-50: Starting training...

2023-10-28-05-42-36: Training (last 600 batches): accuracy = 0.903889, f1-score = 0.910802, loss = 132.756270
2023-10-28-05-42-40: Validation (total 179 batches): accuracy = 0.962150, f1-score = 0.963984, loss = 20.562378
2023-10-28-05-42-45: Testing (total 179 batches): accuracy = 0.959813, f1-score = 0.961913, loss = 20.857601
2023-10-28-05-42-45: Finished batch 600.

2023-10-28-05-43-31: Training (last 600 batches): accuracy = 0.972917, f1-score = 0.973885, loss = 48.898680
2023-10-28-05-43-36: Validation (total 179 batches): accuracy = 0.966355, f1-score = 0.968113, loss = 19.508852
2023-10-28-05-43-40: Testing (total 179 batches): accuracy = 0.967757, f1-score = 0.969510, loss = 19.135395
2023-10-28-05-43-40: Finished batch 1200.

2023-10-28-05-44-27: Training (last 600 batches): accuracy = 0.985000, f1-score = 0.985729, loss = 26.441487
2023-10-28-05-44-31: Validation (total 179 batches): accuracy = 0.952804, f1-score = 0.956484, loss = 34.136414
2023-10-28-05-44-35: Testing (total 179 batches): accuracy = 0.951402, f1-score = 0.955172, loss = 32.645546
2023-10-28-05-44-35: Finished batch 1800.

2023-10-28-05-45-22: Training (last 600 batches): accuracy = 0.992222, f1-score = 0.992624, loss = 14.653806
2023-10-28-05-45-26: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969563, loss = 26.631144
2023-10-28-05-45-30: Testing (total 179 batches): accuracy = 0.964953, f1-score = 0.966858, loss = 27.464968
2023-10-28-05-45-30: Finished batch 2400.

2023-10-28-05-46-17: Training (last 600 batches): accuracy = 0.993889, f1-score = 0.994161, loss = 12.912847
2023-10-28-05-46-21: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971806, loss = 23.290842
2023-10-28-05-46-25: Testing (total 179 batches): accuracy = 0.968224, f1-score = 0.970070, loss = 23.492216
2023-10-28-05-46-25: Finished batch 3000.

2023-10-28-05-47-12: Training (last 600 batches): accuracy = 0.995000, f1-score = 0.995218, loss = 8.719606
2023-10-28-05-47-16: Validation (total 179 batches): accuracy = 0.969626, f1-score = 0.971047, loss = 24.387878
2023-10-28-05-47-20: Testing (total 179 batches): accuracy = 0.971963, f1-score = 0.973333, loss = 20.942102
2023-10-28-05-47-20: Finished batch 3600.

2023-10-28-05-48-06: Training (last 600 batches): accuracy = 0.996111, f1-score = 0.996292, loss = 7.563193
2023-10-28-05-48-11: Validation (total 179 batches): accuracy = 0.967290, f1-score = 0.968610, loss = 25.591764
2023-10-28-05-48-15: Testing (total 179 batches): accuracy = 0.962150, f1-score = 0.963791, loss = 27.257614
2023-10-28-05-48-15: Finished batch 4200.

2023-10-28-05-49-01: Training (last 600 batches): accuracy = 0.997639, f1-score = 0.997750, loss = 5.480236
2023-10-28-05-49-05: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.972062, loss = 22.776684
2023-10-28-05-49-09: Testing (total 179 batches): accuracy = 0.969159, f1-score = 0.970693, loss = 23.661985
2023-10-28-05-49-09: Finished batch 4800.

2023-10-28-05-49-52: Training (last 600 batches): accuracy = 0.997917, f1-score = 0.998001, loss = 4.469688
2023-10-28-05-49-56: Validation (total 179 batches): accuracy = 0.972430, f1-score = 0.973649, loss = 26.826769
2023-10-28-05-50-00: Testing (total 179 batches): accuracy = 0.971495, f1-score = 0.972707, loss = 28.816473
2023-10-28-05-50-00: Finished batch 5350.

