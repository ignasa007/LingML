DATASET = aaai-constraint-covid-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = roberta-base
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-06-04-22-35: Loading and pre-processing datasets...
2023-09-06-04-22-37: Finished pre-processing datasets.

2023-09-06-04-22-37: Tokenizing datasets...
2023-09-06-04-22-39: Finished tokenizing datasets.

2023-09-06-04-22-39: Preparing data-loaders...
2023-09-06-04-22-39: Finished preparing data-loaders.

2023-09-06-04-22-39: Loading and preparing model...
2023-09-06-04-22-41: Finshed preparing model.

2023-09-06-04-22-41: Starting training...

2023-09-06-04-23-24: Training (last 600 batches): accuracy = 0.904583, f1-score = 0.911068, loss = 129.624000
2023-09-06-04-23-27: Validation (total 179 batches): accuracy = 0.959813, f1-score = 0.961744, loss = 21.013832
2023-09-06-04-23-27: Finished batch 600.

2023-09-06-04-24-09: Training (last 600 batches): accuracy = 0.971111, f1-score = 0.972581, loss = 51.833796
2023-09-06-04-24-13: Validation (total 179 batches): accuracy = 0.955140, f1-score = 0.958333, loss = 27.162668
2023-09-06-04-24-13: Finished batch 1200.

2023-09-06-04-24-55: Training (last 600 batches): accuracy = 0.984861, f1-score = 0.985592, loss = 29.158531
2023-09-06-04-24-59: Validation (total 179 batches): accuracy = 0.966355, f1-score = 0.968393, loss = 24.711611
2023-09-06-04-24-59: Finished batch 1800.

2023-09-06-04-25-41: Training (last 600 batches): accuracy = 0.988194, f1-score = 0.988749, loss = 19.838190
2023-09-06-04-25-44: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971806, loss = 18.046974
2023-09-06-04-25-44: Finished batch 2400.

2023-09-06-04-26-26: Training (last 600 batches): accuracy = 0.993611, f1-score = 0.993868, loss = 13.338291
2023-09-06-04-26-30: Validation (total 179 batches): accuracy = 0.971028, f1-score = 0.972759, loss = 24.474571
2023-09-06-04-26-30: Finished batch 3000.

2023-09-06-04-27-12: Training (last 600 batches): accuracy = 0.994722, f1-score = 0.994976, loss = 10.393174
2023-09-06-04-27-15: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.970614, loss = 24.929783
2023-09-06-04-27-15: Finished batch 3600.

2023-09-06-04-27-57: Training (last 600 batches): accuracy = 0.995556, f1-score = 0.995718, loss = 9.417743
2023-09-06-04-28-01: Validation (total 179 batches): accuracy = 0.956075, f1-score = 0.959413, loss = 35.782757
2023-09-06-04-28-01: Finished batch 4200.

2023-09-06-04-28-43: Training (last 600 batches): accuracy = 0.996389, f1-score = 0.996573, loss = 7.464457
2023-09-06-04-28-47: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.972012, loss = 22.129715
2023-09-06-04-28-47: Finished batch 4800.

2023-09-06-04-29-25: Training (last 600 batches): accuracy = 0.997361, f1-score = 0.997491, loss = 4.519636
2023-09-06-04-29-29: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.970951, loss = 34.218487
2023-09-06-04-29-29: Finished batch 5350.

