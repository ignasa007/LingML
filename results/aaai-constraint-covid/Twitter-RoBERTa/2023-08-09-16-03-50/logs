DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-09-16-03-50: Loading and pre-processing datasets...
2023-08-09-16-03-52: Finished pre-processing datasets.

2023-08-09-16-03-52: Tokenizing datasets...
2023-08-09-16-03-54: Finished tokenizing datasets.

2023-08-09-16-03-54: Preparing data-loaders...
2023-08-09-16-03-54: Finished preparing data-loaders.

2023-08-09-16-03-54: Loading and preparing model...
2023-08-09-16-03-56: Finshed preparing model.

2023-08-09-16-03-56: Starting training...

2023-08-09-16-05-57: Training (last 600 batches): accuracy = 0.927222, f1-score = 0.931034, loss = 113.198596
2023-08-09-16-06-10: Validation (total 179 batches): accuracy = 0.958879, f1-score = 0.960958, loss = 23.042995
2023-08-09-16-06-10: Finished batch 600.

2023-08-09-16-08-17: Training (last 600 batches): accuracy = 0.975556, f1-score = 0.976471, loss = 43.631264
2023-08-09-16-08-30: Validation (total 179 batches): accuracy = 0.964486, f1-score = 0.966461, loss = 19.470715
2023-08-09-16-08-30: Finished batch 1200.

2023-08-09-16-10-38: Training (last 600 batches): accuracy = 0.986389, f1-score = 0.987119, loss = 25.547502
2023-08-09-16-10-50: Validation (total 179 batches): accuracy = 0.965888, f1-score = 0.967742, loss = 22.185686
2023-08-09-16-10-50: Finished batch 1800.

2023-08-09-16-12-55: Training (last 600 batches): accuracy = 0.990556, f1-score = 0.991069, loss = 14.606200
2023-08-09-16-13-08: Validation (total 179 batches): accuracy = 0.972897, f1-score = 0.974153, loss = 19.480698
2023-08-09-16-13-08: Finished batch 2400.

2023-08-09-16-15-16: Training (last 600 batches): accuracy = 0.995972, f1-score = 0.996142, loss = 9.157216
2023-08-09-16-15-29: Validation (total 179 batches): accuracy = 0.962617, f1-score = 0.965157, loss = 35.541790
2023-08-09-16-15-29: Finished batch 3000.

2023-08-09-16-17-36: Training (last 600 batches): accuracy = 0.994167, f1-score = 0.994403, loss = 10.591257
2023-08-09-16-17-49: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969697, loss = 30.086439
2023-08-09-16-17-49: Finished batch 3600.

2023-08-09-16-19-56: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997085, loss = 6.652397
2023-08-09-16-20-09: Validation (total 179 batches): accuracy = 0.953738, f1-score = 0.957565, loss = 51.981602
2023-08-09-16-20-09: Finished batch 4200.

2023-08-09-16-22-16: Training (last 600 batches): accuracy = 0.996806, f1-score = 0.996938, loss = 5.549726
2023-08-09-16-22-28: Validation (total 179 batches): accuracy = 0.971028, f1-score = 0.972444, loss = 25.410625
2023-08-09-16-22-28: Finished batch 4800.

2023-08-09-16-24-25: Training (last 600 batches): accuracy = 0.998611, f1-score = 0.998669, loss = 2.841750
2023-08-09-16-24-37: Validation (total 179 batches): accuracy = 0.969626, f1-score = 0.970995, loss = 24.720942
2023-08-09-16-24-37: Finished batch 5350.

