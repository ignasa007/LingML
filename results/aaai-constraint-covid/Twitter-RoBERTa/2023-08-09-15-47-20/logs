DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-08-09-15-47-20: Loading and pre-processing datasets...
2023-08-09-15-47-21: Finished pre-processing datasets.

2023-08-09-15-47-21: Tokenizing datasets...
2023-08-09-15-47-24: Finished tokenizing datasets.

2023-08-09-15-47-24: Preparing data-loaders...
2023-08-09-15-47-24: Finished preparing data-loaders.

2023-08-09-15-47-24: Loading and preparing model...
2023-08-09-15-47-26: Finshed preparing model.

2023-08-09-15-47-26: Starting training...

2023-08-09-15-49-01: Training (last 600 batches): accuracy = 0.925000, f1-score = 0.928779, loss = 112.920847
2023-08-09-15-49-10: Validation (total 179 batches): accuracy = 0.944860, f1-score = 0.945370, loss = 25.587036
2023-08-09-15-49-10: Finished batch 600.

2023-08-09-15-50-47: Training (last 600 batches): accuracy = 0.974167, f1-score = 0.975539, loss = 46.029152
2023-08-09-15-50-55: Validation (total 179 batches): accuracy = 0.968692, f1-score = 0.970103, loss = 17.056101
2023-08-09-15-50-55: Finished batch 1200.

2023-08-09-15-52-31: Training (last 600 batches): accuracy = 0.984722, f1-score = 0.985361, loss = 27.066548
2023-08-09-15-52-40: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.971938, loss = 21.278509
2023-08-09-15-52-40: Finished batch 1800.

2023-08-09-15-54-16: Training (last 600 batches): accuracy = 0.992083, f1-score = 0.992342, loss = 15.625971
2023-08-09-15-54-25: Validation (total 179 batches): accuracy = 0.968692, f1-score = 0.969915, loss = 25.325380
2023-08-09-15-54-25: Finished batch 2400.

2023-08-09-15-56-00: Training (last 600 batches): accuracy = 0.994306, f1-score = 0.994673, loss = 10.546281
2023-08-09-15-56-09: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969882, loss = 27.698212
2023-08-09-15-56-09: Finished batch 3000.

2023-08-09-15-57-45: Training (last 600 batches): accuracy = 0.994722, f1-score = 0.994918, loss = 10.153439
2023-08-09-15-57-54: Validation (total 179 batches): accuracy = 0.967290, f1-score = 0.969486, loss = 25.160149
2023-08-09-15-57-54: Finished batch 3600.

2023-08-09-15-59-31: Training (last 600 batches): accuracy = 0.996806, f1-score = 0.996938, loss = 6.989293
2023-08-09-15-59-41: Validation (total 179 batches): accuracy = 0.972430, f1-score = 0.973882, loss = 26.365929
2023-08-09-15-59-41: Finished batch 4200.

2023-08-09-16-01-32: Training (last 600 batches): accuracy = 0.997917, f1-score = 0.998019, loss = 4.378605
2023-08-09-16-01-43: Validation (total 179 batches): accuracy = 0.973364, f1-score = 0.974790, loss = 27.468544
2023-08-09-16-01-43: Finished batch 4800.

2023-08-09-16-03-36: Training (last 600 batches): accuracy = 0.997500, f1-score = 0.997594, loss = 4.596095
2023-08-09-16-03-49: Validation (total 179 batches): accuracy = 0.971495, f1-score = 0.973234, loss = 32.328445
2023-08-09-16-03-49: Finished batch 5350.

