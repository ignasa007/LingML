DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-06-02-38-33: Loading and pre-processing datasets...
2023-09-06-02-38-34: Finished pre-processing datasets.

2023-09-06-02-38-34: Tokenizing datasets...
2023-09-06-02-38-37: Finished tokenizing datasets.

2023-09-06-02-38-37: Preparing data-loaders...
2023-09-06-02-38-37: Finished preparing data-loaders.

2023-09-06-02-38-37: Loading and preparing model...
2023-09-06-02-38-39: Finshed preparing model.

2023-09-06-02-38-39: Starting training...

2023-09-06-02-39-21: Training (last 600 batches): accuracy = 0.925000, f1-score = 0.928609, loss = 115.114433
2023-09-06-02-39-25: Validation (total 179 batches): accuracy = 0.929439, f1-score = 0.936528, loss = 41.776352
2023-09-06-02-39-25: Finished batch 600.

2023-09-06-02-40-07: Training (last 600 batches): accuracy = 0.970417, f1-score = 0.971724, loss = 49.454737
2023-09-06-02-40-10: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.969805, loss = 16.595922
2023-09-06-02-40-10: Finished batch 1200.

2023-09-06-02-40-52: Training (last 600 batches): accuracy = 0.985278, f1-score = 0.986056, loss = 26.943823
2023-09-06-02-40-56: Validation (total 179 batches): accuracy = 0.963551, f1-score = 0.965147, loss = 19.792847
2023-09-06-02-40-56: Finished batch 1800.

2023-09-06-02-41-37: Training (last 600 batches): accuracy = 0.990417, f1-score = 0.990828, loss = 15.056319
2023-09-06-02-41-41: Validation (total 179 batches): accuracy = 0.965421, f1-score = 0.967629, loss = 24.190130
2023-09-06-02-41-41: Finished batch 2400.

2023-09-06-02-42-23: Training (last 600 batches): accuracy = 0.996389, f1-score = 0.996546, loss = 7.445121
2023-09-06-02-42-27: Validation (total 179 batches): accuracy = 0.965421, f1-score = 0.967082, loss = 23.782259
2023-09-06-02-42-27: Finished batch 3000.

2023-09-06-02-43-08: Training (last 600 batches): accuracy = 0.995694, f1-score = 0.995876, loss = 7.527005
2023-09-06-02-43-12: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.972087, loss = 30.181168
2023-09-06-02-43-12: Finished batch 3600.

2023-09-06-02-43-54: Training (last 600 batches): accuracy = 0.996528, f1-score = 0.996678, loss = 6.943802
2023-09-06-02-43-58: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.969938, loss = 24.154009
2023-09-06-02-43-58: Finished batch 4200.

2023-09-06-02-44-39: Training (last 600 batches): accuracy = 0.995833, f1-score = 0.996047, loss = 6.391840
2023-09-06-02-44-43: Validation (total 179 batches): accuracy = 0.964486, f1-score = 0.966579, loss = 31.016472
2023-09-06-02-44-43: Finished batch 4800.

2023-09-06-02-45-21: Training (last 600 batches): accuracy = 0.997778, f1-score = 0.997879, loss = 3.277684
2023-09-06-02-45-25: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.970018, loss = 38.849567
2023-09-06-02-45-25: Finished batch 5350.

