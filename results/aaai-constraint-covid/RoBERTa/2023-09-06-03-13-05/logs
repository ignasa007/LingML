DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = roberta-base
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-06-03-13-05: Loading and pre-processing datasets...
2023-09-06-03-13-06: Finished pre-processing datasets.

2023-09-06-03-13-06: Tokenizing datasets...
2023-09-06-03-13-09: Finished tokenizing datasets.

2023-09-06-03-13-09: Preparing data-loaders...
2023-09-06-03-13-09: Finished preparing data-loaders.

2023-09-06-03-13-09: Loading and preparing model...
2023-09-06-03-13-11: Finshed preparing model.

2023-09-06-03-13-11: Starting training...

2023-09-06-03-13-53: Training (last 600 batches): accuracy = 0.901806, f1-score = 0.908974, loss = 130.919959
2023-09-06-03-13-57: Validation (total 179 batches): accuracy = 0.955607, f1-score = 0.958388, loss = 25.407028
2023-09-06-03-13-57: Finished batch 600.

2023-09-06-03-14-38: Training (last 600 batches): accuracy = 0.971667, f1-score = 0.973087, loss = 49.888447
2023-09-06-03-14-42: Validation (total 179 batches): accuracy = 0.960280, f1-score = 0.961556, loss = 22.054417
2023-09-06-03-14-42: Finished batch 1200.

2023-09-06-03-15-24: Training (last 600 batches): accuracy = 0.984722, f1-score = 0.985361, loss = 26.710295
2023-09-06-03-15-28: Validation (total 179 batches): accuracy = 0.961682, f1-score = 0.964161, loss = 22.171278
2023-09-06-03-15-28: Finished batch 1800.

2023-09-06-03-16-10: Training (last 600 batches): accuracy = 0.993056, f1-score = 0.993426, loss = 14.373136
2023-09-06-03-16-13: Validation (total 179 batches): accuracy = 0.965888, f1-score = 0.967996, loss = 19.073359
2023-09-06-03-16-13: Finished batch 2400.

2023-09-06-03-16-55: Training (last 600 batches): accuracy = 0.992222, f1-score = 0.992523, loss = 13.716612
2023-09-06-03-16-59: Validation (total 179 batches): accuracy = 0.965421, f1-score = 0.967629, loss = 22.534851
2023-09-06-03-16-59: Finished batch 3000.

2023-09-06-03-17-41: Training (last 600 batches): accuracy = 0.994861, f1-score = 0.995044, loss = 10.034546
2023-09-06-03-17-44: Validation (total 179 batches): accuracy = 0.966355, f1-score = 0.968085, loss = 23.745686
2023-09-06-03-17-44: Finished batch 3600.

2023-09-06-03-18-26: Training (last 600 batches): accuracy = 0.997639, f1-score = 0.997777, loss = 5.258113
2023-09-06-03-18-30: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.966231, loss = 31.496407
2023-09-06-03-18-30: Finished batch 4200.

2023-09-06-03-19-12: Training (last 600 batches): accuracy = 0.994444, f1-score = 0.994658, loss = 11.086575
2023-09-06-03-19-16: Validation (total 179 batches): accuracy = 0.969159, f1-score = 0.970848, loss = 26.431450
2023-09-06-03-19-16: Finished batch 4800.

2023-09-06-03-19-54: Training (last 600 batches): accuracy = 0.997222, f1-score = 0.997343, loss = 5.020469
2023-09-06-03-19-58: Validation (total 179 batches): accuracy = 0.962617, f1-score = 0.965096, loss = 30.380859
2023-09-06-03-19-58: Finished batch 5350.

