DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = roberta-base
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-06-02-59-15: Loading and pre-processing datasets...
2023-09-06-02-59-17: Finished pre-processing datasets.

2023-09-06-02-59-17: Tokenizing datasets...
2023-09-06-02-59-20: Finished tokenizing datasets.

2023-09-06-02-59-20: Preparing data-loaders...
2023-09-06-02-59-20: Finished preparing data-loaders.

2023-09-06-02-59-20: Loading and preparing model...
2023-09-06-02-59-22: Finshed preparing model.

2023-09-06-02-59-22: Starting training...

2023-09-06-03-00-04: Training (last 600 batches): accuracy = 0.901667, f1-score = 0.907087, loss = 134.014852
2023-09-06-03-00-08: Validation (total 179 batches): accuracy = 0.951402, f1-score = 0.954506, loss = 29.948679
2023-09-06-03-00-08: Finished batch 600.

2023-09-06-03-00-49: Training (last 600 batches): accuracy = 0.972639, f1-score = 0.974225, loss = 47.021504
2023-09-06-03-00-53: Validation (total 179 batches): accuracy = 0.960280, f1-score = 0.962604, loss = 23.337393
2023-09-06-03-00-53: Finished batch 1200.

2023-09-06-03-01-35: Training (last 600 batches): accuracy = 0.982500, f1-score = 0.983204, loss = 28.800881
2023-09-06-03-01-38: Validation (total 179 batches): accuracy = 0.963551, f1-score = 0.965022, loss = 22.890062
2023-09-06-03-01-38: Finished batch 1800.

2023-09-06-03-02-20: Training (last 600 batches): accuracy = 0.991389, f1-score = 0.991753, loss = 15.790558
2023-09-06-03-02-24: Validation (total 179 batches): accuracy = 0.964486, f1-score = 0.966282, loss = 22.734795
2023-09-06-03-02-24: Finished batch 2400.

2023-09-06-03-03-06: Training (last 600 batches): accuracy = 0.991389, f1-score = 0.991790, loss = 13.616571
2023-09-06-03-03-10: Validation (total 179 batches): accuracy = 0.961215, f1-score = 0.963803, loss = 29.123812
2023-09-06-03-03-10: Finished batch 3000.

2023-09-06-03-03-51: Training (last 600 batches): accuracy = 0.993611, f1-score = 0.993904, loss = 10.351703
2023-09-06-03-03-55: Validation (total 179 batches): accuracy = 0.965421, f1-score = 0.967343, loss = 29.948034
2023-09-06-03-03-55: Finished batch 3600.

2023-09-06-03-04-37: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997080, loss = 7.244855
2023-09-06-03-04-41: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.970097, loss = 31.746843
2023-09-06-03-04-41: Finished batch 4200.

2023-09-06-03-05-22: Training (last 600 batches): accuracy = 0.997639, f1-score = 0.997747, loss = 4.966025
2023-09-06-03-05-26: Validation (total 179 batches): accuracy = 0.966822, f1-score = 0.968570, loss = 31.939249
2023-09-06-03-05-26: Finished batch 4800.

2023-09-06-03-06-04: Training (last 600 batches): accuracy = 0.996944, f1-score = 0.997078, loss = 5.987305
2023-09-06-03-06-08: Validation (total 179 batches): accuracy = 0.963084, f1-score = 0.964998, loss = 30.450594
2023-09-06-03-06-08: Finished batch 5350.

