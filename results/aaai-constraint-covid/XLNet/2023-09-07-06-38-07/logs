DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = xlnet-base-cased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-07-06-38-07: Loading and pre-processing datasets...
2023-09-07-06-38-08: Finished pre-processing datasets.

2023-09-07-06-38-08: Tokenizing datasets...
2023-09-07-06-38-11: Finished tokenizing datasets.

2023-09-07-06-38-11: Preparing data-loaders...
2023-09-07-06-38-11: Finished preparing data-loaders.

2023-09-07-06-38-11: Loading and preparing model...
2023-09-07-06-38-13: Finshed preparing model.

2023-09-07-06-38-13: Starting training...

2023-09-07-06-39-05: Training (last 600 batches): accuracy = 0.907778, f1-score = 0.912146, loss = 134.284383
2023-09-07-06-39-10: Validation (total 179 batches): accuracy = 0.939720, f1-score = 0.944942, loss = 25.840942
2023-09-07-06-39-10: Finished batch 600.

2023-09-07-06-40-01: Training (last 600 batches): accuracy = 0.968750, f1-score = 0.970092, loss = 55.966281
2023-09-07-06-40-06: Validation (total 179 batches): accuracy = 0.958879, f1-score = 0.961606, loss = 26.536783
2023-09-07-06-40-06: Finished batch 1200.

2023-09-07-06-40-57: Training (last 600 batches): accuracy = 0.982083, f1-score = 0.982997, loss = 32.599023
2023-09-07-06-41-02: Validation (total 179 batches): accuracy = 0.946262, f1-score = 0.947029, loss = 32.269100
2023-09-07-06-41-02: Finished batch 1800.

2023-09-07-06-41-54: Training (last 600 batches): accuracy = 0.988889, f1-score = 0.989421, loss = 19.638325
2023-09-07-06-41-58: Validation (total 179 batches): accuracy = 0.971963, f1-score = 0.973568, loss = 23.425613
2023-09-07-06-41-58: Finished batch 2400.

2023-09-07-06-42-50: Training (last 600 batches): accuracy = 0.994306, f1-score = 0.994575, loss = 10.574765
2023-09-07-06-42-55: Validation (total 179 batches): accuracy = 0.963084, f1-score = 0.965667, loss = 32.401241
2023-09-07-06-42-55: Finished batch 3000.

2023-09-07-06-43-46: Training (last 600 batches): accuracy = 0.993194, f1-score = 0.993492, loss = 12.250146
2023-09-07-06-43-51: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.970228, loss = 26.645815
2023-09-07-06-43-51: Finished batch 3600.

2023-09-07-06-44-42: Training (last 600 batches): accuracy = 0.995833, f1-score = 0.995993, loss = 7.001505
2023-09-07-06-44-47: Validation (total 179 batches): accuracy = 0.971495, f1-score = 0.973163, loss = 28.812042
2023-09-07-06-44-47: Finished batch 4200.

2023-09-07-06-45-39: Training (last 600 batches): accuracy = 0.995833, f1-score = 0.996040, loss = 6.773158
2023-09-07-06-45-43: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.970018, loss = 30.772327
2023-09-07-06-45-43: Finished batch 4800.

2023-09-07-06-46-31: Training (last 600 batches): accuracy = 0.998056, f1-score = 0.998140, loss = 3.879819
2023-09-07-06-46-36: Validation (total 179 batches): accuracy = 0.971963, f1-score = 0.973357, loss = 25.581491
2023-09-07-06-46-36: Finished batch 5350.

