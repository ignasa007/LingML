DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = xlnet-base-cased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-10-29-23-58-03: Loading and pre-processing datasets...
2023-10-29-23-58-05: Finished pre-processing datasets.

2023-10-29-23-58-05: Tokenizing datasets...
2023-10-29-23-58-10: Finished tokenizing datasets.

2023-10-29-23-58-10: Preparing data-loaders...
2023-10-29-23-58-10: Finished preparing data-loaders.

2023-10-29-23-58-10: Loading and preparing model...
2023-10-29-23-58-12: Finshed preparing model.

2023-10-29-23-58-12: Starting training...

2023-10-29-23-59-09: Training (last 600 batches): accuracy = 0.913611, f1-score = 0.918841, loss = 129.757321
2023-10-29-23-59-14: Validation (total 179 batches): accuracy = 0.940654, f1-score = 0.945842, loss = 33.501087
2023-10-29-23-59-19: Testing (total 179 batches): accuracy = 0.932243, f1-score = 0.938689, loss = 37.442776
2023-10-29-23-59-19: Finished batch 600.

2023-10-30-00-00-17: Training (last 600 batches): accuracy = 0.966528, f1-score = 0.967854, loss = 57.875909
2023-10-30-00-00-23: Validation (total 179 batches): accuracy = 0.972430, f1-score = 0.973928, loss = 15.762079
2023-10-30-00-00-28: Testing (total 179 batches): accuracy = 0.966355, f1-score = 0.968226, loss = 16.481548
2023-10-30-00-00-28: Finished batch 1200.

2023-10-30-00-01-25: Training (last 600 batches): accuracy = 0.983472, f1-score = 0.984361, loss = 28.030334
2023-10-30-00-01-31: Validation (total 179 batches): accuracy = 0.953738, f1-score = 0.957419, loss = 30.467579
2023-10-30-00-01-36: Testing (total 179 batches): accuracy = 0.948598, f1-score = 0.952911, loss = 30.472588
2023-10-30-00-01-36: Finished batch 1800.

2023-10-30-00-02-33: Training (last 600 batches): accuracy = 0.988194, f1-score = 0.988671, loss = 18.661607
2023-10-30-00-02-38: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.967263, loss = 29.057949
2023-10-30-00-02-44: Testing (total 179 batches): accuracy = 0.966822, f1-score = 0.969036, loss = 27.987743
2023-10-30-00-02-44: Finished batch 2400.

2023-10-30-00-03-41: Training (last 600 batches): accuracy = 0.993333, f1-score = 0.993598, loss = 10.666002
2023-10-30-00-03-46: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971681, loss = 23.995724
2023-10-30-00-03-51: Testing (total 179 batches): accuracy = 0.970093, f1-score = 0.971656, loss = 22.448761
2023-10-30-00-03-51: Finished batch 3000.

2023-10-30-00-04-48: Training (last 600 batches): accuracy = 0.995833, f1-score = 0.996042, loss = 7.733786
2023-10-30-00-04-53: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.972062, loss = 26.594461
2023-10-30-00-04-59: Testing (total 179 batches): accuracy = 0.971963, f1-score = 0.973286, loss = 25.710804
2023-10-30-00-04-59: Finished batch 3600.

2023-10-30-00-05-56: Training (last 600 batches): accuracy = 0.995972, f1-score = 0.996183, loss = 8.407186
2023-10-30-00-06-01: Validation (total 179 batches): accuracy = 0.971963, f1-score = 0.973357, loss = 27.920443
2023-10-30-00-06-06: Testing (total 179 batches): accuracy = 0.974766, f1-score = 0.975979, loss = 23.178850
2023-10-30-00-06-06: Finished batch 4200.

2023-10-30-00-07-03: Training (last 600 batches): accuracy = 0.996528, f1-score = 0.996678, loss = 6.895781
2023-10-30-00-07-08: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971756, loss = 31.085007
2023-10-30-00-07-14: Testing (total 179 batches): accuracy = 0.971963, f1-score = 0.973568, loss = 25.913025
2023-10-30-00-07-14: Finished batch 4800.

2023-10-30-00-08-05: Training (last 600 batches): accuracy = 0.996667, f1-score = 0.996814, loss = 6.549183
2023-10-30-00-08-11: Validation (total 179 batches): accuracy = 0.960280, f1-score = 0.962801, loss = 29.121662
2023-10-30-00-08-16: Testing (total 179 batches): accuracy = 0.959813, f1-score = 0.962413, loss = 28.728704
2023-10-30-00-08-16: Finished batch 5350.

