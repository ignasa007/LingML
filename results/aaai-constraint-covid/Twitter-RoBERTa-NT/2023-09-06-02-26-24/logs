DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-06-02-26-24: Loading and pre-processing datasets...
2023-09-06-02-26-26: Finished pre-processing datasets.

2023-09-06-02-26-26: Tokenizing datasets...
2023-09-06-02-26-28: Finished tokenizing datasets.

2023-09-06-02-26-28: Preparing data-loaders...
2023-09-06-02-26-28: Finished preparing data-loaders.

2023-09-06-02-26-28: Loading and preparing model...
2023-09-06-02-26-31: Finshed preparing model.

2023-09-06-02-26-31: Starting training...

2023-09-06-02-27-32: Training (last 600 batches): accuracy = 0.924583, f1-score = 0.928355, loss = 121.284495
2023-09-06-02-27-39: Validation (total 179 batches): accuracy = 0.955140, f1-score = 0.958225, loss = 22.299389
2023-09-06-02-27-39: Finished batch 600.

2023-09-06-02-28-50: Training (last 600 batches): accuracy = 0.971806, f1-score = 0.973095, loss = 47.423738
2023-09-06-02-28-57: Validation (total 179 batches): accuracy = 0.957009, f1-score = 0.960139, loss = 25.437372
2023-09-06-02-28-57: Finished batch 1200.

2023-09-06-02-30-09: Training (last 600 batches): accuracy = 0.985694, f1-score = 0.986287, loss = 27.717933
2023-09-06-02-30-16: Validation (total 179 batches): accuracy = 0.959346, f1-score = 0.961992, loss = 27.396248
2023-09-06-02-30-16: Finished batch 1800.

2023-09-06-02-31-28: Training (last 600 batches): accuracy = 0.990278, f1-score = 0.990787, loss = 15.111546
2023-09-06-02-31-35: Validation (total 179 batches): accuracy = 0.963084, f1-score = 0.965427, loss = 32.092617
2023-09-06-02-31-35: Finished batch 2400.

2023-09-06-02-32-45: Training (last 600 batches): accuracy = 0.992361, f1-score = 0.992737, loss = 14.757543
2023-09-06-02-32-52: Validation (total 179 batches): accuracy = 0.965421, f1-score = 0.967401, loss = 24.731934
2023-09-06-02-32-52: Finished batch 3000.

2023-09-06-02-34-05: Training (last 600 batches): accuracy = 0.994306, f1-score = 0.994559, loss = 9.669038
2023-09-06-02-34-12: Validation (total 179 batches): accuracy = 0.966355, f1-score = 0.968310, loss = 33.863628
2023-09-06-02-34-12: Finished batch 3600.

2023-09-06-02-35-25: Training (last 600 batches): accuracy = 0.994583, f1-score = 0.994790, loss = 9.815712
2023-09-06-02-35-32: Validation (total 179 batches): accuracy = 0.948131, f1-score = 0.948824, loss = 36.372765
2023-09-06-02-35-32: Finished batch 4200.

2023-09-06-02-36-45: Training (last 600 batches): accuracy = 0.996111, f1-score = 0.996309, loss = 6.777153
2023-09-06-02-36-52: Validation (total 179 batches): accuracy = 0.966355, f1-score = 0.968338, loss = 25.221365
2023-09-06-02-36-52: Finished batch 4800.

2023-09-06-02-38-00: Training (last 600 batches): accuracy = 0.997639, f1-score = 0.997743, loss = 4.656963
2023-09-06-02-38-07: Validation (total 179 batches): accuracy = 0.971495, f1-score = 0.972997, loss = 31.099398
2023-09-06-02-38-07: Finished batch 5350.

