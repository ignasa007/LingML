DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = xlm-roberta-base
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-07-14-21-44: Loading and pre-processing datasets...
2023-09-07-14-21-45: Finished pre-processing datasets.

2023-09-07-14-21-45: Tokenizing datasets...
2023-09-07-14-21-48: Finished tokenizing datasets.

2023-09-07-14-21-48: Preparing data-loaders...
2023-09-07-14-21-48: Finished preparing data-loaders.

2023-09-07-14-21-48: Loading and preparing model...
2023-09-07-14-21-52: Finshed preparing model.

2023-09-07-14-21-52: Starting training...

2023-09-07-14-23-45: Training (last 600 batches): accuracy = 0.882361, f1-score = 0.887710, loss = 175.539648
2023-09-07-14-23-54: Validation (total 179 batches): accuracy = 0.943458, f1-score = 0.948224, loss = 26.982199
2023-09-07-14-23-54: Finished batch 600.

2023-09-07-14-25-45: Training (last 600 batches): accuracy = 0.960833, f1-score = 0.962904, loss = 69.887640
2023-09-07-14-25-54: Validation (total 179 batches): accuracy = 0.964953, f1-score = 0.966799, loss = 16.957018
2023-09-07-14-25-54: Finished batch 1200.

2023-09-07-14-27-46: Training (last 600 batches): accuracy = 0.977778, f1-score = 0.978500, loss = 39.669486
2023-09-07-14-27-54: Validation (total 179 batches): accuracy = 0.947196, f1-score = 0.951730, loss = 37.461151
2023-09-07-14-27-54: Finished batch 1800.

2023-09-07-14-29-46: Training (last 600 batches): accuracy = 0.987361, f1-score = 0.988018, loss = 25.570768
2023-09-07-14-29-54: Validation (total 179 batches): accuracy = 0.967290, f1-score = 0.968440, loss = 19.467787
2023-09-07-14-29-54: Finished batch 2400.

2023-09-07-14-31-46: Training (last 600 batches): accuracy = 0.990694, f1-score = 0.991139, loss = 16.092949
2023-09-07-14-31-55: Validation (total 179 batches): accuracy = 0.976168, f1-score = 0.977444, loss = 18.475061
2023-09-07-14-31-55: Finished batch 3000.

2023-09-07-14-33-47: Training (last 600 batches): accuracy = 0.993750, f1-score = 0.994009, loss = 13.210882
2023-09-07-14-33-55: Validation (total 179 batches): accuracy = 0.948131, f1-score = 0.952665, loss = 40.679817
2023-09-07-14-33-55: Finished batch 3600.

2023-09-07-14-35-47: Training (last 600 batches): accuracy = 0.992917, f1-score = 0.993230, loss = 11.517991
2023-09-07-14-35-55: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.972381, loss = 26.372683
2023-09-07-14-35-55: Finished batch 4200.

2023-09-07-14-37-40: Training (last 600 batches): accuracy = 0.993750, f1-score = 0.994047, loss = 9.755040
2023-09-07-14-37-44: Validation (total 179 batches): accuracy = 0.972430, f1-score = 0.973578, loss = 23.897242
2023-09-07-14-37-44: Finished batch 4800.

2023-09-07-14-39-04: Training (last 600 batches): accuracy = 0.995972, f1-score = 0.996136, loss = 7.963654
2023-09-07-14-39-12: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971856, loss = 25.737722
2023-09-07-14-39-12: Finished batch 5350.

