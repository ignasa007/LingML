DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = xlm-roberta-base
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-07-14-39-14: Loading and pre-processing datasets...
2023-09-07-14-39-15: Finished pre-processing datasets.

2023-09-07-14-39-15: Tokenizing datasets...
2023-09-07-14-39-18: Finished tokenizing datasets.

2023-09-07-14-39-18: Preparing data-loaders...
2023-09-07-14-39-18: Finished preparing data-loaders.

2023-09-07-14-39-18: Loading and preparing model...
2023-09-07-14-39-22: Finshed preparing model.

2023-09-07-14-39-22: Starting training...

2023-09-07-14-41-16: Training (last 600 batches): accuracy = 0.888472, f1-score = 0.897954, loss = 158.181956
2023-09-07-14-41-24: Validation (total 179 batches): accuracy = 0.948598, f1-score = 0.952709, loss = 25.300222
2023-09-07-14-41-24: Finished batch 600.

2023-09-07-14-43-16: Training (last 600 batches): accuracy = 0.967500, f1-score = 0.969129, loss = 58.748074
2023-09-07-14-43-24: Validation (total 179 batches): accuracy = 0.958879, f1-score = 0.961905, loss = 26.370834
2023-09-07-14-43-24: Finished batch 1200.

2023-09-07-14-45-16: Training (last 600 batches): accuracy = 0.976944, f1-score = 0.978164, loss = 42.516852
2023-09-07-14-45-24: Validation (total 179 batches): accuracy = 0.964486, f1-score = 0.966870, loss = 18.930666
2023-09-07-14-45-24: Finished batch 1800.

2023-09-07-14-47-16: Training (last 600 batches): accuracy = 0.986667, f1-score = 0.987261, loss = 22.279843
2023-09-07-14-47-25: Validation (total 179 batches): accuracy = 0.964486, f1-score = 0.966608, loss = 23.439863
2023-09-07-14-47-25: Finished batch 2400.

2023-09-07-14-49-16: Training (last 600 batches): accuracy = 0.993472, f1-score = 0.993731, loss = 13.554238
2023-09-07-14-49-25: Validation (total 179 batches): accuracy = 0.966355, f1-score = 0.968614, loss = 32.304699
2023-09-07-14-49-25: Finished batch 3000.

2023-09-07-14-51-17: Training (last 600 batches): accuracy = 0.993056, f1-score = 0.993391, loss = 13.024936
2023-09-07-14-51-25: Validation (total 179 batches): accuracy = 0.957009, f1-score = 0.960276, loss = 39.754166
2023-09-07-14-51-25: Finished batch 3600.

2023-09-07-14-53-17: Training (last 600 batches): accuracy = 0.994306, f1-score = 0.994553, loss = 10.562819
2023-09-07-14-53-25: Validation (total 179 batches): accuracy = 0.972430, f1-score = 0.973974, loss = 23.408001
2023-09-07-14-53-25: Finished batch 4200.

2023-09-07-14-55-17: Training (last 600 batches): accuracy = 0.996250, f1-score = 0.996421, loss = 6.210127
2023-09-07-14-55-25: Validation (total 179 batches): accuracy = 0.964019, f1-score = 0.965016, loss = 30.604061
2023-09-07-14-55-25: Finished batch 4800.

2023-09-07-14-56-41: Training (last 600 batches): accuracy = 0.996111, f1-score = 0.996276, loss = 7.244518
2023-09-07-14-56-45: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971831, loss = 26.729277
2023-09-07-14-56-45: Finished batch 5350.

