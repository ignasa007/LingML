DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = covid-twitter-bert-v2
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-10-30-17-28-41: Loading and pre-processing datasets...
2023-10-30-17-28-43: Finished pre-processing datasets.

2023-10-30-17-28-43: Tokenizing datasets...
2023-10-30-17-28-45: Finished tokenizing datasets.

2023-10-30-17-28-45: Preparing data-loaders...
2023-10-30-17-28-45: Finished preparing data-loaders.

2023-10-30-17-28-45: Loading and preparing model...
2023-10-30-17-28-49: Finshed preparing model.

2023-10-30-17-28-49: Starting training...

2023-10-30-17-31-14: Training (last 600 batches): accuracy = 0.870000, f1-score = 0.882795, loss = 170.551908
2023-10-30-17-31-27: Validation (total 179 batches): accuracy = 0.959813, f1-score = 0.960838, loss = 20.320818
2023-10-30-17-31-40: Testing (total 179 batches): accuracy = 0.962150, f1-score = 0.963132, loss = 20.540182
2023-10-30-17-31-40: Finished batch 600.

2023-10-30-17-34-04: Training (last 600 batches): accuracy = 0.978333, f1-score = 0.979560, loss = 36.573999
2023-10-30-17-34-17: Validation (total 179 batches): accuracy = 0.977570, f1-score = 0.978686, loss = 10.955639
2023-10-30-17-34-30: Testing (total 179 batches): accuracy = 0.978972, f1-score = 0.980027, loss = 11.910537
2023-10-30-17-34-30: Finished batch 1200.

2023-10-30-17-36-54: Training (last 600 batches): accuracy = 0.991667, f1-score = 0.991957, loss = 15.953299
2023-10-30-17-37-07: Validation (total 179 batches): accuracy = 0.980841, f1-score = 0.981866, loss = 12.407313
2023-10-30-17-37-20: Testing (total 179 batches): accuracy = 0.973364, f1-score = 0.974879, loss = 14.322737
2023-10-30-17-37-20: Finished batch 1800.

2023-10-30-17-39-44: Training (last 600 batches): accuracy = 0.997778, f1-score = 0.997879, loss = 5.098150
2023-10-30-17-39-57: Validation (total 179 batches): accuracy = 0.978037, f1-score = 0.979139, loss = 17.610054
2023-10-30-17-40-10: Testing (total 179 batches): accuracy = 0.979907, f1-score = 0.980880, loss = 17.335281
2023-10-30-17-40-10: Finished batch 2400.

2023-10-30-17-42-34: Training (last 600 batches): accuracy = 0.996250, f1-score = 0.996454, loss = 7.706596
2023-10-30-17-42-47: Validation (total 179 batches): accuracy = 0.978505, f1-score = 0.979409, loss = 14.672361
2023-10-30-17-43-00: Testing (total 179 batches): accuracy = 0.982243, f1-score = 0.982960, loss = 15.441674
2023-10-30-17-43-00: Finished batch 3000.

2023-10-30-17-45-25: Training (last 600 batches): accuracy = 0.997361, f1-score = 0.997466, loss = 6.151485
2023-10-30-17-45-37: Validation (total 179 batches): accuracy = 0.972430, f1-score = 0.974202, loss = 23.824156
2023-10-30-17-45-50: Testing (total 179 batches): accuracy = 0.971495, f1-score = 0.973304, loss = 23.057322
2023-10-30-17-45-50: Finished batch 3600.

2023-10-30-17-48-15: Training (last 600 batches): accuracy = 0.998611, f1-score = 0.998675, loss = 3.673193
2023-10-30-17-48-28: Validation (total 179 batches): accuracy = 0.981776, f1-score = 0.982690, loss = 20.573631
2023-10-30-17-48-41: Testing (total 179 batches): accuracy = 0.978505, f1-score = 0.979556, loss = 17.388586
2023-10-30-17-48-41: Finished batch 4200.

2023-10-30-17-51-06: Training (last 600 batches): accuracy = 1.000000, f1-score = 1.000000, loss = 0.281258
2023-10-30-17-51-19: Validation (total 179 batches): accuracy = 0.979907, f1-score = 0.980948, loss = 21.459509
2023-10-30-17-51-32: Testing (total 179 batches): accuracy = 0.980374, f1-score = 0.981383, loss = 20.122364
2023-10-30-17-51-32: Finished batch 4800.

2023-10-30-17-53-45: Training (last 600 batches): accuracy = 1.000000, f1-score = 1.000000, loss = 0.097148
2023-10-30-17-53-58: Validation (total 179 batches): accuracy = 0.979439, f1-score = 0.980531, loss = 23.181063
2023-10-30-17-54-11: Testing (total 179 batches): accuracy = 0.980374, f1-score = 0.981399, loss = 22.170759
2023-10-30-17-54-11: Finished batch 5350.

