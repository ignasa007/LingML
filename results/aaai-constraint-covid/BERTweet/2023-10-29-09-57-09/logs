DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = bertweet-covid19-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-10-29-09-57-09: Loading and pre-processing datasets...
2023-10-29-09-57-11: Finished pre-processing datasets.

2023-10-29-09-57-11: Tokenizing datasets...
2023-10-29-09-57-15: Finished tokenizing datasets.

2023-10-29-09-57-15: Preparing data-loaders...
2023-10-29-09-57-15: Finished preparing data-loaders.

2023-10-29-09-57-15: Loading and preparing model...
2023-10-29-09-57-17: Finshed preparing model.

2023-10-29-09-57-17: Starting training...

2023-10-29-09-58-03: Training (last 600 batches): accuracy = 0.909444, f1-score = 0.915215, loss = 134.963611
2023-10-29-09-58-07: Validation (total 179 batches): accuracy = 0.955140, f1-score = 0.958297, loss = 22.979664
2023-10-29-09-58-12: Testing (total 179 batches): accuracy = 0.957944, f1-score = 0.960836, loss = 21.316311
2023-10-29-09-58-12: Finished batch 600.

2023-10-29-09-58-59: Training (last 600 batches): accuracy = 0.974861, f1-score = 0.975953, loss = 48.786549
2023-10-29-09-59-03: Validation (total 179 batches): accuracy = 0.963084, f1-score = 0.965214, loss = 21.014790
2023-10-29-09-59-07: Testing (total 179 batches): accuracy = 0.966355, f1-score = 0.968226, loss = 19.184246
2023-10-29-09-59-07: Finished batch 1200.

2023-10-29-09-59-54: Training (last 600 batches): accuracy = 0.982639, f1-score = 0.983420, loss = 32.993418
2023-10-29-09-59-58: Validation (total 179 batches): accuracy = 0.963551, f1-score = 0.965548, loss = 22.440250
2023-10-29-10-00-02: Testing (total 179 batches): accuracy = 0.970561, f1-score = 0.972234, loss = 17.720207
2023-10-29-10-00-02: Finished batch 1800.

2023-10-29-10-00-49: Training (last 600 batches): accuracy = 0.989306, f1-score = 0.989784, loss = 20.335401
2023-10-29-10-00-53: Validation (total 179 batches): accuracy = 0.961215, f1-score = 0.964116, loss = 26.749807
2023-10-29-10-00-57: Testing (total 179 batches): accuracy = 0.962617, f1-score = 0.965248, loss = 26.644556
2023-10-29-10-00-57: Finished batch 2400.

2023-10-29-10-01-44: Training (last 600 batches): accuracy = 0.995139, f1-score = 0.995389, loss = 11.078770
2023-10-29-10-01-48: Validation (total 179 batches): accuracy = 0.963084, f1-score = 0.964302, loss = 27.013514
2023-10-29-10-01-52: Testing (total 179 batches): accuracy = 0.973364, f1-score = 0.974336, loss = 21.132502
2023-10-29-10-01-52: Finished batch 3000.

2023-10-29-10-02-39: Training (last 600 batches): accuracy = 0.994722, f1-score = 0.994941, loss = 9.702365
2023-10-29-10-02-43: Validation (total 179 batches): accuracy = 0.970561, f1-score = 0.972259, loss = 24.049181
2023-10-29-10-02-47: Testing (total 179 batches): accuracy = 0.971495, f1-score = 0.973092, loss = 22.741901
2023-10-29-10-02-47: Finished batch 3600.

2023-10-29-10-03-34: Training (last 600 batches): accuracy = 0.995000, f1-score = 0.995232, loss = 9.388425
2023-10-29-10-03-38: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.970097, loss = 25.765783
2023-10-29-10-03-42: Testing (total 179 batches): accuracy = 0.970561, f1-score = 0.972234, loss = 23.930691
2023-10-29-10-03-42: Finished batch 4200.

2023-10-29-10-04-29: Training (last 600 batches): accuracy = 0.997361, f1-score = 0.997492, loss = 6.678157
2023-10-29-10-04-33: Validation (total 179 batches): accuracy = 0.962617, f1-score = 0.964061, loss = 29.878885
2023-10-29-10-04-37: Testing (total 179 batches): accuracy = 0.966355, f1-score = 0.967655, loss = 22.634800
2023-10-29-10-04-37: Finished batch 4800.

2023-10-29-10-05-20: Training (last 600 batches): accuracy = 0.996250, f1-score = 0.996385, loss = 8.380193
2023-10-29-10-05-24: Validation (total 179 batches): accuracy = 0.972430, f1-score = 0.973928, loss = 21.408316
2023-10-29-10-05-28: Testing (total 179 batches): accuracy = 0.971028, f1-score = 0.972566, loss = 22.490898
2023-10-29-10-05-28: Finished batch 5350.

