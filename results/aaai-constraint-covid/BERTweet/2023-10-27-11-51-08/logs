DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = bertweet-covid19-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-10-27-11-51-08: Loading and pre-processing datasets...
2023-10-27-11-51-09: Finished pre-processing datasets.

2023-10-27-11-51-09: Tokenizing datasets...
2023-10-27-11-51-13: Finished tokenizing datasets.

2023-10-27-11-51-13: Preparing data-loaders...
2023-10-27-11-51-13: Finished preparing data-loaders.

2023-10-27-11-51-13: Loading and preparing model...
2023-10-27-11-51-15: Finshed preparing model.

2023-10-27-11-51-15: Starting training...

2023-10-27-11-52-02: Training (last 600 batches): accuracy = 0.917083, f1-score = 0.921766, loss = 134.322255
2023-10-27-11-52-06: Validation (total 179 batches): accuracy = 0.952336, f1-score = 0.955959, loss = 27.196613
2023-10-27-11-52-10: Testing (total 179 batches): accuracy = 0.955140, f1-score = 0.958442, loss = 23.937939
2023-10-27-11-52-10: Finished batch 600.

2023-10-27-11-52-57: Training (last 600 batches): accuracy = 0.973472, f1-score = 0.974865, loss = 47.541568
2023-10-27-11-53-01: Validation (total 179 batches): accuracy = 0.961215, f1-score = 0.963740, loss = 22.720743
2023-10-27-11-53-06: Testing (total 179 batches): accuracy = 0.965421, f1-score = 0.967629, loss = 18.802254
2023-10-27-11-53-06: Finished batch 1200.

2023-10-27-11-53-52: Training (last 600 batches): accuracy = 0.984861, f1-score = 0.985607, loss = 27.790013
2023-10-27-11-53-57: Validation (total 179 batches): accuracy = 0.956075, f1-score = 0.959518, loss = 32.996532
2023-10-27-11-54-01: Testing (total 179 batches): accuracy = 0.954206, f1-score = 0.957759, loss = 32.685173
2023-10-27-11-54-01: Finished batch 1800.

2023-10-27-11-54-48: Training (last 600 batches): accuracy = 0.991806, f1-score = 0.992221, loss = 15.504222
2023-10-27-11-54-52: Validation (total 179 batches): accuracy = 0.965888, f1-score = 0.967912, loss = 23.326555
2023-10-27-11-54-56: Testing (total 179 batches): accuracy = 0.971028, f1-score = 0.972542, loss = 19.685379
2023-10-27-11-54-56: Finished batch 2400.

2023-10-27-11-55-43: Training (last 600 batches): accuracy = 0.993472, f1-score = 0.993677, loss = 12.364839
2023-10-27-11-55-47: Validation (total 179 batches): accuracy = 0.968692, f1-score = 0.970653, loss = 27.422018
2023-10-27-11-55-51: Testing (total 179 batches): accuracy = 0.969626, f1-score = 0.971429, loss = 25.065891
2023-10-27-11-55-51: Finished batch 3000.

2023-10-27-11-56-38: Training (last 600 batches): accuracy = 0.995972, f1-score = 0.996186, loss = 8.291409
2023-10-27-11-56-42: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969644, loss = 27.075285
2023-10-27-11-56-46: Testing (total 179 batches): accuracy = 0.974766, f1-score = 0.976106, loss = 22.171322
2023-10-27-11-56-46: Finished batch 3600.

2023-10-27-11-57-33: Training (last 600 batches): accuracy = 0.994444, f1-score = 0.994692, loss = 8.881179
2023-10-27-11-57-37: Validation (total 179 batches): accuracy = 0.964486, f1-score = 0.965704, loss = 30.134724
2023-10-27-11-57-42: Testing (total 179 batches): accuracy = 0.965888, f1-score = 0.967102, loss = 27.104568
2023-10-27-11-57-42: Finished batch 4200.

2023-10-27-11-58-29: Training (last 600 batches): accuracy = 0.996667, f1-score = 0.996796, loss = 6.528581
2023-10-27-11-58-33: Validation (total 179 batches): accuracy = 0.971963, f1-score = 0.973545, loss = 25.324486
2023-10-27-11-58-37: Testing (total 179 batches): accuracy = 0.970093, f1-score = 0.971706, loss = 25.364943
2023-10-27-11-58-37: Finished batch 4800.

2023-10-27-11-59-20: Training (last 600 batches): accuracy = 0.997639, f1-score = 0.997763, loss = 5.272895
2023-10-27-11-59-24: Validation (total 179 batches): accuracy = 0.973832, f1-score = 0.975133, loss = 23.251146
2023-10-27-11-59-28: Testing (total 179 batches): accuracy = 0.975234, f1-score = 0.976350, loss = 24.992819
2023-10-27-11-59-28: Finished batch 5350.

