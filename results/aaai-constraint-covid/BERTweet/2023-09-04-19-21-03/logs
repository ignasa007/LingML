DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = bertweet-covid19-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-04-19-21-03: Loading and pre-processing datasets...
2023-09-04-19-21-04: Finished pre-processing datasets.

2023-09-04-19-21-04: Tokenizing datasets...
2023-09-04-19-21-07: Finished tokenizing datasets.

2023-09-04-19-21-07: Preparing data-loaders...
2023-09-04-19-21-07: Finished preparing data-loaders.

2023-09-04-19-21-07: Loading and preparing model...
2023-09-04-19-21-10: Finshed preparing model.

2023-09-04-19-21-10: Starting training...

2023-09-04-19-22-39: Training (last 600 batches): accuracy = 0.912639, f1-score = 0.918723, loss = 133.371169
2023-09-04-19-22-46: Validation (total 179 batches): accuracy = 0.953738, f1-score = 0.956560, loss = 23.729034
2023-09-04-19-22-46: Finished batch 600.

2023-09-04-19-24-13: Training (last 600 batches): accuracy = 0.969583, f1-score = 0.970858, loss = 53.779885
2023-09-04-19-24-21: Validation (total 179 batches): accuracy = 0.958411, f1-score = 0.960982, loss = 22.366644
2023-09-04-19-24-21: Finished batch 1200.

2023-09-04-19-25-37: Training (last 600 batches): accuracy = 0.985278, f1-score = 0.986115, loss = 27.120217
2023-09-04-19-25-45: Validation (total 179 batches): accuracy = 0.966355, f1-score = 0.968282, loss = 21.466463
2023-09-04-19-25-45: Finished batch 1800.

2023-09-04-19-27-12: Training (last 600 batches): accuracy = 0.992222, f1-score = 0.992571, loss = 14.715442
2023-09-04-19-27-19: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.969805, loss = 24.893024
2023-09-04-19-27-19: Finished batch 2400.

2023-09-04-19-28-46: Training (last 600 batches): accuracy = 0.991111, f1-score = 0.991386, loss = 17.196062
2023-09-04-19-28-54: Validation (total 179 batches): accuracy = 0.968224, f1-score = 0.969697, loss = 24.363850
2023-09-04-19-28-54: Finished batch 3000.

2023-09-04-19-30-21: Training (last 600 batches): accuracy = 0.995694, f1-score = 0.995910, loss = 8.576523
2023-09-04-19-30-29: Validation (total 179 batches): accuracy = 0.969626, f1-score = 0.971378, loss = 25.400854
2023-09-04-19-30-29: Finished batch 3600.

2023-09-04-19-31-56: Training (last 600 batches): accuracy = 0.997639, f1-score = 0.997749, loss = 5.031696
2023-09-04-19-32-03: Validation (total 179 batches): accuracy = 0.958879, f1-score = 0.961302, loss = 40.009239
2023-09-04-19-32-03: Finished batch 4200.

2023-09-04-19-33-31: Training (last 600 batches): accuracy = 0.992917, f1-score = 0.993258, loss = 16.457820
2023-09-04-19-33-38: Validation (total 179 batches): accuracy = 0.971028, f1-score = 0.972469, loss = 23.821253
2023-09-04-19-33-38: Finished batch 4800.

2023-09-04-19-34-58: Training (last 600 batches): accuracy = 0.997639, f1-score = 0.997735, loss = 5.655873
2023-09-04-19-35-06: Validation (total 179 batches): accuracy = 0.942991, f1-score = 0.948173, loss = 44.746979
2023-09-04-19-35-06: Finished batch 5350.

