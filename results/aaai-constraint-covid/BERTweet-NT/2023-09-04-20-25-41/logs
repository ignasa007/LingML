DATASET = aaai-constraint-covid
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 128
BATCH SIZE = 12
MODEL = bertweet-covid19-base-uncased
LEARNING RATE = 1e-05
TEST EVERY = 600
SAVE EVERY = None

2023-09-04-20-25-41: Loading and pre-processing datasets...
2023-09-04-20-25-42: Finished pre-processing datasets.

2023-09-04-20-25-42: Tokenizing datasets...
2023-09-04-20-25-45: Finished tokenizing datasets.

2023-09-04-20-25-45: Preparing data-loaders...
2023-09-04-20-25-45: Finished preparing data-loaders.

2023-09-04-20-25-45: Loading and preparing model...
2023-09-04-20-25-48: Finshed preparing model.

2023-09-04-20-25-48: Starting training...

2023-09-04-20-26-31: Training (last 600 batches): accuracy = 0.905833, f1-score = 0.911650, loss = 142.798993
2023-09-04-20-26-35: Validation (total 179 batches): accuracy = 0.945794, f1-score = 0.950257, loss = 30.569574
2023-09-04-20-26-35: Finished batch 600.

2023-09-04-20-27-17: Training (last 600 batches): accuracy = 0.970556, f1-score = 0.971756, loss = 51.924449
2023-09-04-20-27-21: Validation (total 179 batches): accuracy = 0.952804, f1-score = 0.956596, loss = 30.851574
2023-09-04-20-27-21: Finished batch 1200.

2023-09-04-20-28-04: Training (last 600 batches): accuracy = 0.984167, f1-score = 0.985164, loss = 29.808407
2023-09-04-20-28-07: Validation (total 179 batches): accuracy = 0.968692, f1-score = 0.970653, loss = 20.773724
2023-09-04-20-28-07: Finished batch 1800.

2023-09-04-20-28-50: Training (last 600 batches): accuracy = 0.991667, f1-score = 0.991974, loss = 19.346464
2023-09-04-20-28-54: Validation (total 179 batches): accuracy = 0.960280, f1-score = 0.963156, loss = 28.516918
2023-09-04-20-28-54: Finished batch 2400.

2023-09-04-20-29-36: Training (last 600 batches): accuracy = 0.993194, f1-score = 0.993441, loss = 12.987693
2023-09-04-20-29-40: Validation (total 179 batches): accuracy = 0.971495, f1-score = 0.973210, loss = 19.792671
2023-09-04-20-29-40: Finished batch 3000.

2023-09-04-20-30-22: Training (last 600 batches): accuracy = 0.995972, f1-score = 0.996193, loss = 9.114476
2023-09-04-20-30-26: Validation (total 179 batches): accuracy = 0.971495, f1-score = 0.972877, loss = 24.322477
2023-09-04-20-30-26: Finished batch 3600.

2023-09-04-20-31-09: Training (last 600 batches): accuracy = 0.996111, f1-score = 0.996272, loss = 7.859390
2023-09-04-20-31-12: Validation (total 179 batches): accuracy = 0.967757, f1-score = 0.969044, loss = 22.792299
2023-09-04-20-31-12: Finished batch 4200.

2023-09-04-20-31-55: Training (last 600 batches): accuracy = 0.998194, f1-score = 0.998278, loss = 5.191425
2023-09-04-20-31-59: Validation (total 179 batches): accuracy = 0.970093, f1-score = 0.971930, loss = 24.985544
2023-09-04-20-31-59: Finished batch 4800.

2023-09-04-20-32-38: Training (last 600 batches): accuracy = 0.998472, f1-score = 0.998535, loss = 3.378803
2023-09-04-20-32-41: Validation (total 179 batches): accuracy = 0.966822, f1-score = 0.969090, loss = 32.571934
2023-09-04-20-32-41: Finished batch 5350.

