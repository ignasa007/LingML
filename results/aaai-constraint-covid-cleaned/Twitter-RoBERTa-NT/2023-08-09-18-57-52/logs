DATASET = aaai-constraint-covid-cleaned
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 300
SAVE EVERY = None

2023-08-09-18-57-52: Loading and pre-processing datasets...
2023-08-09-18-57-53: Finished pre-processing datasets.

2023-08-09-18-57-53: Tokenizing datasets...
2023-08-09-18-57-55: Finished tokenizing datasets.

2023-08-09-18-57-55: Preparing data-loaders...
2023-08-09-18-57-55: Finished preparing data-loaders.

2023-08-09-18-57-55: Loading and preparing model...
2023-08-09-18-57-57: Finshed preparing model.

2023-08-09-18-57-57: Starting training...

2023-08-09-18-58-42: Training (last 300 batches): accuracy = 0.920000, f1-score = 0.937419, loss = 66.960339
2023-08-09-18-58-45: Validation (total 82 batches): accuracy = 0.948980, f1-score = 0.960128, loss = 13.465508
2023-08-09-18-58-45: Finished batch 300.

2023-08-09-18-59-29: Training (last 300 batches): accuracy = 0.964673, f1-score = 0.972192, loss = 35.316674
2023-08-09-18-59-33: Validation (total 82 batches): accuracy = 0.946939, f1-score = 0.959184, loss = 12.200818
2023-08-09-18-59-33: Finished batch 600.

2023-08-09-19-00-17: Training (last 300 batches): accuracy = 0.968289, f1-score = 0.974945, loss = 28.221528
2023-08-09-19-00-20: Validation (total 82 batches): accuracy = 0.955102, f1-score = 0.965024, loss = 12.565449
2023-08-09-19-00-20: Finished batch 900.

2023-08-09-19-01-04: Training (last 300 batches): accuracy = 0.979138, f1-score = 0.983621, loss = 19.680915
2023-08-09-19-01-08: Validation (total 82 batches): accuracy = 0.954082, f1-score = 0.964200, loss = 15.186305
2023-08-09-19-01-08: Finished batch 1200.

2023-08-09-19-01-52: Training (last 300 batches): accuracy = 0.982754, f1-score = 0.986313, loss = 15.645179
2023-08-09-19-01-55: Validation (total 82 batches): accuracy = 0.944898, f1-score = 0.957143, loss = 17.479280
2023-08-09-19-01-55: Finished batch 1500.

2023-08-09-19-02-39: Training (last 300 batches): accuracy = 0.988317, f1-score = 0.990773, loss = 9.471427
2023-08-09-19-02-43: Validation (total 82 batches): accuracy = 0.933673, f1-score = 0.946237, loss = 29.238300
2023-08-09-19-02-43: Finished batch 1800.

2023-08-09-19-03-27: Training (last 300 batches): accuracy = 0.987483, f1-score = 0.990270, loss = 10.880093
2023-08-09-19-03-31: Validation (total 82 batches): accuracy = 0.957143, f1-score = 0.966238, loss = 15.301247
2023-08-09-19-03-31: Finished batch 2100.

2023-08-09-19-04-14: Training (last 300 batches): accuracy = 0.993880, f1-score = 0.995152, loss = 5.364977
2023-08-09-19-04-18: Validation (total 82 batches): accuracy = 0.942857, f1-score = 0.954323, loss = 20.309929
2023-08-09-19-04-18: Finished batch 2400.

2023-08-09-19-05-02: Training (last 300 batches): accuracy = 0.997218, f1-score = 0.997793, loss = 2.695102
2023-08-09-19-05-06: Validation (total 82 batches): accuracy = 0.953061, f1-score = 0.962963, loss = 22.633818
2023-08-09-19-05-06: Finished batch 2700.

2023-08-09-19-05-49: Training (last 300 batches): accuracy = 0.994715, f1-score = 0.995888, loss = 4.421452
2023-08-09-19-05-53: Validation (total 82 batches): accuracy = 0.954082, f1-score = 0.964143, loss = 19.092636
2023-08-09-19-05-53: Finished batch 3000.

2023-08-09-19-06-33: Training (last 300 batches): accuracy = 0.998609, f1-score = 0.998906, loss = 1.534393
2023-08-09-19-06-36: Validation (total 82 batches): accuracy = 0.946939, f1-score = 0.959119, loss = 21.799196
2023-08-09-19-06-36: Finished batch 3270.

