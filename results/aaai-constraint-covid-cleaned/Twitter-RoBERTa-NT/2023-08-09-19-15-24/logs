DATASET = aaai-constraint-covid-cleaned
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 300
SAVE EVERY = None

2023-08-09-19-15-24: Loading and pre-processing datasets...
2023-08-09-19-15-25: Finished pre-processing datasets.

2023-08-09-19-15-25: Tokenizing datasets...
2023-08-09-19-15-27: Finished tokenizing datasets.

2023-08-09-19-15-27: Preparing data-loaders...
2023-08-09-19-15-27: Finished preparing data-loaders.

2023-08-09-19-15-27: Loading and preparing model...
2023-08-09-19-15-29: Finshed preparing model.

2023-08-09-19-15-29: Starting training...

2023-08-09-19-16-14: Training (last 300 batches): accuracy = 0.919167, f1-score = 0.936808, loss = 66.901908
2023-08-09-19-16-17: Validation (total 82 batches): accuracy = 0.936735, f1-score = 0.951181, loss = 15.626689
2023-08-09-19-16-17: Finished batch 300.

2023-08-09-19-17-01: Training (last 300 batches): accuracy = 0.953268, f1-score = 0.963287, loss = 40.247679
2023-08-09-19-17-05: Validation (total 82 batches): accuracy = 0.937755, f1-score = 0.952232, loss = 15.021297
2023-08-09-19-17-05: Finished batch 600.

2023-08-09-19-17-49: Training (last 300 batches): accuracy = 0.966342, f1-score = 0.973319, loss = 31.116563
2023-08-09-19-17-52: Validation (total 82 batches): accuracy = 0.947959, f1-score = 0.958570, loss = 14.107213
2023-08-09-19-17-52: Finished batch 900.

2023-08-09-19-18-36: Training (last 300 batches): accuracy = 0.982197, f1-score = 0.986063, loss = 16.859701
2023-08-09-19-18-40: Validation (total 82 batches): accuracy = 0.947959, f1-score = 0.959298, loss = 18.877031
2023-08-09-19-18-40: Finished batch 1200.

2023-08-09-19-19-24: Training (last 300 batches): accuracy = 0.984701, f1-score = 0.988030, loss = 14.664604
2023-08-09-19-19-27: Validation (total 82 batches): accuracy = 0.947959, f1-score = 0.959427, loss = 18.592234
2023-08-09-19-19-27: Finished batch 1500.

2023-08-09-19-20-11: Training (last 300 batches): accuracy = 0.986648, f1-score = 0.989579, loss = 12.481870
2023-08-09-19-20-15: Validation (total 82 batches): accuracy = 0.943878, f1-score = 0.956315, loss = 20.231249
2023-08-09-19-20-15: Finished batch 1800.

2023-08-09-19-20-59: Training (last 300 batches): accuracy = 0.992211, f1-score = 0.993873, loss = 7.105427
2023-08-09-19-21-02: Validation (total 82 batches): accuracy = 0.936735, f1-score = 0.951334, loss = 26.995792
2023-08-09-19-21-02: Finished batch 2100.

2023-08-09-19-21-46: Training (last 300 batches): accuracy = 0.993324, f1-score = 0.994690, loss = 5.766648
2023-08-09-19-21-50: Validation (total 82 batches): accuracy = 0.946939, f1-score = 0.958533, loss = 21.204599
2023-08-09-19-21-50: Finished batch 2400.

2023-08-09-19-22-33: Training (last 300 batches): accuracy = 0.994159, f1-score = 0.995456, loss = 5.034883
2023-08-09-19-22-37: Validation (total 82 batches): accuracy = 0.945918, f1-score = 0.958169, loss = 23.221687
2023-08-09-19-22-37: Finished batch 2700.

2023-08-09-19-23-21: Training (last 300 batches): accuracy = 0.995828, f1-score = 0.996728, loss = 3.471076
2023-08-09-19-23-25: Validation (total 82 batches): accuracy = 0.944898, f1-score = 0.956240, loss = 19.190765
2023-08-09-19-23-25: Finished batch 3000.

2023-08-09-19-24-04: Training (last 300 batches): accuracy = 0.994993, f1-score = 0.996042, loss = 3.657450
2023-08-09-19-24-08: Validation (total 82 batches): accuracy = 0.946939, f1-score = 0.958796, loss = 26.664497
2023-08-09-19-24-08: Finished batch 3270.

