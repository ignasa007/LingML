DATASET = aaai-constraint-covid-cleaned
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 300
SAVE EVERY = None

2023-08-09-19-06-38: Loading and pre-processing datasets...
2023-08-09-19-06-39: Finished pre-processing datasets.

2023-08-09-19-06-39: Tokenizing datasets...
2023-08-09-19-06-41: Finished tokenizing datasets.

2023-08-09-19-06-41: Preparing data-loaders...
2023-08-09-19-06-41: Finished preparing data-loaders.

2023-08-09-19-06-41: Loading and preparing model...
2023-08-09-19-06-43: Finshed preparing model.

2023-08-09-19-06-43: Starting training...

2023-08-09-19-07-28: Training (last 300 batches): accuracy = 0.916389, f1-score = 0.935698, loss = 69.850265
2023-08-09-19-07-31: Validation (total 82 batches): accuracy = 0.947959, f1-score = 0.958637, loss = 12.452661
2023-08-09-19-07-31: Finished batch 300.

2023-08-09-19-08-15: Training (last 300 batches): accuracy = 0.956885, f1-score = 0.966105, loss = 39.354705
2023-08-09-19-08-19: Validation (total 82 batches): accuracy = 0.946939, f1-score = 0.956229, loss = 11.997765
2023-08-09-19-08-19: Finished batch 600.

2023-08-09-19-09-03: Training (last 300 batches): accuracy = 0.970515, f1-score = 0.976754, loss = 28.188197
2023-08-09-19-09-06: Validation (total 82 batches): accuracy = 0.951020, f1-score = 0.961102, loss = 15.073417
2023-08-09-19-09-06: Finished batch 900.

2023-08-09-19-09-50: Training (last 300 batches): accuracy = 0.980250, f1-score = 0.984675, loss = 19.448105
2023-08-09-19-09-54: Validation (total 82 batches): accuracy = 0.960204, f1-score = 0.967688, loss = 11.652292
2023-08-09-19-09-54: Finished batch 1200.

2023-08-09-19-10-38: Training (last 300 batches): accuracy = 0.983032, f1-score = 0.986845, loss = 15.062547
2023-08-09-19-10-41: Validation (total 82 batches): accuracy = 0.956122, f1-score = 0.964841, loss = 16.324213
2023-08-09-19-10-41: Finished batch 1500.

2023-08-09-19-11-25: Training (last 300 batches): accuracy = 0.991099, f1-score = 0.993109, loss = 8.132621
2023-08-09-19-11-29: Validation (total 82 batches): accuracy = 0.956122, f1-score = 0.964955, loss = 19.815025
2023-08-09-19-11-29: Finished batch 1800.

2023-08-09-19-12-13: Training (last 300 batches): accuracy = 0.991099, f1-score = 0.992930, loss = 8.105918
2023-08-09-19-12-16: Validation (total 82 batches): accuracy = 0.947959, f1-score = 0.957886, loss = 16.538792
2023-08-09-19-12-16: Finished batch 2100.

2023-08-09-19-13-00: Training (last 300 batches): accuracy = 0.995271, f1-score = 0.996339, loss = 5.304099
2023-08-09-19-13-04: Validation (total 82 batches): accuracy = 0.941837, f1-score = 0.953921, loss = 22.251781
2023-08-09-19-13-04: Finished batch 2400.

2023-08-09-19-13-48: Training (last 300 batches): accuracy = 0.994159, f1-score = 0.995456, loss = 5.417541
2023-08-09-19-13-51: Validation (total 82 batches): accuracy = 0.941837, f1-score = 0.954290, loss = 25.934786
2023-08-09-19-13-51: Finished batch 2700.

2023-08-09-19-14-35: Training (last 300 batches): accuracy = 0.995549, f1-score = 0.996522, loss = 3.435898
2023-08-09-19-14-39: Validation (total 82 batches): accuracy = 0.962245, f1-score = 0.969497, loss = 18.562723
2023-08-09-19-14-39: Finished batch 3000.

2023-08-09-19-15-19: Training (last 300 batches): accuracy = 0.996940, f1-score = 0.997606, loss = 2.549535
2023-08-09-19-15-22: Validation (total 82 batches): accuracy = 0.945918, f1-score = 0.957361, loss = 22.714624
2023-08-09-19-15-22: Finished batch 3270.

