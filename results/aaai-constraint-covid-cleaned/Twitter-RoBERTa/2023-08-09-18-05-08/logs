DATASET = aaai-constraint-covid-cleaned
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 300
SAVE EVERY = None

2023-08-09-18-05-08: Loading and pre-processing datasets...
2023-08-09-18-05-09: Finished pre-processing datasets.

2023-08-09-18-05-09: Tokenizing datasets...
2023-08-09-18-05-11: Finished tokenizing datasets.

2023-08-09-18-05-11: Preparing data-loaders...
2023-08-09-18-05-11: Finished preparing data-loaders.

2023-08-09-18-05-11: Loading and preparing model...
2023-08-09-18-05-13: Finshed preparing model.

2023-08-09-18-05-13: Starting training...

2023-08-09-18-05-57: Training (last 300 batches): accuracy = 0.912778, f1-score = 0.932415, loss = 71.858319
2023-08-09-18-06-01: Validation (total 82 batches): accuracy = 0.931633, f1-score = 0.947036, loss = 16.957230
2023-08-09-18-06-01: Finished batch 300.

2023-08-09-18-06-45: Training (last 300 batches): accuracy = 0.956050, f1-score = 0.965396, loss = 39.295276
2023-08-09-18-06-49: Validation (total 82 batches): accuracy = 0.946939, f1-score = 0.957929, loss = 12.721037
2023-08-09-18-06-49: Finished batch 600.

2023-08-09-18-07-33: Training (last 300 batches): accuracy = 0.971071, f1-score = 0.977518, loss = 29.530449
2023-08-09-18-07-36: Validation (total 82 batches): accuracy = 0.937755, f1-score = 0.950687, loss = 14.802181
2023-08-09-18-07-36: Finished batch 900.

2023-08-09-18-08-20: Training (last 300 batches): accuracy = 0.984145, f1-score = 0.987622, loss = 17.268417
2023-08-09-18-08-24: Validation (total 82 batches): accuracy = 0.923469, f1-score = 0.941360, loss = 19.593143
2023-08-09-18-08-24: Finished batch 1200.

2023-08-09-18-09-08: Training (last 300 batches): accuracy = 0.979972, f1-score = 0.984279, loss = 17.542875
2023-08-09-18-09-11: Validation (total 82 batches): accuracy = 0.941837, f1-score = 0.953009, loss = 14.280621
2023-08-09-18-09-11: Finished batch 1500.

2023-08-09-18-09-55: Training (last 300 batches): accuracy = 0.986092, f1-score = 0.989059, loss = 13.587196
2023-08-09-18-09-59: Validation (total 82 batches): accuracy = 0.943878, f1-score = 0.955029, loss = 16.944195
2023-08-09-18-09-59: Finished batch 1800.

2023-08-09-18-10-43: Training (last 300 batches): accuracy = 0.993324, f1-score = 0.994776, loss = 6.865522
2023-08-09-18-10-46: Validation (total 82 batches): accuracy = 0.947959, f1-score = 0.958299, loss = 21.124241
2023-08-09-18-10-46: Finished batch 2100.

2023-08-09-18-11-30: Training (last 300 batches): accuracy = 0.994993, f1-score = 0.996061, loss = 4.835754
2023-08-09-18-11-34: Validation (total 82 batches): accuracy = 0.947959, f1-score = 0.959102, loss = 19.800592
2023-08-09-18-11-34: Finished batch 2400.

2023-08-09-18-12-18: Training (last 300 batches): accuracy = 0.994993, f1-score = 0.996106, loss = 4.236956
2023-08-09-18-12-22: Validation (total 82 batches): accuracy = 0.941837, f1-score = 0.954509, loss = 22.450291
2023-08-09-18-12-22: Finished batch 2700.

2023-08-09-18-13-06: Training (last 300 batches): accuracy = 0.993324, f1-score = 0.994787, loss = 5.630175
2023-08-09-18-13-09: Validation (total 82 batches): accuracy = 0.945918, f1-score = 0.957634, loss = 23.404993
2023-08-09-18-13-09: Finished batch 3000.

2023-08-09-18-13-49: Training (last 300 batches): accuracy = 0.997497, f1-score = 0.998046, loss = 1.953397
2023-08-09-18-13-52: Validation (total 82 batches): accuracy = 0.939796, f1-score = 0.952988, loss = 29.260666
2023-08-09-18-13-52: Finished batch 3270.

