DATASET = aaai-constraint-covid-cleaned
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 300
SAVE EVERY = None

2023-08-09-18-13-54: Loading and pre-processing datasets...
2023-08-09-18-13-55: Finished pre-processing datasets.

2023-08-09-18-13-55: Tokenizing datasets...
2023-08-09-18-13-57: Finished tokenizing datasets.

2023-08-09-18-13-57: Preparing data-loaders...
2023-08-09-18-13-57: Finished preparing data-loaders.

2023-08-09-18-13-57: Loading and preparing model...
2023-08-09-18-13-59: Finshed preparing model.

2023-08-09-18-13-59: Starting training...

2023-08-09-18-14-44: Training (last 300 batches): accuracy = 0.905833, f1-score = 0.926829, loss = 76.048653
2023-08-09-18-14-47: Validation (total 82 batches): accuracy = 0.948980, f1-score = 0.961120, loss = 11.074712
2023-08-09-18-14-47: Finished batch 300.

2023-08-09-18-15-31: Training (last 300 batches): accuracy = 0.957719, f1-score = 0.966623, loss = 38.383507
2023-08-09-18-15-35: Validation (total 82 batches): accuracy = 0.956122, f1-score = 0.966222, loss = 11.118989
2023-08-09-18-15-35: Finished batch 600.

2023-08-09-18-16-19: Training (last 300 batches): accuracy = 0.970515, f1-score = 0.976673, loss = 28.229423
2023-08-09-18-16-23: Validation (total 82 batches): accuracy = 0.950000, f1-score = 0.960388, loss = 10.589039
2023-08-09-18-16-23: Finished batch 900.

2023-08-09-18-17-07: Training (last 300 batches): accuracy = 0.977191, f1-score = 0.981946, loss = 23.838358
2023-08-09-18-17-11: Validation (total 82 batches): accuracy = 0.959184, f1-score = 0.968603, loss = 10.438680
2023-08-09-18-17-11: Finished batch 1200.

2023-08-09-18-17-55: Training (last 300 batches): accuracy = 0.984145, f1-score = 0.987481, loss = 14.412859
2023-08-09-18-17-58: Validation (total 82 batches): accuracy = 0.956122, f1-score = 0.966062, loss = 12.180742
2023-08-09-18-17-58: Finished batch 1500.

2023-08-09-18-18-43: Training (last 300 batches): accuracy = 0.983866, f1-score = 0.987264, loss = 13.475762
2023-08-09-18-18-46: Validation (total 82 batches): accuracy = 0.959184, f1-score = 0.968750, loss = 14.743941
2023-08-09-18-18-46: Finished batch 1800.

2023-08-09-18-19-30: Training (last 300 batches): accuracy = 0.993324, f1-score = 0.994702, loss = 6.730436
2023-08-09-18-19-34: Validation (total 82 batches): accuracy = 0.958163, f1-score = 0.967742, loss = 12.833548
2023-08-09-18-19-34: Finished batch 2100.

2023-08-09-18-20-18: Training (last 300 batches): accuracy = 0.994437, f1-score = 0.995673, loss = 5.064308
2023-08-09-18-20-22: Validation (total 82 batches): accuracy = 0.956122, f1-score = 0.966380, loss = 17.444983
2023-08-09-18-20-22: Finished batch 2400.

2023-08-09-18-21-06: Training (last 300 batches): accuracy = 0.989986, f1-score = 0.991986, loss = 8.123642
2023-08-09-18-21-09: Validation (total 82 batches): accuracy = 0.953061, f1-score = 0.964561, loss = 15.029513
2023-08-09-18-21-09: Finished batch 2700.

2023-08-09-18-21-53: Training (last 300 batches): accuracy = 0.996384, f1-score = 0.997178, loss = 3.537904
2023-08-09-18-21-57: Validation (total 82 batches): accuracy = 0.952041, f1-score = 0.963195, loss = 17.988716
2023-08-09-18-21-57: Finished batch 3000.

2023-08-09-18-22-37: Training (last 300 batches): accuracy = 0.999444, f1-score = 0.999563, loss = 0.849356
2023-08-09-18-22-40: Validation (total 82 batches): accuracy = 0.957143, f1-score = 0.966981, loss = 20.673532
2023-08-09-18-22-40: Finished batch 3270.

