DATASET = aaai-constraint-covid-cleaned
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 300
SAVE EVERY = None

2023-08-09-18-22-42: Loading and pre-processing datasets...
2023-08-09-18-22-43: Finished pre-processing datasets.

2023-08-09-18-22-43: Tokenizing datasets...
2023-08-09-18-22-45: Finished tokenizing datasets.

2023-08-09-18-22-45: Preparing data-loaders...
2023-08-09-18-22-45: Finished preparing data-loaders.

2023-08-09-18-22-45: Loading and preparing model...
2023-08-09-18-22-47: Finshed preparing model.

2023-08-09-18-22-47: Starting training...

2023-08-09-18-23-32: Training (last 300 batches): accuracy = 0.903611, f1-score = 0.925232, loss = 75.152384
2023-08-09-18-23-35: Validation (total 82 batches): accuracy = 0.953061, f1-score = 0.963200, loss = 13.012424
2023-08-09-18-23-35: Finished batch 300.

2023-08-09-18-24-20: Training (last 300 batches): accuracy = 0.956328, f1-score = 0.965995, loss = 42.030994
2023-08-09-18-24-23: Validation (total 82 batches): accuracy = 0.954082, f1-score = 0.964086, loss = 10.856441
2023-08-09-18-24-23: Finished batch 600.

2023-08-09-18-25-07: Training (last 300 batches): accuracy = 0.967177, f1-score = 0.974055, loss = 30.430459
2023-08-09-18-25-11: Validation (total 82 batches): accuracy = 0.955102, f1-score = 0.964912, loss = 11.159353
2023-08-09-18-25-11: Finished batch 900.

2023-08-09-18-25-55: Training (last 300 batches): accuracy = 0.980250, f1-score = 0.984268, loss = 19.040864
2023-08-09-18-25-59: Validation (total 82 batches): accuracy = 0.955102, f1-score = 0.964630, loss = 12.423248
2023-08-09-18-25-59: Finished batch 1200.

2023-08-09-18-26-43: Training (last 300 batches): accuracy = 0.988039, f1-score = 0.990654, loss = 12.814221
2023-08-09-18-26-47: Validation (total 82 batches): accuracy = 0.931633, f1-score = 0.948342, loss = 23.472591
2023-08-09-18-26-47: Finished batch 1500.

2023-08-09-18-27-31: Training (last 300 batches): accuracy = 0.986370, f1-score = 0.989285, loss = 12.851410
2023-08-09-18-27-34: Validation (total 82 batches): accuracy = 0.951020, f1-score = 0.960720, loss = 16.616730
2023-08-09-18-27-34: Finished batch 1800.

2023-08-09-18-28-18: Training (last 300 batches): accuracy = 0.992490, f1-score = 0.994106, loss = 7.078935
2023-08-09-18-28-22: Validation (total 82 batches): accuracy = 0.954082, f1-score = 0.963024, loss = 19.278923
2023-08-09-18-28-22: Finished batch 2100.

2023-08-09-18-29-06: Training (last 300 batches): accuracy = 0.994715, f1-score = 0.995904, loss = 4.931678
2023-08-09-18-29-10: Validation (total 82 batches): accuracy = 0.953061, f1-score = 0.963492, loss = 19.117544
2023-08-09-18-29-10: Finished batch 2400.

2023-08-09-18-29-54: Training (last 300 batches): accuracy = 0.996940, f1-score = 0.997564, loss = 3.582921
2023-08-09-18-29-57: Validation (total 82 batches): accuracy = 0.953061, f1-score = 0.963082, loss = 16.249268
2023-08-09-18-29-57: Finished batch 2700.

2023-08-09-18-30-42: Training (last 300 batches): accuracy = 0.998053, f1-score = 0.998477, loss = 2.104150
2023-08-09-18-30-45: Validation (total 82 batches): accuracy = 0.953061, f1-score = 0.963259, loss = 20.027288
2023-08-09-18-30-45: Finished batch 3000.

2023-08-09-18-31-25: Training (last 300 batches): accuracy = 0.994993, f1-score = 0.996049, loss = 4.911406
2023-08-09-18-31-29: Validation (total 82 batches): accuracy = 0.946939, f1-score = 0.958065, loss = 17.869015
2023-08-09-18-31-29: Finished batch 3270.

