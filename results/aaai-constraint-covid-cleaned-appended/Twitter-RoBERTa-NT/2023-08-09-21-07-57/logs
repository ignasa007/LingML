DATASET = aaai-constraint-covid-cleaned-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = True
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 300
SAVE EVERY = None

2023-08-09-21-07-57: Loading and pre-processing datasets...
2023-08-09-21-07-58: Finished pre-processing datasets.

2023-08-09-21-07-58: Tokenizing datasets...
2023-08-09-21-08-01: Finished tokenizing datasets.

2023-08-09-21-08-01: Preparing data-loaders...
2023-08-09-21-08-01: Finished preparing data-loaders.

2023-08-09-21-08-01: Loading and preparing model...
2023-08-09-21-08-03: Finshed preparing model.

2023-08-09-21-08-03: Starting training...

2023-08-09-21-09-06: Training (last 300 batches): accuracy = 0.912778, f1-score = 0.932531, loss = 71.930111
2023-08-09-21-09-12: Validation (total 82 batches): accuracy = 0.946939, f1-score = 0.958730, loss = 13.194670
2023-08-09-21-09-12: Finished batch 300.

2023-08-09-21-10-20: Training (last 300 batches): accuracy = 0.956885, f1-score = 0.965971, loss = 40.701558
2023-08-09-21-10-27: Validation (total 82 batches): accuracy = 0.957143, f1-score = 0.965854, loss = 12.257509
2023-08-09-21-10-27: Finished batch 600.

2023-08-09-21-11-36: Training (last 300 batches): accuracy = 0.966064, f1-score = 0.973432, loss = 32.586170
2023-08-09-21-11-43: Validation (total 82 batches): accuracy = 0.951020, f1-score = 0.960976, loss = 11.264210
2023-08-09-21-11-43: Finished batch 900.

2023-08-09-21-12-52: Training (last 300 batches): accuracy = 0.976912, f1-score = 0.981905, loss = 21.925899
2023-08-09-21-12-59: Validation (total 82 batches): accuracy = 0.952041, f1-score = 0.962846, loss = 16.415386
2023-08-09-21-12-59: Finished batch 1200.

2023-08-09-21-14-08: Training (last 300 batches): accuracy = 0.984979, f1-score = 0.988095, loss = 13.600509
2023-08-09-21-14-14: Validation (total 82 batches): accuracy = 0.948980, f1-score = 0.959872, loss = 14.778769
2023-08-09-21-14-14: Finished batch 1500.

2023-08-09-21-15-23: Training (last 300 batches): accuracy = 0.990542, f1-score = 0.992644, loss = 9.479609
2023-08-09-21-15-30: Validation (total 82 batches): accuracy = 0.926531, f1-score = 0.944530, loss = 26.736698
2023-08-09-21-15-30: Finished batch 1800.

2023-08-09-21-16-40: Training (last 300 batches): accuracy = 0.989430, f1-score = 0.991732, loss = 9.849155
2023-08-09-21-16-47: Validation (total 82 batches): accuracy = 0.948980, f1-score = 0.960380, loss = 17.488867
2023-08-09-21-16-47: Finished batch 2100.

2023-08-09-21-17-55: Training (last 300 batches): accuracy = 0.991377, f1-score = 0.993256, loss = 7.554001
2023-08-09-21-18-02: Validation (total 82 batches): accuracy = 0.953061, f1-score = 0.963608, loss = 16.272955
2023-08-09-21-18-02: Finished batch 2400.

2023-08-09-21-19-12: Training (last 300 batches): accuracy = 0.996106, f1-score = 0.996907, loss = 3.672886
2023-08-09-21-19-19: Validation (total 82 batches): accuracy = 0.957143, f1-score = 0.965686, loss = 17.845699
2023-08-09-21-19-19: Finished batch 2700.

2023-08-09-21-20-30: Training (last 300 batches): accuracy = 0.993602, f1-score = 0.995014, loss = 5.453140
2023-08-09-21-20-37: Validation (total 82 batches): accuracy = 0.952041, f1-score = 0.962249, loss = 17.519953
2023-08-09-21-20-37: Finished batch 3000.

2023-08-09-21-21-41: Training (last 300 batches): accuracy = 0.996662, f1-score = 0.997382, loss = 2.155132
2023-08-09-21-21-48: Validation (total 82 batches): accuracy = 0.935714, f1-score = 0.950820, loss = 28.028685
2023-08-09-21-21-48: Finished batch 3270.

