DATASET = aaai-constraint-covid-cleaned-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 300
SAVE EVERY = None

2023-08-09-20-30-15: Loading and pre-processing datasets...
2023-08-09-20-30-15: Finished pre-processing datasets.

2023-08-09-20-30-15: Tokenizing datasets...
2023-08-09-20-30-17: Finished tokenizing datasets.

2023-08-09-20-30-17: Preparing data-loaders...
2023-08-09-20-30-17: Finished preparing data-loaders.

2023-08-09-20-30-17: Loading and preparing model...
2023-08-09-20-30-19: Finshed preparing model.

2023-08-09-20-30-19: Starting training...

2023-08-09-20-31-19: Training (last 300 batches): accuracy = 0.914444, f1-score = 0.932515, loss = 70.951632
2023-08-09-20-31-25: Validation (total 82 batches): accuracy = 0.931633, f1-score = 0.946783, loss = 15.620872
2023-08-09-20-31-25: Finished batch 300.

2023-08-09-20-32-27: Training (last 300 batches): accuracy = 0.957719, f1-score = 0.966942, loss = 40.970878
2023-08-09-20-32-33: Validation (total 82 batches): accuracy = 0.938776, f1-score = 0.953846, loss = 17.035158
2023-08-09-20-32-33: Finished batch 600.

2023-08-09-20-33-34: Training (last 300 batches): accuracy = 0.968289, f1-score = 0.974801, loss = 31.460378
2023-08-09-20-33-40: Validation (total 82 batches): accuracy = 0.944898, f1-score = 0.958009, loss = 16.165237
2023-08-09-20-33-40: Finished batch 900.

2023-08-09-20-34-40: Training (last 300 batches): accuracy = 0.977747, f1-score = 0.982433, loss = 21.482377
2023-08-09-20-34-46: Validation (total 82 batches): accuracy = 0.941837, f1-score = 0.955780, loss = 14.588218
2023-08-09-20-34-46: Finished batch 1200.

2023-08-09-20-35-49: Training (last 300 batches): accuracy = 0.982476, f1-score = 0.985984, loss = 16.649201
2023-08-09-20-35-54: Validation (total 82 batches): accuracy = 0.948980, f1-score = 0.960317, loss = 17.768370
2023-08-09-20-35-54: Finished batch 1500.

2023-08-09-20-36-57: Training (last 300 batches): accuracy = 0.983588, f1-score = 0.987098, loss = 14.982801
2023-08-09-20-37-02: Validation (total 82 batches): accuracy = 0.939796, f1-score = 0.953942, loss = 15.874265
2023-08-09-20-37-02: Finished batch 1800.

2023-08-09-20-38-04: Training (last 300 batches): accuracy = 0.991655, f1-score = 0.993351, loss = 8.965862
2023-08-09-20-38-09: Validation (total 82 batches): accuracy = 0.934694, f1-score = 0.949765, loss = 17.634085
2023-08-09-20-38-09: Finished batch 2100.

2023-08-09-20-39-11: Training (last 300 batches): accuracy = 0.994159, f1-score = 0.995456, loss = 6.036303
2023-08-09-20-39-17: Validation (total 82 batches): accuracy = 0.940816, f1-score = 0.953376, loss = 24.258549
2023-08-09-20-39-17: Finished batch 2400.

2023-08-09-20-40-20: Training (last 300 batches): accuracy = 0.995549, f1-score = 0.996446, loss = 4.184513
2023-08-09-20-40-25: Validation (total 82 batches): accuracy = 0.941837, f1-score = 0.955504, loss = 24.632961
2023-08-09-20-40-25: Finished batch 2700.

2023-08-09-20-41-29: Training (last 300 batches): accuracy = 0.993602, f1-score = 0.994981, loss = 5.038083
2023-08-09-20-41-34: Validation (total 82 batches): accuracy = 0.944898, f1-score = 0.957480, loss = 23.435442
2023-08-09-20-41-34: Finished batch 3000.

2023-08-09-20-42-31: Training (last 300 batches): accuracy = 0.996106, f1-score = 0.996938, loss = 2.813784
2023-08-09-20-42-36: Validation (total 82 batches): accuracy = 0.943878, f1-score = 0.956105, loss = 22.218660
2023-08-09-20-42-36: Finished batch 3270.

