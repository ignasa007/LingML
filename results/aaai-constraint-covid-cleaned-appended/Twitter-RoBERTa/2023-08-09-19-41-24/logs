DATASET = aaai-constraint-covid-cleaned-appended
COVID WORDS = covid 19, covid-19, covid19, covid, corona virus, coronavirus, corona
TOKENS = [URL], [HASHTAG], [MENTION], [EMOJI], [COVID]
ADD NEW TOKENS = False
MAX LENGTH = 286
BATCH SIZE = 12
MODEL = twitter-roberta-base-sentiment-latest
LEARNING RATE = 1e-05
TEST EVERY = 300
SAVE EVERY = None

2023-08-09-19-41-24: Loading and pre-processing datasets...
2023-08-09-19-41-25: Finished pre-processing datasets.

2023-08-09-19-41-25: Tokenizing datasets...
2023-08-09-19-41-27: Finished tokenizing datasets.

2023-08-09-19-41-27: Preparing data-loaders...
2023-08-09-19-41-27: Finished preparing data-loaders.

2023-08-09-19-41-27: Loading and preparing model...
2023-08-09-19-41-29: Finshed preparing model.

2023-08-09-19-41-29: Starting training...

2023-08-09-19-42-14: Training (last 300 batches): accuracy = 0.909722, f1-score = 0.929363, loss = 73.015056
2023-08-09-19-42-18: Validation (total 82 batches): accuracy = 0.952041, f1-score = 0.963481, loss = 11.869193
2023-08-09-19-42-18: Finished batch 300.

2023-08-09-19-43-06: Training (last 300 batches): accuracy = 0.958832, f1-score = 0.967458, loss = 39.096193
2023-08-09-19-43-11: Validation (total 82 batches): accuracy = 0.951020, f1-score = 0.962382, loss = 11.722596
2023-08-09-19-43-11: Finished batch 600.

2023-08-09-19-44-03: Training (last 300 batches): accuracy = 0.970793, f1-score = 0.976672, loss = 29.157668
2023-08-09-19-44-08: Validation (total 82 batches): accuracy = 0.953061, f1-score = 0.964230, loss = 11.953646
2023-08-09-19-44-08: Finished batch 900.

2023-08-09-19-45-05: Training (last 300 batches): accuracy = 0.979416, f1-score = 0.983643, loss = 19.675663
2023-08-09-19-45-10: Validation (total 82 batches): accuracy = 0.954082, f1-score = 0.964706, loss = 13.280056
2023-08-09-19-45-10: Finished batch 1200.

2023-08-09-19-46-10: Training (last 300 batches): accuracy = 0.982754, f1-score = 0.986463, loss = 16.427407
2023-08-09-19-46-15: Validation (total 82 batches): accuracy = 0.950000, f1-score = 0.961018, loss = 16.992136
2023-08-09-19-46-15: Finished batch 1500.

2023-08-09-19-47-17: Training (last 300 batches): accuracy = 0.988039, f1-score = 0.990514, loss = 11.599987
2023-08-09-19-47-22: Validation (total 82 batches): accuracy = 0.952041, f1-score = 0.962669, loss = 18.594124
2023-08-09-19-47-22: Finished batch 1800.

2023-08-09-19-48-24: Training (last 300 batches): accuracy = 0.988873, f1-score = 0.991247, loss = 9.505301
2023-08-09-19-48-29: Validation (total 82 batches): accuracy = 0.951020, f1-score = 0.962323, loss = 15.711473
2023-08-09-19-48-29: Finished batch 2100.

2023-08-09-19-49-32: Training (last 300 batches): accuracy = 0.993046, f1-score = 0.994453, loss = 4.997810
2023-08-09-19-49-37: Validation (total 82 batches): accuracy = 0.954082, f1-score = 0.964086, loss = 21.027853
2023-08-09-19-49-37: Finished batch 2400.

2023-08-09-19-50-38: Training (last 300 batches): accuracy = 0.991377, f1-score = 0.993103, loss = 7.979802
2023-08-09-19-50-44: Validation (total 82 batches): accuracy = 0.955102, f1-score = 0.965024, loss = 16.355110
2023-08-09-19-50-44: Finished batch 2700.

2023-08-09-19-51-47: Training (last 300 batches): accuracy = 0.998053, f1-score = 0.998476, loss = 2.442519
2023-08-09-19-51-52: Validation (total 82 batches): accuracy = 0.957143, f1-score = 0.966825, loss = 19.983904
2023-08-09-19-51-52: Finished batch 3000.

2023-08-09-19-52-48: Training (last 300 batches): accuracy = 0.994437, f1-score = 0.995587, loss = 5.194372
2023-08-09-19-52-53: Validation (total 82 batches): accuracy = 0.956122, f1-score = 0.966275, loss = 18.189966
2023-08-09-19-52-53: Finished batch 3270.

