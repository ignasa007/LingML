{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FONTDICT = {\n",
    "    'family': 'serif', \n",
    "    'color': 'black', \n",
    "    'weight': 'normal', \n",
    "    'size': 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(dataset, models):\n",
    "\n",
    "    valid_models = set(models)\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    for model in valid_models.copy():\n",
    "\n",
    "        exp_dir = f'./results/{dataset}/{model}'\n",
    "\n",
    "        if not os.path.isdir(exp_dir):\n",
    "            valid_models.discard(model)\n",
    "            continue\n",
    "\n",
    "        run_dir = f'{exp_dir}'\n",
    "        results[model].append(dict())\n",
    "        for split in ('training', 'validation'):\n",
    "            fn = f'{run_dir}/{split}_results.pkl'\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn, 'rb') as f:\n",
    "                    results[model][-1][split] = dict(pickle.load(f))\n",
    "        if not results[model][-1]:\n",
    "            results[model].pop()\n",
    "\n",
    "        runs = os.listdir(exp_dir)\n",
    "        if len(runs) != 5:\n",
    "            print(f'{len(runs)} total runs: dataset {dataset}, model {model}')\n",
    "        for run in runs:\n",
    "            run_dir = f'{exp_dir}/{run}'\n",
    "            if os.path.isdir(run_dir):\n",
    "                results[model].append(dict())\n",
    "                for split in ('training', 'validation'):\n",
    "                    fn = f'{run_dir}/{split}_results.pkl'\n",
    "                    if os.path.isfile(fn):\n",
    "                        with open(fn, 'rb') as f:\n",
    "                            results[model][-1][split] = dict(pickle.load(f))\n",
    "                if not results[model][-1]:\n",
    "                    results[model].pop()\n",
    "        if len(results[model]) != 5:\n",
    "            print(f'{len(results[model])} valid runs: dataset {dataset}, model {model}')\n",
    "    \n",
    "    return dict(results), tuple(valid_models)\n",
    "\n",
    "def loss(data, idxs, jump):\n",
    "    ys = list()\n",
    "    for idx in idxs:\n",
    "        loss = sum(data['loss'][idx-jump:idx])\n",
    "        tp, tn, fp, fn = (\n",
    "            sum(data['tp'][idx-jump:idx]),\n",
    "            sum(data['tn'][idx-jump:idx]),\n",
    "            sum(data['fp'][idx-jump:idx]),\n",
    "            sum(data['fn'][idx-jump:idx]),\n",
    "        )\n",
    "        ys.append(loss / (tp+tn+fp+fn))\n",
    "    return ys\n",
    "\n",
    "def accuracy(data, idxs, jump):\n",
    "    ys = list()\n",
    "    for idx in idxs:\n",
    "        tp, tn, fp, fn = (\n",
    "            sum(data['tp'][idx-jump:idx]),\n",
    "            sum(data['tn'][idx-jump:idx]),\n",
    "            sum(data['fp'][idx-jump:idx]),\n",
    "            sum(data['fn'][idx-jump:idx]),\n",
    "        )\n",
    "        acc = (tp+tn) / (tp+tn+fp+fn)\n",
    "        ys.append(acc)\n",
    "    return ys\n",
    "\n",
    "def f1_score(data, idxs, jump):\n",
    "    ys = list()\n",
    "    for idx in idxs:\n",
    "        tp, fp, fn = (\n",
    "            sum(data['tp'][idx-jump:idx]),\n",
    "            sum(data['fp'][idx-jump:idx]),\n",
    "            sum(data['fn'][idx-jump:idx]),\n",
    "        )\n",
    "        f1 = (tp+tp) / (tp+tp+fp+fn)\n",
    "        ys.append(f1)\n",
    "    return ys\n",
    "\n",
    "fn_map = {\n",
    "    'Loss': loss,\n",
    "    'Accuracy': accuracy,\n",
    "    'F1-Score': f1_score\n",
    "}\n",
    "\n",
    "models = ['ALBERT', 'BERT', 'BERTweet', 'CT-BERT', 'DistilBERT', 'RoBERTa', 'Twitter-RoBERTa', 'XLM', 'XLM-RoBERTa', 'XLNet',]\n",
    "\n",
    "pairs = (\n",
    "    ('CT-BERT', 'Twitter-RoBERTa'), \n",
    "    ('CT-BERT-NT', 'Twitter-RoBERTa-NT'), \n",
    "    ('CT-BERT', 'CT-BERT-NT'), \n",
    "    ('Twitter-RoBERTa', 'Twitter-RoBERTa-NT'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_plot(dataset, results, pairs, split, metric, jump, sep='/'):\n",
    "\n",
    "    for k1, k2 in pairs:\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.xlabel('Batches Trained', fontdict=FONTDICT, labelpad=12)\n",
    "        plt.ylabel(metric, fontdict=FONTDICT, labelpad=12)\n",
    "        if metric.lower() == 'loss':\n",
    "            plt.ticklabel_format(axis='both', style='sci', scilimits=(0, 0))\n",
    "        else:\n",
    "            plt.ticklabel_format(axis='x', style='sci', scilimits=(0, 0))\n",
    "\n",
    "        data = results[k1][split]\n",
    "        idxs = list(range(jump, len(data['batch'])+jump, jump))\n",
    "        xs = [data['batch'][min(idx, len(data['batch']))-1] for idx in idxs]\n",
    "        ys = fn_map[metric](data, idxs, jump)\n",
    "        plt.plot(xs, ys, label=k1)\n",
    "\n",
    "        data = results[k2][split]\n",
    "        ys = fn_map[metric](data, idxs, jump)\n",
    "        plt.plot(xs, ys, label=k2)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        fn = f'./assets/{dataset}{sep}{k1}_{k2}{sep}{split}{sep}{metric.lower()}.png'\n",
    "        if not os.path.exists(os.path.dirname(fn)):\n",
    "            os.makedirs(os.path.dirname(fn))\n",
    "        plt.savefig(fn, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'aaai-constraint-covid'\n",
    "jump = 50\n",
    "\n",
    "results, valid_pairs = get_results(dataset, pairs)\n",
    "\n",
    "for split, jump in (('training', 50), ('validation', 1)):\n",
    "    for metric in ('Loss', 'Accuracy', 'F1-Score'):\n",
    "        pairwise_plot(dataset, results, valid_pairs, split, metric, jump, sep='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_91ddc_row0_col0, #T_91ddc_row0_col1, #T_91ddc_row0_col2, #T_91ddc_row1_col0, #T_91ddc_row1_col1, #T_91ddc_row1_col2, #T_91ddc_row2_col0, #T_91ddc_row2_col1, #T_91ddc_row2_col2, #T_91ddc_row3_col0, #T_91ddc_row3_col1, #T_91ddc_row3_col2, #T_91ddc_row4_col0, #T_91ddc_row4_col1, #T_91ddc_row4_col2, #T_91ddc_row5_col0, #T_91ddc_row5_col1, #T_91ddc_row5_col2, #T_91ddc_row6_col0, #T_91ddc_row6_col1, #T_91ddc_row6_col2, #T_91ddc_row7_col0, #T_91ddc_row7_col1, #T_91ddc_row7_col2, #T_91ddc_row8_col0, #T_91ddc_row8_col1, #T_91ddc_row8_col2, #T_91ddc_row9_col0, #T_91ddc_row9_col1, #T_91ddc_row9_col2 {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_91ddc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_91ddc_level0_col0\" class=\"col_heading level0 col0\" >acc</th>\n",
       "      <th id=\"T_91ddc_level0_col1\" class=\"col_heading level0 col1\" >acc-appended</th>\n",
       "      <th id=\"T_91ddc_level0_col2\" class=\"col_heading level0 col2\" >improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_91ddc_level0_row0\" class=\"row_heading level0 row0\" >ALBERT</th>\n",
       "      <td id=\"T_91ddc_row0_col0\" class=\"data row0 col0\" >96.663551</td>\n",
       "      <td id=\"T_91ddc_row0_col1\" class=\"data row0 col1\" >96.794393</td>\n",
       "      <td id=\"T_91ddc_row0_col2\" class=\"data row0 col2\" >0.130841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91ddc_level0_row1\" class=\"row_heading level0 row1\" >BERT</th>\n",
       "      <td id=\"T_91ddc_row1_col0\" class=\"data row1 col0\" >96.841121</td>\n",
       "      <td id=\"T_91ddc_row1_col1\" class=\"data row1 col1\" >97.046729</td>\n",
       "      <td id=\"T_91ddc_row1_col2\" class=\"data row1 col2\" >0.205607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91ddc_level0_row2\" class=\"row_heading level0 row2\" >BERTweet</th>\n",
       "      <td id=\"T_91ddc_row2_col0\" class=\"data row2 col0\" >97.046729</td>\n",
       "      <td id=\"T_91ddc_row2_col1\" class=\"data row2 col1\" >97.084112</td>\n",
       "      <td id=\"T_91ddc_row2_col2\" class=\"data row2 col2\" >0.037383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91ddc_level0_row3\" class=\"row_heading level0 row3\" >CT-BERT</th>\n",
       "      <td id=\"T_91ddc_row3_col0\" class=\"data row3 col0\" >98.074766</td>\n",
       "      <td id=\"T_91ddc_row3_col1\" class=\"data row3 col1\" >98.158879</td>\n",
       "      <td id=\"T_91ddc_row3_col2\" class=\"data row3 col2\" >0.084112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91ddc_level0_row4\" class=\"row_heading level0 row4\" >DistilBERT</th>\n",
       "      <td id=\"T_91ddc_row4_col0\" class=\"data row4 col0\" >97.383178</td>\n",
       "      <td id=\"T_91ddc_row4_col1\" class=\"data row4 col1\" >97.233645</td>\n",
       "      <td id=\"T_91ddc_row4_col2\" class=\"data row4 col2\" >-0.149533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91ddc_level0_row5\" class=\"row_heading level0 row5\" >RoBERTa</th>\n",
       "      <td id=\"T_91ddc_row5_col0\" class=\"data row5 col0\" >97.009346</td>\n",
       "      <td id=\"T_91ddc_row5_col1\" class=\"data row5 col1\" >97.046729</td>\n",
       "      <td id=\"T_91ddc_row5_col2\" class=\"data row5 col2\" >0.037383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91ddc_level0_row6\" class=\"row_heading level0 row6\" >Twitter-RoBERTa</th>\n",
       "      <td id=\"T_91ddc_row6_col0\" class=\"data row6 col0\" >97.121495</td>\n",
       "      <td id=\"T_91ddc_row6_col1\" class=\"data row6 col1\" >97.074766</td>\n",
       "      <td id=\"T_91ddc_row6_col2\" class=\"data row6 col2\" >-0.046729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91ddc_level0_row7\" class=\"row_heading level0 row7\" >XLM</th>\n",
       "      <td id=\"T_91ddc_row7_col0\" class=\"data row7 col0\" >97.121495</td>\n",
       "      <td id=\"T_91ddc_row7_col1\" class=\"data row7 col1\" >96.962617</td>\n",
       "      <td id=\"T_91ddc_row7_col2\" class=\"data row7 col2\" >-0.158879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91ddc_level0_row8\" class=\"row_heading level0 row8\" >XLM-RoBERTa</th>\n",
       "      <td id=\"T_91ddc_row8_col0\" class=\"data row8 col0\" >97.420561</td>\n",
       "      <td id=\"T_91ddc_row8_col1\" class=\"data row8 col1\" >97.476636</td>\n",
       "      <td id=\"T_91ddc_row8_col2\" class=\"data row8 col2\" >0.056075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91ddc_level0_row9\" class=\"row_heading level0 row9\" >XLNet</th>\n",
       "      <td id=\"T_91ddc_row9_col0\" class=\"data row9 col0\" >97.252336</td>\n",
       "      <td id=\"T_91ddc_row9_col1\" class=\"data row9 col1\" >97.177570</td>\n",
       "      <td id=\"T_91ddc_row9_col2\" class=\"data row9 col2\" >-0.074766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f83d2c64790>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = (\n",
    "    'aaai-constraint-covid',\n",
    "    'aaai-constraint-covid-appended',\n",
    "    # 'aaai-constraint-covid-cleaned',\n",
    "    # 'aaai-constraint-covid-cleaned-appended',\n",
    "    # 'covid-misinformation',\n",
    ")\n",
    "\n",
    "index = sorted(models) # + [model+'-NT' for model in models])\n",
    "split = 'validation'\n",
    "metric = 'Accuracy'\n",
    "jump = 600 if split == 'training' else 1\n",
    "\n",
    "dataframe = defaultdict(list)\n",
    "\n",
    "for dataset in datasets:\n",
    "    col_name = dataset.replace('aaai-constraint-covid', 'acc')\n",
    "    results, _ = get_results(dataset, index)\n",
    "    for model in index:\n",
    "        if model in results:\n",
    "            scores = list()\n",
    "            for run in results[model]:\n",
    "                data = run[split]\n",
    "                idxs = list(range(jump, len(data['batch'])+jump, jump))\n",
    "                ys = fn_map[metric](data, idxs, jump)\n",
    "                scores.append(max(ys))\n",
    "            dataframe[col_name].append(100*np.mean(scores)) # f'{100*np.mean(scores):.4f} +- {100*np.std(scores):.4f}')\n",
    "        else:\n",
    "            dataframe[col_name].append(np.nan)\n",
    "\n",
    "dataframe['improved'] = (np.array(dataframe['acc-appended'] - np.array(dataframe['acc']))).tolist()\n",
    "\n",
    "pd.DataFrame(dataframe, index=index).style.set_properties(**{'text-align': 'right'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
